{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e300ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gypsum-gpu105/4288174/ipykernel_721832/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbef18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from functools import reduce\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.insert(0,'./utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from SGD import *\n",
    "import copy\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77aa30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models import *\n",
    "from cifar10_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d17e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26708069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dirichlet_train_data(trainset, no_participants, alpha=0.9, force=False):\n",
    "        \"\"\"\n",
    "            Input: Number of participants and alpha (param for distribution)\n",
    "            Output: A list of indices denoting data in CIFAR training set.\n",
    "            Requires: cifar_classes, a preprocessed class-indice dictionary.\n",
    "            Sample Method: take a uniformly sampled 10-dimension vector as parameters for\n",
    "            dirichlet distribution to sample number of images in each class.\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants)) or force:\n",
    "            print('generating participant indices for alpha %.1f'%alpha)\n",
    "            np.random.seed(0)\n",
    "            cifar_classes = {}\n",
    "            for ind, x in enumerate(trainset):\n",
    "                _, label = x\n",
    "                if label in cifar_classes:\n",
    "                    cifar_classes[label].append(ind)\n",
    "                else:\n",
    "                    cifar_classes[label] = [ind]\n",
    "\n",
    "            per_participant_list = defaultdict(list)\n",
    "            no_classes = len(cifar_classes.keys())\n",
    "            for n in range(no_classes):\n",
    "                random.shuffle(cifar_classes[n])\n",
    "                sampled_probabilities = len(cifar_classes[n]) * np.random.dirichlet(\n",
    "                    np.array(no_participants * [alpha]))\n",
    "                for user in range(no_participants):\n",
    "                    no_imgs = int(round(sampled_probabilities[user]))\n",
    "                    sampled_list = cifar_classes[n][:min(len(cifar_classes[n]), no_imgs)]\n",
    "                    per_participant_list[user].extend(sampled_list)\n",
    "                    cifar_classes[n] = cifar_classes[n][min(len(cifar_classes[n]), no_imgs):]\n",
    "            with open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'wb') as f:\n",
    "                pickle.dump(per_participant_list, f)\n",
    "        else:\n",
    "            per_participant_list = pickle.load(open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'rb'))\n",
    "\n",
    "        return per_participant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c258374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fang_train_data(trainset, num_workers=100, bias=0.5):\n",
    "    bias_weight = bias\n",
    "    other_group_size = (1 - bias_weight) / 9.\n",
    "    worker_per_group = num_workers / 10\n",
    "\n",
    "    each_worker_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_label = [[] for _ in range(num_workers)]\n",
    "    per_participant_list = defaultdict(list)\n",
    "    for i, (x, y) in enumerate(trainset):\n",
    "        # assign a data point to a group\n",
    "        upper_bound = (y) * (1 - bias_weight) / 9. + bias_weight\n",
    "        lower_bound = (y) * (1 - bias_weight) / 9.\n",
    "        rd = np.random.random_sample()\n",
    "\n",
    "        if rd > upper_bound:\n",
    "            worker_group = int(np.floor((rd - upper_bound) / other_group_size) + y + 1)\n",
    "        elif rd < lower_bound:\n",
    "            worker_group = int(np.floor(rd / other_group_size))\n",
    "        else:\n",
    "            worker_group = y\n",
    "\n",
    "        rd = np.random.random_sample()\n",
    "        selected_worker = int(worker_group * worker_per_group + int(np.floor(rd * worker_per_group)))\n",
    "        \n",
    "        per_participant_list[selected_worker].extend([i])\n",
    "    \n",
    "    return per_participant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799ffb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_federated_data(trainset, num_workers, distribution='fang', param=1, force=False):\n",
    "    if distribution == 'fang':\n",
    "        per_participant_list = get_fang_train_data(trainset, num_workers, bias=param)\n",
    "    elif distribution == 'dirichlet':\n",
    "        per_participant_list = sample_dirichlet_train_data(trainset, num_workers, alpha=param, force=force)\n",
    "\n",
    "    each_worker_idx = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    each_worker_te_idx = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    for worker_idx in range(len(per_participant_list)):\n",
    "        w_indices = np.array(per_participant_list[worker_idx])\n",
    "        w_len = len(w_indices)\n",
    "        len_tr = int(6*w_len/7)\n",
    "        tr_idx = np.random.choice(w_len, len_tr, replace=False)\n",
    "        te_idx = np.delete(np.arange(w_len), tr_idx)\n",
    "        \n",
    "        each_worker_idx[worker_idx] = w_indices[tr_idx]\n",
    "        each_worker_te_idx[worker_idx] = w_indices[te_idx]\n",
    "    \n",
    "    global_test_idx = np.concatenate(each_worker_te_idx)\n",
    "    \n",
    "    return each_worker_idx, each_worker_te_idx, global_test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2590db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(dataset, indices, batch_size=32, shuffle=False):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=torch.utils.data.sampler.SubsetRandomSampler(indices))\n",
    "    \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbb06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/home/vshejwalkar_umass_edu/data/'\n",
    "# load the train dataset\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=transform_train)\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=transform_train)\n",
    "\n",
    "te_cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=transform_test)\n",
    "te_cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84b05be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs(S_k_list, Y_k_list, v):\n",
    "    curr_S_k = torch.stack(S_k_list).T\n",
    "    curr_Y_k = torch.stack(Y_k_list).T\n",
    "    S_k_time_Y_k = np.dot(curr_S_k.T.cpu().numpy(), curr_Y_k.cpu().numpy())\n",
    "    S_k_time_S_k = np.dot(curr_S_k.T.cpu().numpy(), curr_S_k.cpu().numpy())\n",
    "    R_k = np.triu(S_k_time_Y_k)\n",
    "    L_k = S_k_time_Y_k - R_k\n",
    "    sigma_k = np.dot(Y_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()) / (np.dot(S_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()))\n",
    "    D_k_diag = np.diag(S_k_time_Y_k)\n",
    "    upper_mat = np.concatenate((sigma_k * S_k_time_S_k, L_k), axis=1)\n",
    "    lower_mat = np.concatenate((L_k.T, -np.diag(D_k_diag)), axis=1)\n",
    "    mat = np.concatenate((upper_mat, lower_mat), axis=0)\n",
    "    mat_inv = np.linalg.inv(mat)\n",
    "\n",
    "    approx_prod = sigma_k * v.cpu().numpy()\n",
    "    approx_prod = approx_prod.T\n",
    "    p_mat = np.concatenate((np.dot(curr_S_k.T.cpu().numpy(), sigma_k * v.unsqueeze(0).T.cpu().numpy()), np.dot(curr_Y_k.T.cpu().numpy(), v.unsqueeze(0).T.cpu().numpy())), axis=0)\n",
    "    approx_prod -= np.dot(np.dot(np.concatenate((sigma_k * curr_S_k.cpu().numpy(), curr_Y_k.cpu().numpy()), axis=1), mat_inv), p_mat)\n",
    "\n",
    "    return approx_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e35368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_trim(v, f):\n",
    "    '''\n",
    "    Full-knowledge Trim attack. w.l.o.g., we assume the first f worker devices are compromised.\n",
    "    v: the list of squeezed gradients\n",
    "    f: the number of compromised worker devices\n",
    "    '''\n",
    "    vi_shape = v[0].unsqueeze(0).T.shape\n",
    "    v_tran = v.T\n",
    "    \n",
    "    maximum_dim = torch.max(v_tran, dim=1)\n",
    "    maximum_dim = maximum_dim[0].reshape(vi_shape)\n",
    "    minimum_dim = torch.min(v_tran, dim=1)\n",
    "    minimum_dim = minimum_dim[0].reshape(vi_shape)\n",
    "    direction = torch.sign(torch.sum(v_tran, dim=-1, keepdims=True))\n",
    "    directed_dim = (direction > 0) * minimum_dim + (direction < 0) * maximum_dim\n",
    "\n",
    "    for i in range(20):\n",
    "        random_12 = 2\n",
    "        tmp = directed_dim * ((direction * directed_dim > 0) / random_12 + (direction * directed_dim < 0) * random_12)\n",
    "        tmp = tmp.squeeze()\n",
    "        v[i] = tmp\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2f5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_mean(all_updates, n_attackers):\n",
    "    sorted_updates = torch.sort(all_updates, 0)[0]\n",
    "    out = torch.mean(sorted_updates[n_attackers:-n_attackers], 0) if n_attackers else torch.mean(sorted_updates,0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5c00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mean(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = torch.mean(user_grads,dim=0)\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72fe92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = torch.median(user_grads, 0)[0]\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2626a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_mean(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = tr_mean(user_grads, b)\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67adc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(score, nobyz):\n",
    "    estimator = KMeans(n_clusters=2)\n",
    "    estimator.fit(score.reshape(-1, 1))\n",
    "    label_pred = estimator.labels_\n",
    "    if np.mean(score[label_pred==0])<np.mean(score[label_pred==1]):\n",
    "        #0 is the label of malicious clients\n",
    "        label_pred = 1 - label_pred\n",
    "    real_label=np.ones(100)\n",
    "    real_label[:nobyz]=0\n",
    "    acc=len(label_pred[label_pred==real_label])/100\n",
    "    recall=1-np.sum(label_pred[:nobyz])/nobyz\n",
    "    fpr=1-np.sum(label_pred[nobyz:])/(100-nobyz)\n",
    "    fnr=np.sum(label_pred[:nobyz])/nobyz\n",
    "    print(\"acc %0.4f; recall %0.4f; fpr %0.4f; fnr %0.4f;\" % (acc, recall, fpr, fnr))\n",
    "    print(silhouette_score(score.reshape(-1, 1), label_pred))\n",
    "\n",
    "def detection1(score, nobyz):\n",
    "    nrefs = 10\n",
    "    ks = range(1, 8)\n",
    "    gaps = np.zeros(len(ks))\n",
    "    gapDiff = np.zeros(len(ks) - 1)\n",
    "    sdk = np.zeros(len(ks))\n",
    "    min = np.min(score)\n",
    "    max = np.max(score)\n",
    "    score = (score - min)/(max-min)\n",
    "    for i, k in enumerate(ks):\n",
    "        estimator = KMeans(n_clusters=k)\n",
    "        estimator.fit(score.reshape(-1, 1))\n",
    "        label_pred = estimator.labels_\n",
    "        center = estimator.cluster_centers_\n",
    "        Wk = np.sum([np.square(score[m]-center[label_pred[m]]) for m in range(len(score))])\n",
    "        WkRef = np.zeros(nrefs)\n",
    "        for j in range(nrefs):\n",
    "            rand = np.random.uniform(0, 1, len(score))\n",
    "            estimator = KMeans(n_clusters=k)\n",
    "            estimator.fit(rand.reshape(-1, 1))\n",
    "            label_pred = estimator.labels_\n",
    "            center = estimator.cluster_centers_\n",
    "            WkRef[j] = np.sum([np.square(rand[m]-center[label_pred[m]]) for m in range(len(rand))])\n",
    "        gaps[i] = np.log(np.mean(WkRef)) - np.log(Wk)\n",
    "        sdk[i] = np.sqrt((1.0 + nrefs) / nrefs) * np.std(np.log(WkRef))\n",
    "\n",
    "        if i > 0:\n",
    "            gapDiff[i - 1] = gaps[i - 1] - gaps[i] + sdk[i]\n",
    "    #print(gapDiff)\n",
    "    for i in range(len(gapDiff)):\n",
    "        if gapDiff[i] >= 0:\n",
    "            select_k = i+1\n",
    "            break\n",
    "    if select_k == 1:\n",
    "        print('No attack detected!')\n",
    "        return 0\n",
    "    else:\n",
    "        print('Attack Detected!')\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa727c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "def train(trainloader, model, model_received, criterion, optimizer, pgd=False, eps=2):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    for batch_ind, (inputs, targets) in enumerate(trainloader):\n",
    "\n",
    "        inputs = inputs.to(device, torch.float)\n",
    "        targets = targets.to(device, torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size()[0])\n",
    "        top1.update(prec1.item()/100.0, inputs.size()[0])\n",
    "        top5.update(prec5.item()/100.0, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if pgd:\n",
    "            curr_model = list(model.parameters())\n",
    "            curr_model_vec = parameters_to_vector(curr_model)\n",
    "\n",
    "            if torch.norm(curr_model_vec - model_received) > eps:\n",
    "                curr_model_vec = eps*(curr_model_vec - model_received)/torch.norm(curr_model_vec - model_received) + model_received\n",
    "                vector_to_parameters(curr_model_vec, curr_model)\n",
    "        \n",
    "    return (losses.avg, top1.avg)\n",
    "\n",
    "def test(testloader, model, criterion):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    for batch_ind, (inputs, targets) in enumerate(testloader):\n",
    "        inputs = inputs.to(device, torch.float)\n",
    "        targets = targets.to(device, torch.long)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1/100.0, inputs.size()[0])\n",
    "        top5.update(prec5/100.0, inputs.size()[0])\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7649f7",
   "metadata": {},
   "source": [
    "# Dirichlet + FLDetector + No attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc35a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 29175.260 val loss 2.306 val acc 0.100 best val_acc 0.100\n",
      "e 1 benign_norm 21858.783 val loss 2.313 val acc 0.102 best val_acc 0.102\n",
      "e 2 benign_norm 1609.195 val loss 2.327 val acc 0.102 best val_acc 0.102\n",
      "e 3 benign_norm 594.408 val loss 2.324 val acc 0.102 best val_acc 0.102\n",
      "e 4 benign_norm 574.951 val loss 2.302 val acc 0.133 best val_acc 0.133\n",
      "e 5 benign_norm 576.496 val loss 2.286 val acc 0.106 best val_acc 0.133\n",
      "e 6 benign_norm 568.677 val loss 2.240 val acc 0.110 best val_acc 0.133\n",
      "e 7 benign_norm 568.249 val loss 2.186 val acc 0.142 best val_acc 0.142\n",
      "e 8 benign_norm 568.988 val loss 2.115 val acc 0.205 best val_acc 0.205\n",
      "e 9 benign_norm 565.248 val loss 2.043 val acc 0.245 best val_acc 0.245\n",
      "e 10 benign_norm 564.762 val loss 1.991 val acc 0.270 best val_acc 0.270\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 564.371 val loss 1.941 val acc 0.296 best val_acc 0.296\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 564.153 val loss 1.893 val acc 0.327 best val_acc 0.327\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 563.919 val loss 1.850 val acc 0.348 best val_acc 0.348\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 563.953 val loss 1.802 val acc 0.370 best val_acc 0.370\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 563.843 val loss 1.783 val acc 0.371 best val_acc 0.371\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 563.861 val loss 1.737 val acc 0.388 best val_acc 0.388\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 563.920 val loss 1.711 val acc 0.396 best val_acc 0.396\n",
      "==> 18 (8, 100)\n",
      "e 18 benign_norm 564.525 val loss 1.699 val acc 0.405 best val_acc 0.405\n",
      "==> 19 (9, 100)\n",
      "e 19 benign_norm 564.613 val loss 1.663 val acc 0.421 best val_acc 0.421\n",
      "==> 20 (10, 100)\n",
      "performing detection at epoch 20\n",
      "No attack detected!\n",
      "e 20 benign_norm 563.789 val loss 1.639 val acc 0.419 best val_acc 0.421\n",
      "==> 21 (11, 100)\n",
      "performing detection at epoch 21\n",
      "No attack detected!\n",
      "e 21 benign_norm 563.862 val loss 1.612 val acc 0.432 best val_acc 0.432\n",
      "==> 22 (12, 100)\n",
      "performing detection at epoch 22\n",
      "No attack detected!\n",
      "e 22 benign_norm 563.823 val loss 1.582 val acc 0.443 best val_acc 0.443\n",
      "==> 23 (13, 100)\n",
      "performing detection at epoch 23\n",
      "No attack detected!\n",
      "e 23 benign_norm 563.871 val loss 1.573 val acc 0.443 best val_acc 0.443\n",
      "==> 24 (14, 100)\n",
      "performing detection at epoch 24\n",
      "No attack detected!\n",
      "e 24 benign_norm 563.963 val loss 1.551 val acc 0.451 best val_acc 0.451\n",
      "==> 25 (15, 100)\n",
      "performing detection at epoch 25\n",
      "No attack detected!\n",
      "e 25 benign_norm 563.872 val loss 1.525 val acc 0.461 best val_acc 0.461\n",
      "==> 26 (16, 100)\n",
      "performing detection at epoch 26\n",
      "No attack detected!\n",
      "e 26 benign_norm 564.015 val loss 1.493 val acc 0.474 best val_acc 0.474\n",
      "==> 27 (17, 100)\n",
      "performing detection at epoch 27\n",
      "No attack detected!\n",
      "e 27 benign_norm 564.033 val loss 1.493 val acc 0.473 best val_acc 0.474\n",
      "==> 28 (18, 100)\n",
      "performing detection at epoch 28\n",
      "No attack detected!\n",
      "e 28 benign_norm 563.992 val loss 1.458 val acc 0.490 best val_acc 0.490\n",
      "==> 29 (19, 100)\n",
      "performing detection at epoch 29\n",
      "No attack detected!\n",
      "e 29 benign_norm 564.088 val loss 1.450 val acc 0.496 best val_acc 0.496\n",
      "==> 30 (20, 100)\n",
      "performing detection at epoch 30\n",
      "No attack detected!\n",
      "e 30 benign_norm 564.122 val loss 1.437 val acc 0.503 best val_acc 0.503\n",
      "==> 31 (21, 100)\n",
      "performing detection at epoch 31\n",
      "No attack detected!\n",
      "e 31 benign_norm 564.136 val loss 1.418 val acc 0.505 best val_acc 0.505\n",
      "==> 32 (22, 100)\n",
      "performing detection at epoch 32\n",
      "No attack detected!\n",
      "e 32 benign_norm 564.164 val loss 1.399 val acc 0.512 best val_acc 0.512\n",
      "==> 33 (23, 100)\n",
      "performing detection at epoch 33\n",
      "No attack detected!\n",
      "e 33 benign_norm 564.263 val loss 1.394 val acc 0.513 best val_acc 0.513\n",
      "==> 34 (24, 100)\n",
      "performing detection at epoch 34\n",
      "No attack detected!\n",
      "e 34 benign_norm 564.151 val loss 1.372 val acc 0.522 best val_acc 0.522\n",
      "==> 35 (25, 100)\n",
      "performing detection at epoch 35\n",
      "No attack detected!\n",
      "e 35 benign_norm 564.213 val loss 1.347 val acc 0.529 best val_acc 0.529\n",
      "==> 36 (26, 100)\n",
      "performing detection at epoch 36\n",
      "No attack detected!\n",
      "e 36 benign_norm 564.395 val loss 1.355 val acc 0.530 best val_acc 0.530\n",
      "==> 37 (27, 100)\n",
      "performing detection at epoch 37\n",
      "No attack detected!\n",
      "e 37 benign_norm 564.366 val loss 1.341 val acc 0.533 best val_acc 0.533\n",
      "==> 38 (28, 100)\n",
      "performing detection at epoch 38\n",
      "No attack detected!\n",
      "e 38 benign_norm 564.302 val loss 1.332 val acc 0.533 best val_acc 0.533\n",
      "==> 39 (29, 100)\n",
      "performing detection at epoch 39\n",
      "No attack detected!\n",
      "e 39 benign_norm 564.429 val loss 1.310 val acc 0.541 best val_acc 0.541\n",
      "==> 40 (30, 100)\n",
      "performing detection at epoch 40\n",
      "No attack detected!\n",
      "e 40 benign_norm 564.467 val loss 1.297 val acc 0.552 best val_acc 0.552\n",
      "==> 41 (31, 100)\n",
      "performing detection at epoch 41\n",
      "No attack detected!\n",
      "e 41 benign_norm 564.459 val loss 1.289 val acc 0.549 best val_acc 0.552\n",
      "==> 42 (32, 100)\n",
      "performing detection at epoch 42\n",
      "No attack detected!\n",
      "e 42 benign_norm 564.826 val loss 1.286 val acc 0.553 best val_acc 0.553\n",
      "==> 43 (33, 100)\n",
      "performing detection at epoch 43\n",
      "No attack detected!\n",
      "e 43 benign_norm 564.425 val loss 1.263 val acc 0.562 best val_acc 0.562\n",
      "==> 44 (34, 100)\n",
      "performing detection at epoch 44\n",
      "No attack detected!\n",
      "e 44 benign_norm 564.496 val loss 1.252 val acc 0.566 best val_acc 0.566\n",
      "==> 45 (35, 100)\n",
      "performing detection at epoch 45\n",
      "No attack detected!\n",
      "e 45 benign_norm 564.727 val loss 1.229 val acc 0.576 best val_acc 0.576\n",
      "==> 46 (36, 100)\n",
      "performing detection at epoch 46\n",
      "No attack detected!\n",
      "e 46 benign_norm 564.603 val loss 1.231 val acc 0.570 best val_acc 0.576\n",
      "==> 47 (37, 100)\n",
      "performing detection at epoch 47\n",
      "No attack detected!\n",
      "e 47 benign_norm 564.676 val loss 1.219 val acc 0.579 best val_acc 0.579\n",
      "==> 48 (38, 100)\n",
      "performing detection at epoch 48\n",
      "No attack detected!\n",
      "e 48 benign_norm 564.681 val loss 1.219 val acc 0.576 best val_acc 0.579\n",
      "==> 49 (39, 100)\n",
      "performing detection at epoch 49\n",
      "No attack detected!\n",
      "e 49 benign_norm 564.881 val loss 1.200 val acc 0.582 best val_acc 0.582\n",
      "==> 50 (40, 100)\n",
      "performing detection at epoch 50\n",
      "No attack detected!\n",
      "e 50 benign_norm 564.780 val loss 1.203 val acc 0.582 best val_acc 0.582\n",
      "==> 51 (41, 100)\n",
      "performing detection at epoch 51\n",
      "No attack detected!\n",
      "e 51 benign_norm 564.996 val loss 1.197 val acc 0.586 best val_acc 0.586\n",
      "==> 52 (42, 100)\n",
      "performing detection at epoch 52\n",
      "No attack detected!\n",
      "e 52 benign_norm 564.836 val loss 1.181 val acc 0.589 best val_acc 0.589\n",
      "==> 53 (43, 100)\n",
      "performing detection at epoch 53\n",
      "No attack detected!\n",
      "e 53 benign_norm 564.988 val loss 1.171 val acc 0.592 best val_acc 0.592\n",
      "==> 54 (44, 100)\n",
      "performing detection at epoch 54\n",
      "No attack detected!\n",
      "e 54 benign_norm 564.959 val loss 1.162 val acc 0.594 best val_acc 0.594\n",
      "==> 55 (45, 100)\n",
      "performing detection at epoch 55\n",
      "No attack detected!\n",
      "e 55 benign_norm 565.183 val loss 1.147 val acc 0.604 best val_acc 0.604\n",
      "==> 56 (46, 100)\n",
      "performing detection at epoch 56\n",
      "No attack detected!\n",
      "e 56 benign_norm 565.088 val loss 1.142 val acc 0.602 best val_acc 0.604\n",
      "==> 57 (47, 100)\n",
      "performing detection at epoch 57\n",
      "No attack detected!\n",
      "e 57 benign_norm 565.117 val loss 1.136 val acc 0.605 best val_acc 0.605\n",
      "==> 58 (48, 100)\n",
      "performing detection at epoch 58\n",
      "No attack detected!\n",
      "e 58 benign_norm 565.165 val loss 1.125 val acc 0.609 best val_acc 0.609\n",
      "==> 59 (49, 100)\n",
      "performing detection at epoch 59\n",
      "No attack detected!\n",
      "e 59 benign_norm 565.281 val loss 1.114 val acc 0.613 best val_acc 0.613\n",
      "==> 60 (50, 100)\n",
      "performing detection at epoch 60\n",
      "No attack detected!\n",
      "e 60 benign_norm 565.362 val loss 1.108 val acc 0.615 best val_acc 0.615\n",
      "==> 61 (51, 100)\n",
      "performing detection at epoch 61\n",
      "No attack detected!\n",
      "e 61 benign_norm 565.389 val loss 1.103 val acc 0.617 best val_acc 0.617\n",
      "==> 62 (52, 100)\n",
      "performing detection at epoch 62\n",
      "No attack detected!\n",
      "e 62 benign_norm 565.373 val loss 1.097 val acc 0.619 best val_acc 0.619\n",
      "==> 63 (53, 100)\n",
      "performing detection at epoch 63\n",
      "No attack detected!\n",
      "e 63 benign_norm 565.390 val loss 1.083 val acc 0.624 best val_acc 0.624\n",
      "==> 64 (54, 100)\n",
      "performing detection at epoch 64\n",
      "No attack detected!\n",
      "e 64 benign_norm 565.563 val loss 1.080 val acc 0.627 best val_acc 0.627\n",
      "==> 65 (55, 100)\n",
      "performing detection at epoch 65\n",
      "No attack detected!\n",
      "e 65 benign_norm 565.412 val loss 1.075 val acc 0.625 best val_acc 0.627\n",
      "==> 66 (56, 100)\n",
      "performing detection at epoch 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 66 benign_norm 565.753 val loss 1.072 val acc 0.629 best val_acc 0.629\n",
      "==> 67 (57, 100)\n",
      "performing detection at epoch 67\n",
      "No attack detected!\n",
      "e 67 benign_norm 565.967 val loss 1.059 val acc 0.633 best val_acc 0.633\n",
      "==> 68 (58, 100)\n",
      "performing detection at epoch 68\n",
      "No attack detected!\n",
      "e 68 benign_norm 565.642 val loss 1.049 val acc 0.634 best val_acc 0.634\n",
      "==> 69 (59, 100)\n",
      "performing detection at epoch 69\n",
      "No attack detected!\n",
      "e 69 benign_norm 565.820 val loss 1.042 val acc 0.639 best val_acc 0.639\n",
      "==> 70 (60, 100)\n",
      "performing detection at epoch 70\n",
      "No attack detected!\n",
      "e 70 benign_norm 565.719 val loss 1.042 val acc 0.639 best val_acc 0.639\n",
      "==> 71 (61, 100)\n",
      "performing detection at epoch 71\n",
      "No attack detected!\n",
      "e 71 benign_norm 565.954 val loss 1.028 val acc 0.644 best val_acc 0.644\n",
      "==> 72 (62, 100)\n",
      "performing detection at epoch 72\n",
      "No attack detected!\n",
      "e 72 benign_norm 565.842 val loss 1.026 val acc 0.648 best val_acc 0.648\n",
      "==> 73 (63, 100)\n",
      "performing detection at epoch 73\n",
      "No attack detected!\n",
      "e 73 benign_norm 566.100 val loss 1.013 val acc 0.654 best val_acc 0.654\n",
      "==> 74 (64, 100)\n",
      "performing detection at epoch 74\n",
      "No attack detected!\n",
      "e 74 benign_norm 566.347 val loss 1.022 val acc 0.649 best val_acc 0.654\n",
      "==> 75 (65, 100)\n",
      "performing detection at epoch 75\n",
      "No attack detected!\n",
      "e 75 benign_norm 566.131 val loss 1.012 val acc 0.652 best val_acc 0.654\n",
      "==> 76 (66, 100)\n",
      "performing detection at epoch 76\n",
      "No attack detected!\n",
      "e 76 benign_norm 566.241 val loss 1.014 val acc 0.650 best val_acc 0.654\n",
      "==> 77 (67, 100)\n",
      "performing detection at epoch 77\n",
      "No attack detected!\n",
      "e 77 benign_norm 566.027 val loss 0.998 val acc 0.657 best val_acc 0.657\n",
      "==> 78 (68, 100)\n",
      "performing detection at epoch 78\n",
      "No attack detected!\n",
      "e 78 benign_norm 566.289 val loss 0.993 val acc 0.659 best val_acc 0.659\n",
      "==> 79 (69, 100)\n",
      "performing detection at epoch 79\n",
      "No attack detected!\n",
      "e 79 benign_norm 566.042 val loss 0.986 val acc 0.665 best val_acc 0.665\n",
      "==> 80 (70, 100)\n",
      "performing detection at epoch 80\n",
      "No attack detected!\n",
      "e 80 benign_norm 566.216 val loss 0.980 val acc 0.664 best val_acc 0.665\n",
      "==> 81 (71, 100)\n",
      "performing detection at epoch 81\n",
      "No attack detected!\n",
      "e 81 benign_norm 566.196 val loss 0.970 val acc 0.667 best val_acc 0.667\n",
      "==> 82 (72, 100)\n",
      "performing detection at epoch 82\n",
      "No attack detected!\n",
      "e 82 benign_norm 566.162 val loss 0.965 val acc 0.669 best val_acc 0.669\n",
      "==> 83 (73, 100)\n",
      "performing detection at epoch 83\n",
      "No attack detected!\n",
      "e 83 benign_norm 566.510 val loss 0.970 val acc 0.668 best val_acc 0.669\n",
      "==> 84 (74, 100)\n",
      "performing detection at epoch 84\n",
      "No attack detected!\n",
      "e 84 benign_norm 566.466 val loss 0.949 val acc 0.673 best val_acc 0.673\n",
      "==> 85 (75, 100)\n",
      "performing detection at epoch 85\n",
      "No attack detected!\n",
      "e 85 benign_norm 566.299 val loss 0.945 val acc 0.675 best val_acc 0.675\n",
      "==> 86 (76, 100)\n",
      "performing detection at epoch 86\n",
      "No attack detected!\n",
      "e 86 benign_norm 566.545 val loss 0.955 val acc 0.672 best val_acc 0.675\n",
      "==> 87 (77, 100)\n",
      "performing detection at epoch 87\n",
      "No attack detected!\n",
      "e 87 benign_norm 566.369 val loss 0.940 val acc 0.675 best val_acc 0.675\n",
      "==> 88 (78, 100)\n",
      "performing detection at epoch 88\n",
      "No attack detected!\n",
      "e 88 benign_norm 566.654 val loss 0.929 val acc 0.681 best val_acc 0.681\n",
      "==> 89 (79, 100)\n",
      "performing detection at epoch 89\n",
      "No attack detected!\n",
      "e 89 benign_norm 566.622 val loss 0.937 val acc 0.678 best val_acc 0.681\n",
      "==> 90 (80, 100)\n",
      "performing detection at epoch 90\n",
      "No attack detected!\n",
      "e 90 benign_norm 566.526 val loss 0.922 val acc 0.684 best val_acc 0.684\n",
      "==> 91 (81, 100)\n",
      "performing detection at epoch 91\n",
      "No attack detected!\n",
      "e 91 benign_norm 566.607 val loss 0.922 val acc 0.683 best val_acc 0.684\n",
      "==> 92 (82, 100)\n",
      "performing detection at epoch 92\n",
      "No attack detected!\n",
      "e 92 benign_norm 566.879 val loss 0.915 val acc 0.688 best val_acc 0.688\n",
      "==> 93 (83, 100)\n",
      "performing detection at epoch 93\n",
      "No attack detected!\n",
      "e 93 benign_norm 566.932 val loss 0.914 val acc 0.685 best val_acc 0.688\n",
      "==> 94 (84, 100)\n",
      "performing detection at epoch 94\n",
      "No attack detected!\n",
      "e 94 benign_norm 566.806 val loss 0.913 val acc 0.689 best val_acc 0.689\n",
      "==> 95 (85, 100)\n",
      "performing detection at epoch 95\n",
      "No attack detected!\n",
      "e 95 benign_norm 567.170 val loss 0.905 val acc 0.692 best val_acc 0.692\n",
      "==> 96 (86, 100)\n",
      "performing detection at epoch 96\n",
      "No attack detected!\n",
      "e 96 benign_norm 566.814 val loss 0.909 val acc 0.688 best val_acc 0.692\n",
      "==> 97 (87, 100)\n",
      "performing detection at epoch 97\n",
      "No attack detected!\n",
      "e 97 benign_norm 566.781 val loss 0.903 val acc 0.693 best val_acc 0.693\n",
      "==> 98 (88, 100)\n",
      "performing detection at epoch 98\n",
      "No attack detected!\n",
      "e 98 benign_norm 566.634 val loss 0.896 val acc 0.694 best val_acc 0.694\n",
      "==> 99 (89, 100)\n",
      "performing detection at epoch 99\n",
      "No attack detected!\n",
      "e 99 benign_norm 567.031 val loss 0.887 val acc 0.699 best val_acc 0.699\n",
      "==> 100 (90, 100)\n",
      "performing detection at epoch 100\n",
      "No attack detected!\n",
      "e 100 benign_norm 566.575 val loss 0.888 val acc 0.699 best val_acc 0.699\n",
      "==> 101 (91, 100)\n",
      "performing detection at epoch 101\n",
      "No attack detected!\n",
      "e 101 benign_norm 567.069 val loss 0.887 val acc 0.701 best val_acc 0.701\n",
      "==> 102 (92, 100)\n",
      "performing detection at epoch 102\n",
      "No attack detected!\n",
      "e 102 benign_norm 567.031 val loss 0.888 val acc 0.696 best val_acc 0.701\n",
      "==> 103 (93, 100)\n",
      "performing detection at epoch 103\n",
      "No attack detected!\n",
      "e 103 benign_norm 567.338 val loss 0.877 val acc 0.706 best val_acc 0.706\n",
      "==> 104 (94, 100)\n",
      "performing detection at epoch 104\n",
      "No attack detected!\n",
      "e 104 benign_norm 567.186 val loss 0.870 val acc 0.706 best val_acc 0.706\n",
      "==> 105 (95, 100)\n",
      "performing detection at epoch 105\n",
      "No attack detected!\n",
      "e 105 benign_norm 566.948 val loss 0.867 val acc 0.707 best val_acc 0.707\n",
      "==> 106 (96, 100)\n",
      "performing detection at epoch 106\n",
      "No attack detected!\n",
      "e 106 benign_norm 566.914 val loss 0.864 val acc 0.705 best val_acc 0.707\n",
      "==> 107 (97, 100)\n",
      "performing detection at epoch 107\n",
      "No attack detected!\n",
      "e 107 benign_norm 567.564 val loss 0.885 val acc 0.699 best val_acc 0.707\n",
      "==> 108 (98, 100)\n",
      "performing detection at epoch 108\n",
      "No attack detected!\n",
      "e 108 benign_norm 567.171 val loss 0.863 val acc 0.709 best val_acc 0.709\n",
      "==> 109 (99, 100)\n",
      "performing detection at epoch 109\n",
      "No attack detected!\n",
      "e 109 benign_norm 567.576 val loss 0.869 val acc 0.704 best val_acc 0.709\n",
      "==> 110 (100, 100)\n",
      "performing detection at epoch 110\n",
      "No attack detected!\n",
      "e 110 benign_norm 567.172 val loss 0.854 val acc 0.713 best val_acc 0.713\n",
      "==> 111 (101, 100)\n",
      "performing detection at epoch 111\n",
      "No attack detected!\n",
      "e 111 benign_norm 567.191 val loss 0.856 val acc 0.708 best val_acc 0.713\n",
      "==> 112 (102, 100)\n",
      "performing detection at epoch 112\n",
      "No attack detected!\n",
      "e 112 benign_norm 567.184 val loss 0.849 val acc 0.714 best val_acc 0.714\n",
      "==> 113 (103, 100)\n",
      "performing detection at epoch 113\n",
      "No attack detected!\n",
      "e 113 benign_norm 567.432 val loss 0.846 val acc 0.714 best val_acc 0.714\n",
      "==> 114 (104, 100)\n",
      "performing detection at epoch 114\n",
      "No attack detected!\n",
      "e 114 benign_norm 567.170 val loss 0.839 val acc 0.715 best val_acc 0.715\n",
      "==> 115 (105, 100)\n",
      "performing detection at epoch 115\n",
      "No attack detected!\n",
      "e 115 benign_norm 567.262 val loss 0.846 val acc 0.713 best val_acc 0.715\n",
      "==> 116 (106, 100)\n",
      "performing detection at epoch 116\n",
      "No attack detected!\n",
      "e 116 benign_norm 567.282 val loss 0.835 val acc 0.717 best val_acc 0.717\n",
      "==> 117 (107, 100)\n",
      "performing detection at epoch 117\n",
      "No attack detected!\n",
      "e 117 benign_norm 566.990 val loss 0.835 val acc 0.719 best val_acc 0.719\n",
      "==> 118 (108, 100)\n",
      "performing detection at epoch 118\n",
      "No attack detected!\n",
      "e 118 benign_norm 567.284 val loss 0.837 val acc 0.717 best val_acc 0.719\n",
      "==> 119 (109, 100)\n",
      "performing detection at epoch 119\n",
      "No attack detected!\n",
      "e 119 benign_norm 567.092 val loss 0.832 val acc 0.717 best val_acc 0.719\n",
      "==> 120 (110, 100)\n",
      "performing detection at epoch 120\n",
      "No attack detected!\n",
      "e 120 benign_norm 567.544 val loss 0.832 val acc 0.716 best val_acc 0.719\n",
      "==> 121 (111, 100)\n",
      "performing detection at epoch 121\n",
      "No attack detected!\n",
      "e 121 benign_norm 567.338 val loss 0.827 val acc 0.719 best val_acc 0.719\n",
      "==> 122 (112, 100)\n",
      "performing detection at epoch 122\n",
      "No attack detected!\n",
      "e 122 benign_norm 567.465 val loss 0.826 val acc 0.720 best val_acc 0.720\n",
      "==> 123 (113, 100)\n",
      "performing detection at epoch 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 123 benign_norm 567.427 val loss 0.822 val acc 0.721 best val_acc 0.721\n",
      "==> 124 (114, 100)\n",
      "performing detection at epoch 124\n",
      "No attack detected!\n",
      "e 124 benign_norm 567.496 val loss 0.825 val acc 0.720 best val_acc 0.721\n",
      "==> 125 (115, 100)\n",
      "performing detection at epoch 125\n",
      "No attack detected!\n",
      "e 125 benign_norm 567.306 val loss 0.817 val acc 0.726 best val_acc 0.726\n",
      "==> 126 (116, 100)\n",
      "performing detection at epoch 126\n",
      "No attack detected!\n",
      "e 126 benign_norm 567.677 val loss 0.810 val acc 0.725 best val_acc 0.726\n",
      "==> 127 (117, 100)\n",
      "performing detection at epoch 127\n",
      "No attack detected!\n",
      "e 127 benign_norm 567.479 val loss 0.815 val acc 0.724 best val_acc 0.726\n",
      "==> 128 (118, 100)\n",
      "performing detection at epoch 128\n",
      "No attack detected!\n",
      "e 128 benign_norm 567.236 val loss 0.808 val acc 0.728 best val_acc 0.728\n",
      "==> 129 (119, 100)\n",
      "performing detection at epoch 129\n",
      "No attack detected!\n",
      "e 129 benign_norm 567.317 val loss 0.812 val acc 0.728 best val_acc 0.728\n",
      "==> 130 (120, 100)\n",
      "performing detection at epoch 130\n",
      "No attack detected!\n",
      "e 130 benign_norm 567.739 val loss 0.808 val acc 0.729 best val_acc 0.729\n",
      "==> 131 (121, 100)\n",
      "performing detection at epoch 131\n",
      "No attack detected!\n",
      "e 131 benign_norm 567.680 val loss 0.798 val acc 0.734 best val_acc 0.734\n",
      "==> 132 (122, 100)\n",
      "performing detection at epoch 132\n",
      "No attack detected!\n",
      "e 132 benign_norm 567.737 val loss 0.805 val acc 0.731 best val_acc 0.734\n",
      "==> 133 (123, 100)\n",
      "performing detection at epoch 133\n",
      "No attack detected!\n",
      "e 133 benign_norm 567.795 val loss 0.804 val acc 0.731 best val_acc 0.734\n",
      "==> 134 (124, 100)\n",
      "performing detection at epoch 134\n",
      "No attack detected!\n",
      "e 134 benign_norm 567.462 val loss 0.801 val acc 0.733 best val_acc 0.734\n",
      "==> 135 (125, 100)\n",
      "performing detection at epoch 135\n",
      "No attack detected!\n",
      "e 135 benign_norm 567.664 val loss 0.791 val acc 0.734 best val_acc 0.734\n",
      "==> 136 (126, 100)\n",
      "performing detection at epoch 136\n",
      "No attack detected!\n",
      "e 136 benign_norm 567.759 val loss 0.793 val acc 0.732 best val_acc 0.734\n",
      "==> 137 (127, 100)\n",
      "performing detection at epoch 137\n",
      "No attack detected!\n",
      "e 137 benign_norm 567.769 val loss 0.788 val acc 0.737 best val_acc 0.737\n",
      "==> 138 (128, 100)\n",
      "performing detection at epoch 138\n",
      "No attack detected!\n",
      "e 138 benign_norm 568.055 val loss 0.795 val acc 0.733 best val_acc 0.737\n",
      "==> 139 (129, 100)\n",
      "performing detection at epoch 139\n",
      "No attack detected!\n",
      "e 139 benign_norm 567.740 val loss 0.783 val acc 0.737 best val_acc 0.737\n",
      "==> 140 (130, 100)\n",
      "performing detection at epoch 140\n",
      "No attack detected!\n",
      "e 140 benign_norm 568.069 val loss 0.780 val acc 0.735 best val_acc 0.737\n",
      "==> 141 (131, 100)\n",
      "performing detection at epoch 141\n",
      "No attack detected!\n",
      "e 141 benign_norm 568.208 val loss 0.790 val acc 0.737 best val_acc 0.737\n",
      "==> 142 (132, 100)\n",
      "performing detection at epoch 142\n",
      "No attack detected!\n",
      "e 142 benign_norm 567.464 val loss 0.776 val acc 0.738 best val_acc 0.738\n",
      "==> 143 (133, 100)\n",
      "performing detection at epoch 143\n",
      "No attack detected!\n",
      "e 143 benign_norm 567.661 val loss 0.780 val acc 0.739 best val_acc 0.739\n",
      "==> 144 (134, 100)\n",
      "performing detection at epoch 144\n",
      "No attack detected!\n",
      "e 144 benign_norm 567.513 val loss 0.768 val acc 0.738 best val_acc 0.739\n",
      "==> 145 (135, 100)\n",
      "performing detection at epoch 145\n",
      "No attack detected!\n",
      "e 145 benign_norm 567.932 val loss 0.774 val acc 0.738 best val_acc 0.739\n",
      "==> 146 (136, 100)\n",
      "performing detection at epoch 146\n",
      "No attack detected!\n",
      "e 146 benign_norm 567.777 val loss 0.774 val acc 0.739 best val_acc 0.739\n",
      "==> 147 (137, 100)\n",
      "performing detection at epoch 147\n",
      "No attack detected!\n",
      "e 147 benign_norm 567.648 val loss 0.772 val acc 0.744 best val_acc 0.744\n",
      "==> 148 (138, 100)\n",
      "performing detection at epoch 148\n",
      "No attack detected!\n",
      "e 148 benign_norm 567.585 val loss 0.769 val acc 0.743 best val_acc 0.744\n",
      "==> 149 (139, 100)\n",
      "performing detection at epoch 149\n",
      "No attack detected!\n",
      "e 149 benign_norm 567.632 val loss 0.769 val acc 0.740 best val_acc 0.744\n",
      "==> 150 (140, 100)\n",
      "performing detection at epoch 150\n",
      "No attack detected!\n",
      "e 150 benign_norm 567.729 val loss 0.760 val acc 0.745 best val_acc 0.745\n",
      "==> 151 (141, 100)\n",
      "performing detection at epoch 151\n",
      "No attack detected!\n",
      "e 151 benign_norm 567.936 val loss 0.759 val acc 0.746 best val_acc 0.746\n",
      "==> 152 (142, 100)\n",
      "performing detection at epoch 152\n",
      "No attack detected!\n",
      "e 152 benign_norm 567.974 val loss 0.763 val acc 0.744 best val_acc 0.746\n",
      "==> 153 (143, 100)\n",
      "performing detection at epoch 153\n",
      "No attack detected!\n",
      "e 153 benign_norm 567.616 val loss 0.765 val acc 0.743 best val_acc 0.746\n",
      "==> 154 (144, 100)\n",
      "performing detection at epoch 154\n",
      "No attack detected!\n",
      "e 154 benign_norm 567.771 val loss 0.759 val acc 0.745 best val_acc 0.746\n",
      "==> 155 (145, 100)\n",
      "performing detection at epoch 155\n",
      "No attack detected!\n",
      "e 155 benign_norm 567.706 val loss 0.759 val acc 0.747 best val_acc 0.747\n",
      "==> 156 (146, 100)\n",
      "performing detection at epoch 156\n",
      "No attack detected!\n",
      "e 156 benign_norm 567.349 val loss 0.754 val acc 0.746 best val_acc 0.747\n",
      "==> 157 (147, 100)\n",
      "performing detection at epoch 157\n",
      "No attack detected!\n",
      "e 157 benign_norm 567.578 val loss 0.753 val acc 0.749 best val_acc 0.749\n",
      "==> 158 (148, 100)\n",
      "performing detection at epoch 158\n",
      "No attack detected!\n",
      "e 158 benign_norm 567.883 val loss 0.750 val acc 0.749 best val_acc 0.749\n",
      "==> 159 (149, 100)\n",
      "performing detection at epoch 159\n",
      "No attack detected!\n",
      "e 159 benign_norm 567.570 val loss 0.751 val acc 0.747 best val_acc 0.749\n",
      "==> 160 (150, 100)\n",
      "performing detection at epoch 160\n",
      "No attack detected!\n",
      "e 160 benign_norm 567.518 val loss 0.752 val acc 0.747 best val_acc 0.749\n",
      "==> 161 (151, 100)\n",
      "performing detection at epoch 161\n",
      "No attack detected!\n",
      "e 161 benign_norm 567.922 val loss 0.747 val acc 0.751 best val_acc 0.751\n",
      "==> 162 (152, 100)\n",
      "performing detection at epoch 162\n",
      "No attack detected!\n",
      "e 162 benign_norm 567.628 val loss 0.744 val acc 0.752 best val_acc 0.752\n",
      "==> 163 (153, 100)\n",
      "performing detection at epoch 163\n",
      "No attack detected!\n",
      "e 163 benign_norm 567.946 val loss 0.740 val acc 0.754 best val_acc 0.754\n",
      "==> 164 (154, 100)\n",
      "performing detection at epoch 164\n",
      "No attack detected!\n",
      "e 164 benign_norm 567.606 val loss 0.743 val acc 0.751 best val_acc 0.754\n",
      "==> 165 (155, 100)\n",
      "performing detection at epoch 165\n",
      "No attack detected!\n",
      "e 165 benign_norm 567.826 val loss 0.743 val acc 0.750 best val_acc 0.754\n",
      "==> 166 (156, 100)\n",
      "performing detection at epoch 166\n",
      "No attack detected!\n",
      "e 166 benign_norm 567.400 val loss 0.739 val acc 0.750 best val_acc 0.754\n",
      "==> 167 (157, 100)\n",
      "performing detection at epoch 167\n",
      "No attack detected!\n",
      "e 167 benign_norm 567.580 val loss 0.739 val acc 0.755 best val_acc 0.755\n",
      "==> 168 (158, 100)\n",
      "performing detection at epoch 168\n",
      "No attack detected!\n",
      "e 168 benign_norm 567.509 val loss 0.736 val acc 0.755 best val_acc 0.755\n",
      "==> 169 (159, 100)\n",
      "performing detection at epoch 169\n",
      "No attack detected!\n",
      "e 169 benign_norm 567.466 val loss 0.740 val acc 0.753 best val_acc 0.755\n",
      "==> 170 (160, 100)\n",
      "performing detection at epoch 170\n",
      "No attack detected!\n",
      "e 170 benign_norm 567.821 val loss 0.739 val acc 0.753 best val_acc 0.755\n",
      "==> 171 (161, 100)\n",
      "performing detection at epoch 171\n",
      "No attack detected!\n",
      "e 171 benign_norm 567.509 val loss 0.734 val acc 0.756 best val_acc 0.756\n",
      "==> 172 (162, 100)\n",
      "performing detection at epoch 172\n",
      "No attack detected!\n",
      "e 172 benign_norm 567.642 val loss 0.733 val acc 0.758 best val_acc 0.758\n",
      "==> 173 (163, 100)\n",
      "performing detection at epoch 173\n",
      "No attack detected!\n",
      "e 173 benign_norm 567.206 val loss 0.729 val acc 0.758 best val_acc 0.758\n",
      "==> 174 (164, 100)\n",
      "performing detection at epoch 174\n",
      "No attack detected!\n",
      "e 174 benign_norm 567.631 val loss 0.733 val acc 0.756 best val_acc 0.758\n",
      "==> 175 (165, 100)\n",
      "performing detection at epoch 175\n",
      "No attack detected!\n",
      "e 175 benign_norm 567.845 val loss 0.730 val acc 0.758 best val_acc 0.758\n",
      "==> 176 (166, 100)\n",
      "performing detection at epoch 176\n",
      "No attack detected!\n",
      "e 176 benign_norm 567.363 val loss 0.728 val acc 0.758 best val_acc 0.758\n",
      "==> 177 (167, 100)\n",
      "performing detection at epoch 177\n",
      "No attack detected!\n",
      "e 177 benign_norm 567.432 val loss 0.733 val acc 0.755 best val_acc 0.758\n",
      "==> 178 (168, 100)\n",
      "performing detection at epoch 178\n",
      "No attack detected!\n",
      "e 178 benign_norm 567.609 val loss 0.723 val acc 0.760 best val_acc 0.760\n",
      "==> 179 (169, 100)\n",
      "performing detection at epoch 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 179 benign_norm 567.617 val loss 0.725 val acc 0.759 best val_acc 0.760\n",
      "==> 180 (170, 100)\n",
      "performing detection at epoch 180\n",
      "No attack detected!\n",
      "e 180 benign_norm 567.984 val loss 0.726 val acc 0.760 best val_acc 0.760\n",
      "==> 181 (171, 100)\n",
      "performing detection at epoch 181\n",
      "No attack detected!\n",
      "e 181 benign_norm 567.981 val loss 0.722 val acc 0.761 best val_acc 0.761\n",
      "==> 182 (172, 100)\n",
      "performing detection at epoch 182\n",
      "No attack detected!\n",
      "e 182 benign_norm 567.750 val loss 0.720 val acc 0.765 best val_acc 0.765\n",
      "==> 183 (173, 100)\n",
      "performing detection at epoch 183\n",
      "No attack detected!\n",
      "e 183 benign_norm 567.506 val loss 0.717 val acc 0.764 best val_acc 0.765\n",
      "==> 184 (174, 100)\n",
      "performing detection at epoch 184\n",
      "No attack detected!\n",
      "e 184 benign_norm 567.867 val loss 0.715 val acc 0.768 best val_acc 0.768\n",
      "==> 185 (175, 100)\n",
      "performing detection at epoch 185\n",
      "No attack detected!\n",
      "e 185 benign_norm 567.413 val loss 0.723 val acc 0.762 best val_acc 0.768\n",
      "==> 186 (176, 100)\n",
      "performing detection at epoch 186\n",
      "No attack detected!\n",
      "e 186 benign_norm 567.710 val loss 0.713 val acc 0.767 best val_acc 0.768\n",
      "==> 187 (177, 100)\n",
      "performing detection at epoch 187\n",
      "No attack detected!\n",
      "e 187 benign_norm 567.499 val loss 0.716 val acc 0.764 best val_acc 0.768\n",
      "==> 188 (178, 100)\n",
      "performing detection at epoch 188\n",
      "No attack detected!\n",
      "e 188 benign_norm 567.384 val loss 0.710 val acc 0.767 best val_acc 0.768\n",
      "==> 189 (179, 100)\n",
      "performing detection at epoch 189\n",
      "No attack detected!\n",
      "e 189 benign_norm 567.757 val loss 0.711 val acc 0.767 best val_acc 0.768\n",
      "==> 190 (180, 100)\n",
      "performing detection at epoch 190\n",
      "No attack detected!\n",
      "e 190 benign_norm 567.567 val loss 0.711 val acc 0.767 best val_acc 0.768\n",
      "==> 191 (181, 100)\n",
      "performing detection at epoch 191\n",
      "No attack detected!\n",
      "e 191 benign_norm 567.802 val loss 0.716 val acc 0.765 best val_acc 0.768\n",
      "==> 192 (182, 100)\n",
      "performing detection at epoch 192\n",
      "No attack detected!\n",
      "e 192 benign_norm 567.702 val loss 0.709 val acc 0.769 best val_acc 0.769\n",
      "==> 193 (183, 100)\n",
      "performing detection at epoch 193\n",
      "No attack detected!\n",
      "e 193 benign_norm 567.749 val loss 0.706 val acc 0.769 best val_acc 0.769\n",
      "==> 194 (184, 100)\n",
      "performing detection at epoch 194\n",
      "No attack detected!\n",
      "e 194 benign_norm 567.795 val loss 0.699 val acc 0.771 best val_acc 0.771\n",
      "==> 195 (185, 100)\n",
      "performing detection at epoch 195\n",
      "No attack detected!\n",
      "e 195 benign_norm 567.771 val loss 0.704 val acc 0.769 best val_acc 0.771\n",
      "==> 196 (186, 100)\n",
      "performing detection at epoch 196\n",
      "No attack detected!\n",
      "e 196 benign_norm 567.633 val loss 0.705 val acc 0.768 best val_acc 0.771\n",
      "==> 197 (187, 100)\n",
      "performing detection at epoch 197\n",
      "No attack detected!\n",
      "e 197 benign_norm 567.364 val loss 0.700 val acc 0.771 best val_acc 0.771\n",
      "==> 198 (188, 100)\n",
      "performing detection at epoch 198\n",
      "No attack detected!\n",
      "e 198 benign_norm 567.371 val loss 0.702 val acc 0.771 best val_acc 0.771\n",
      "==> 199 (189, 100)\n",
      "performing detection at epoch 199\n",
      "No attack detected!\n",
      "e 199 benign_norm 567.445 val loss 0.700 val acc 0.768 best val_acc 0.771\n",
      "==> 200 (190, 100)\n",
      "performing detection at epoch 200\n",
      "No attack detected!\n",
      "e 200 benign_norm 567.698 val loss 0.701 val acc 0.769 best val_acc 0.771\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 2\n",
    "batch_size = 8\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = .1\n",
    "fast_baseline = True\n",
    "global_lr = 1\n",
    "global_decay_factor = 1\n",
    "nepochs = 200\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='dirichlet'\n",
    "param = .1\n",
    "force = True\n",
    "# each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "#     all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, batch_size)))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "attack_type = 'none'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "        if fast_baseline:\n",
    "            optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.999**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        else:\n",
    "            optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        user_grads = full_trim(user_grads, nbyz)\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                print(\"LIE\")\n",
    "                z = 0.01\n",
    "                noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_avg + z * noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "    agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "#     agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    \n",
    "    model_received = model_received + global_lr * (global_decay_factor ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9bec0",
   "metadata": {},
   "source": [
    "# Dirichlet + FLDetector + trim attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .9\n",
    "force = True\n",
    "each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "    all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "attack_type = 'none'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = []\n",
    "    for param in model.parameters():\n",
    "        weight=param.grad.data.view(-1) if not len(weight) else torch.cat((weight,param.grad.view(-1)))\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        user_grads = full_trim(user_grads, nbyz)\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                print(\"LIE\")\n",
    "                z = 0.01\n",
    "                noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_avg + z * noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "    agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "#     agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
