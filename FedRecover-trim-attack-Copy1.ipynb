{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbef18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from functools import reduce\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'./utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from SGD import *\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934d4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "bias = 0.5\n",
    "net = 'cnn'\n",
    "batch_size = 32\n",
    "# lr = 0.0002\n",
    "lr = 3e-4\n",
    "# lr = 0.01\n",
    "nworkers = 100\n",
    "nepochs = 2000\n",
    "gpu = 3\n",
    "seed = 41\n",
    "nbyz = 28\n",
    "byz_type = 'full_trim'\n",
    "aggregation = 'median'\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b05be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs(S_k_list, Y_k_list, v):\n",
    "    curr_S_k = torch.stack(S_k_list).T\n",
    "    curr_Y_k = torch.stack(Y_k_list).T\n",
    "    S_k_time_Y_k = np.dot(curr_S_k.T.cpu().numpy(), curr_Y_k.cpu().numpy())\n",
    "    S_k_time_S_k = np.dot(curr_S_k.T.cpu().numpy(), curr_S_k.cpu().numpy())\n",
    "    R_k = np.triu(S_k_time_Y_k)\n",
    "    L_k = S_k_time_Y_k - R_k\n",
    "    sigma_k = np.dot(Y_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()) / (np.dot(S_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()))\n",
    "    D_k_diag = np.diag(S_k_time_Y_k)\n",
    "    upper_mat = np.concatenate((sigma_k * S_k_time_S_k, L_k), axis=1)\n",
    "    lower_mat = np.concatenate((L_k.T, -np.diag(D_k_diag)), axis=1)\n",
    "    mat = np.concatenate((upper_mat, lower_mat), axis=0)\n",
    "    mat_inv = np.linalg.inv(mat)\n",
    "\n",
    "    approx_prod = sigma_k * v.cpu().numpy()\n",
    "    approx_prod = approx_prod.T\n",
    "    p_mat = np.concatenate((np.dot(curr_S_k.T.cpu().numpy(), sigma_k * v.unsqueeze(0).T.cpu().numpy()), np.dot(curr_Y_k.T.cpu().numpy(), v.unsqueeze(0).T.cpu().numpy())), axis=0)\n",
    "    approx_prod -= np.dot(np.dot(np.concatenate((sigma_k * curr_S_k.cpu().numpy(), curr_Y_k.cpu().numpy()), axis=1), mat_inv), p_mat)\n",
    "\n",
    "    return approx_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290415a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(30, 50, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(800, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e35368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_trim(v, f):\n",
    "    '''\n",
    "    Full-knowledge Trim attack. w.l.o.g., we assume the first f worker devices are compromised.\n",
    "    v: the list of squeezed gradients\n",
    "    f: the number of compromised worker devices\n",
    "    '''\n",
    "    # first compute the statistics\n",
    "    vi_shape = v[0].unsqueeze(0).T.shape\n",
    "    v_tran = v.T\n",
    "#     v_tran = nd.concat(*v, dim=1)\n",
    "    \n",
    "    maximum_dim = torch.max(v_tran, dim=1)\n",
    "    maximum_dim = maximum_dim[0].reshape(vi_shape)\n",
    "    minimum_dim = torch.min(v_tran, dim=1)\n",
    "    minimum_dim = minimum_dim[0].reshape(vi_shape)\n",
    "    direction = torch.sign(torch.sum(v_tran, dim=-1, keepdims=True))\n",
    "    directed_dim = (direction > 0) * minimum_dim + (direction < 0) * maximum_dim\n",
    "\n",
    "    for i in range(20):\n",
    "        # apply attack to compromised worker devices with randomness\n",
    "        random_12 = 2\n",
    "        tmp = directed_dim * ((direction * directed_dim > 0) / random_12 + (direction * directed_dim < 0) * random_12)\n",
    "        tmp = tmp.squeeze()\n",
    "        v[i] = tmp\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2f5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_mean(all_updates, n_attackers):\n",
    "    sorted_updates = torch.sort(all_updates, 0)[0]\n",
    "    out = torch.mean(sorted_updates[n_attackers:-n_attackers], 0) if n_attackers else torch.mean(sorted_updates,0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ced92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = nworkers\n",
    "epochs = nepochs\n",
    "grad_list = []\n",
    "old_grad_list = []\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "train_acc_list = []\n",
    "distance1 = []\n",
    "distance2 = []\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c258374",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_data = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_data = torch.utils.data.DataLoader(testset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375852a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_train_data(trainset, num_workers=100, bias=0.5):\n",
    "\n",
    "    bias_weight = bias\n",
    "    other_group_size = (1 - bias_weight) / 9.\n",
    "    worker_per_group = num_workers / 10\n",
    "\n",
    "    each_worker_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_label = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    for i, (x, y) in enumerate(trainset):\n",
    "        # assign a data point to a group\n",
    "        upper_bound = (y) * (1 - bias_weight) / 9. + bias_weight\n",
    "        lower_bound = (y) * (1 - bias_weight) / 9.\n",
    "        rd = np.random.random_sample()\n",
    "\n",
    "        if rd > upper_bound:\n",
    "            worker_group = int(np.floor((rd - upper_bound) / other_group_size) + y + 1)\n",
    "        elif rd < lower_bound:\n",
    "            worker_group = int(np.floor(rd / other_group_size))\n",
    "        else:\n",
    "            worker_group = y\n",
    "\n",
    "        # assign a data point to a worker\n",
    "        rd = np.random.random_sample()\n",
    "        selected_worker = int(worker_group * worker_per_group + int(np.floor(rd * worker_per_group)))\n",
    "        \n",
    "        if not len(each_worker_data[selected_worker]):\n",
    "            each_worker_data[selected_worker] = x[None, :]\n",
    "        else:\n",
    "            each_worker_data[selected_worker]= torch.concat((each_worker_data[selected_worker], x[None, :]))\n",
    "        \n",
    "        each_worker_label[selected_worker].append(y)\n",
    "    \n",
    "    return each_worker_data, each_worker_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b97476",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_worker_data, each_worker_label = get_client_train_data(trainset, num_workers=100, bias=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33ec087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1407\n",
      "1 0.2\n",
      "2 0.2397\n",
      "3 0.2736\n",
      "4 0.3128\n",
      "5 0.3641\n",
      "6 0.4177\n",
      "7 0.4773\n",
      "8 0.529\n",
      "9 0.5673\n",
      "10 0.598\n",
      "11 0.6177\n",
      "12 0.6391\n",
      "13 0.6554\n",
      "14 0.673\n",
      "15 0.6848\n",
      "16 0.6986\n",
      "17 0.7077\n",
      "18 0.715\n",
      "19 0.722\n",
      "20 0.7276\n",
      "21 0.7315\n",
      "22 0.7344\n",
      "23 0.7371\n",
      "24 0.7373\n",
      "25 0.7356\n",
      "26 0.7356\n",
      "27 0.7351\n",
      "28 0.7335\n",
      "29 0.7316\n",
      "30 0.7307\n",
      "31 0.731\n",
      "32 0.7304\n",
      "33 0.732\n",
      "34 0.734\n",
      "35 0.7366\n",
      "36 0.7408\n",
      "37 0.7438\n",
      "38 0.7485\n",
      "39 0.7525\n",
      "40 0.7573\n",
      "41 0.7617\n",
      "42 0.7644\n",
      "43 0.7678\n",
      "44 0.7715\n",
      "45 0.774\n",
      "46 0.7774\n",
      "47 0.7795\n",
      "48 0.7822\n",
      "49 0.7847\n",
      "50 0.7881\n",
      "51 0.7911\n",
      "52 0.7935\n",
      "53 0.7963\n",
      "54 0.7983\n",
      "55 0.7993\n",
      "56 0.8016\n",
      "57 0.8029\n",
      "58 0.8051\n",
      "59 0.8069\n",
      "60 0.8096\n",
      "61 0.8116\n",
      "62 0.8127\n",
      "63 0.8141\n",
      "64 0.815\n",
      "65 0.8164\n",
      "66 0.8173\n",
      "67 0.8181\n",
      "68 0.8182\n",
      "69 0.8192\n",
      "70 0.82\n",
      "71 0.8206\n",
      "72 0.8215\n",
      "73 0.8225\n",
      "74 0.8224\n",
      "75 0.8221\n",
      "76 0.8226\n",
      "77 0.8228\n",
      "78 0.8232\n",
      "79 0.8234\n",
      "80 0.8236\n",
      "81 0.8239\n",
      "82 0.8245\n",
      "83 0.825\n",
      "84 0.825\n",
      "85 0.8253\n",
      "86 0.8254\n",
      "87 0.8257\n",
      "88 0.8261\n",
      "89 0.8264\n",
      "90 0.8266\n",
      "91 0.8267\n",
      "92 0.8268\n",
      "93 0.8268\n",
      "94 0.8267\n",
      "95 0.8267\n",
      "96 0.8269\n",
      "97 0.827\n",
      "98 0.827\n",
      "99 0.8273\n",
      "100 0.8277\n",
      "101 0.8283\n",
      "102 0.8285\n",
      "103 0.8287\n",
      "104 0.8289\n",
      "105 0.8289\n",
      "106 0.8292\n",
      "107 0.8295\n",
      "108 0.8297\n",
      "109 0.8297\n",
      "110 0.8298\n",
      "111 0.8301\n",
      "112 0.8302\n",
      "113 0.8304\n",
      "114 0.8306\n",
      "115 0.8308\n",
      "116 0.8307\n",
      "117 0.8309\n",
      "118 0.831\n",
      "119 0.831\n",
      "120 0.831\n",
      "121 0.8311\n",
      "122 0.8311\n",
      "123 0.8312\n",
      "124 0.8312\n",
      "125 0.8312\n",
      "126 0.8312\n",
      "127 0.8312\n",
      "128 0.8312\n",
      "129 0.8312\n",
      "130 0.8312\n",
      "131 0.831\n",
      "132 0.831\n",
      "133 0.831\n",
      "134 0.831\n",
      "135 0.8311\n",
      "136 0.8311\n",
      "137 0.8312\n",
      "138 0.8312\n",
      "139 0.8314\n",
      "140 0.8314\n",
      "141 0.8314\n",
      "142 0.8314\n",
      "143 0.8315\n",
      "144 0.8316\n",
      "145 0.8317\n",
      "146 0.8317\n",
      "147 0.8317\n",
      "148 0.8317\n",
      "149 0.8317\n",
      "150 0.8317\n",
      "151 0.8318\n",
      "152 0.8318\n",
      "153 0.8318\n",
      "154 0.8318\n",
      "155 0.8319\n",
      "156 0.832\n",
      "157 0.832\n",
      "158 0.832\n",
      "159 0.832\n",
      "160 0.832\n",
      "161 0.832\n",
      "162 0.832\n",
      "163 0.8321\n",
      "164 0.8321\n",
      "165 0.8321\n",
      "166 0.8321\n",
      "167 0.8321\n",
      "168 0.8322\n",
      "169 0.8322\n",
      "170 0.8322\n",
      "171 0.8322\n",
      "172 0.8322\n",
      "173 0.8322\n",
      "174 0.8322\n",
      "175 0.8322\n",
      "176 0.8322\n",
      "177 0.8323\n",
      "178 0.8323\n",
      "179 0.8323\n",
      "180 0.8323\n",
      "181 0.8323\n",
      "182 0.8323\n",
      "183 0.8323\n",
      "184 0.8323\n",
      "185 0.8323\n",
      "186 0.8323\n",
      "187 0.8323\n",
      "188 0.8323\n",
      "189 0.8323\n",
      "190 0.8323\n",
      "191 0.8323\n",
      "192 0.8323\n",
      "193 0.8323\n",
      "194 0.8323\n",
      "195 0.8323\n",
      "196 0.8323\n",
      "197 0.8323\n",
      "198 0.8323\n",
      "199 0.8323\n",
      "200 0.8323\n",
      "201 0.8323\n",
      "202 0.8323\n",
      "203 0.8323\n",
      "204 0.8323\n",
      "205 0.8323\n",
      "206 0.8323\n",
      "207 0.8323\n",
      "208 0.8323\n",
      "209 0.8323\n",
      "210 0.8323\n",
      "211 0.8323\n",
      "212 0.8323\n",
      "213 0.8323\n",
      "214 0.8323\n",
      "215 0.8323\n",
      "216 0.8323\n",
      "217 0.8323\n",
      "218 0.8323\n",
      "219 0.8323\n",
      "220 0.8323\n",
      "221 0.8323\n",
      "222 0.8323\n",
      "223 0.8323\n",
      "224 0.8323\n",
      "225 0.8323\n",
      "226 0.8323\n",
      "227 0.8323\n",
      "228 0.8323\n",
      "229 0.8323\n",
      "230 0.8323\n",
      "231 0.8323\n",
      "232 0.8323\n",
      "233 0.8323\n",
      "234 0.8323\n",
      "235 0.8323\n",
      "236 0.8323\n",
      "237 0.8323\n",
      "238 0.8323\n",
      "239 0.8323\n",
      "240 0.8323\n",
      "241 0.8323\n",
      "242 0.8323\n",
      "243 0.8323\n",
      "244 0.8323\n",
      "245 0.8323\n",
      "246 0.8324\n",
      "247 0.8324\n",
      "248 0.8324\n",
      "249 0.8323\n",
      "250 0.8323\n",
      "251 0.8323\n",
      "252 0.8323\n",
      "253 0.8324\n",
      "254 0.8323\n",
      "255 0.8323\n",
      "256 0.8324\n",
      "257 0.8324\n",
      "258 0.8324\n",
      "259 0.8324\n",
      "260 0.8324\n",
      "261 0.8324\n",
      "262 0.8324\n",
      "263 0.8324\n",
      "264 0.8324\n",
      "265 0.8324\n",
      "266 0.8324\n",
      "267 0.8324\n",
      "268 0.8324\n",
      "269 0.8324\n",
      "270 0.8324\n",
      "271 0.8323\n",
      "272 0.8324\n",
      "273 0.8324\n",
      "274 0.8324\n",
      "275 0.8324\n",
      "276 0.8324\n",
      "277 0.8324\n",
      "278 0.8324\n",
      "279 0.8324\n",
      "280 0.8324\n",
      "281 0.8324\n",
      "282 0.8324\n",
      "283 0.8324\n",
      "284 0.8324\n",
      "285 0.8324\n",
      "286 0.8324\n",
      "287 0.8324\n",
      "288 0.8324\n",
      "289 0.8324\n",
      "290 0.8324\n",
      "291 0.8324\n",
      "292 0.8324\n",
      "293 0.8324\n",
      "294 0.8324\n",
      "295 0.8324\n",
      "296 0.8324\n",
      "297 0.8324\n",
      "298 0.8324\n",
      "299 0.8324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_global_models = []\n",
    "saved_client_updates = [[] for _ in range(num_workers)]\n",
    "path_to_save_models = '/work/vshejwalkar_umass_edu/fedrecover_models/fedrecover_mnist/original_setting'\n",
    "if not os.path.exists(path_to_save_models):\n",
    "    os.makedirs(path_to_save_models)\n",
    "\n",
    "fed_model = cnn().to(device)\n",
    "recovery_fed_model = copy.deepcopy(fed_model)\n",
    "lr = .15\n",
    "n_epochs = 300\n",
    "for epoch in range(n_epochs):\n",
    "    received_model = []\n",
    "    for param in fed_model.parameters():\n",
    "        received_model = param.data.view(-1) if not len(received_model) else torch.cat((received_model, param.data.view(-1)))\n",
    "    # saved_global_models.append(received_model)\n",
    "\n",
    "    global_optimizer = SGD(fed_model.parameters(), lr = lr*(0.96**epoch))\n",
    "\n",
    "    user_grads = []\n",
    "    for i in range(100):\n",
    "        local_model = copy.deepcopy(fed_model)\n",
    "        local_model.zero_grad()\n",
    "        output = local_model(each_worker_data[i].to(device))\n",
    "        loss = criterion(output, torch.Tensor(each_worker_label[i]).long().to(device))\n",
    "        # backward\n",
    "        loss.backward(retain_graph = True)\n",
    "        # save params\n",
    "        param_grad=[]\n",
    "        for param in local_model.parameters():\n",
    "            param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "#         saved_client_updates[i].append(param_grad)\n",
    "        user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "        del local_model\n",
    "\n",
    "#     user_grads = full_trim(user_grads, 20)\n",
    "#     agg_grads = tr_mean(user_grads, 20)\n",
    "#     agg_grads=torch.median(user_grads,dim=0)[0]\n",
    "    agg_grads=torch.mean(user_grads,dim=0)\n",
    "\n",
    "    del user_grads\n",
    "    start_idx=0\n",
    "    global_optimizer.zero_grad()\n",
    "    model_grads=[]\n",
    "    for i, param in enumerate(fed_model.parameters()):\n",
    "        param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "        start_idx=start_idx+len(param.data.view(-1))\n",
    "#         param_=param_.cuda()\n",
    "        model_grads.append(param_)\n",
    "\n",
    "    global_optimizer.step(model_grads)\n",
    "\n",
    "    total, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(test_data):\n",
    "            inputs, labels = data.to(device), labels.to(device)\n",
    "            outputs = fed_model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(epoch, correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24f9810f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f88a8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    # apply attack to compromised worker devices with randomness\n",
    "    random_12 = 2\n",
    "    tmp = directed_dim * ((direction * directed_dim > 0) / random_12 + (direction * directed_dim < 0) * random_12)\n",
    "    tmp = tmp.squeeze()\n",
    "    v[i] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39f88fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7564\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_data):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8925bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1927\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_data):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_r(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71d46fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d77b7e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  5 15:25:47 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:40:00.0 Off |                  Off |\r\n",
      "| 33%   49C    P2    69W / 260W |  23602MiB / 49152MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A   2921844      C   ...nda/envs/myenv/bin/python    23599MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e06094",
   "metadata": {},
   "source": [
    "## Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de95f7",
   "metadata": {},
   "source": [
    "### Exact Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "144b27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tw=20\n",
    "buffer_models = []\n",
    "recovered_models = []\n",
    "buffer_clients = [[] for _ in range(num_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62a81da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_r.to(device)\n",
    "cnn_r_optimizer = SGD(net_r.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4a322c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1246\n",
      "0.1416\n",
      "0.1633\n",
      "0.2002\n",
      "0.2442\n",
      "0.2828\n",
      "0.3244\n",
      "0.3681\n",
      "0.4055\n",
      "0.4349\n",
      "0.4708\n",
      "0.504\n",
      "0.533\n",
      "0.5553\n",
      "0.5761\n",
      "0.5914\n",
      "0.6032\n",
      "0.6129\n",
      "0.6211\n",
      "0.6287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.12\n",
    "for e in range(Tw):\n",
    "    cnn_r_optimizer = SGD(net_r.parameters(), lr = lr*(0.96**e))\n",
    "    user_grads = []\n",
    "    # for each worker\n",
    "    for i in range(100):\n",
    "        net = copy.deepcopy(net_r)\n",
    "        running_loss = 0\n",
    "        # net_r.train()\n",
    "\n",
    "        net.zero_grad()\n",
    "        output = net(each_worker_data[i][:])\n",
    "        loss = criterion(output, each_worker_label[i][:])\n",
    "        \n",
    "        # backward\n",
    "        loss.backward(retain_graph = True)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        param_grad=[]\n",
    "        for param in net.parameters():\n",
    "            param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "        if (len(buffer_clients[i])==2):\n",
    "            buffer_clients[i].pop(0)\n",
    "        buffer_clients[i].append(param_grad - client_updates[i][e])\n",
    "        \n",
    "        \n",
    "        user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "        del net\n",
    "#         print(\"Client: {} Epoch: {}, Loss:{:.4f}\".format(i, e, running_loss))\n",
    "    \n",
    "    tmp = []\n",
    "    for param in net_r.parameters():\n",
    "        tmp = param.data.view(-1) if not len(tmp) else torch.cat((tmp, param.data.view(-1)))\n",
    "    #make copy instead of assignment\n",
    "    weight = tmp\n",
    "    \n",
    "    recovered_models.append(weight)\n",
    "    \n",
    "    if(e>0):\n",
    "        if(len(buffer_models) == 2):\n",
    "            buffer_models.pop(0)\n",
    "        buffer_models.append(weight - global_models[e])\n",
    "    \n",
    "   \n",
    "#     agg_grads=torch.median(user_grads,dim=0)[0]\n",
    "    agg_grads=torch.mean(user_grads,dim=0)\n",
    "    \n",
    "    del user_grads\n",
    "    \n",
    "    start_idx=0\n",
    "\n",
    "    cnn_r_optimizer.zero_grad()\n",
    "\n",
    "    model_grads=[]\n",
    "\n",
    "    for i, param in enumerate(net_r.parameters()):\n",
    "        param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "        start_idx=start_idx+len(param.data.view(-1))\n",
    "        param_=param_.cuda()\n",
    "        model_grads.append(param_)\n",
    "\n",
    "    cnn_r_optimizer.step(model_grads)\n",
    "    \n",
    "    total, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_data):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net_r(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f14b069f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeb2b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client_updates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ae22aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bf43409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer_clients[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb5c325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36002003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([453572])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(buffer_clients[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b416b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(buffer_models[0]))\n",
    "print(type(buffer_clients[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9603c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recovered_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8179a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated update\n",
      "0.635\n",
      "exact update\n",
      "0.6417\n",
      "estimated update\n",
      "0.6478\n",
      "estimated update\n",
      "0.6559\n",
      "exact update\n",
      "0.6622\n",
      "estimated update\n",
      "0.6681\n",
      "estimated update\n",
      "0.6732\n",
      "exact update\n",
      "0.6793\n",
      "estimated update\n",
      "0.6842\n",
      "estimated update\n",
      "0.6907\n",
      "exact update\n",
      "0.6953\n",
      "estimated update\n",
      "0.6995\n",
      "estimated update\n",
      "0.7021\n",
      "exact update\n",
      "0.7064\n",
      "estimated update\n",
      "0.7097\n",
      "estimated update\n",
      "0.7125\n",
      "exact update\n",
      "0.7149\n",
      "estimated update\n",
      "0.7176\n",
      "estimated update\n",
      "0.7192\n",
      "exact update\n",
      "0.7209\n",
      "estimated update\n",
      "0.7219\n",
      "estimated update\n",
      "0.7244\n",
      "exact update\n",
      "0.7254\n",
      "estimated update\n",
      "0.7272\n",
      "estimated update\n",
      "0.7274\n",
      "exact update\n",
      "0.7281\n",
      "estimated update\n",
      "0.7282\n",
      "estimated update\n",
      "0.7283\n",
      "exact update\n",
      "0.728\n",
      "estimated update\n",
      "0.7294\n"
     ]
    }
   ],
   "source": [
    "for e in range(Tw, Tw+30):\n",
    "    cnn_r_optimizer = SGD(net_r.parameters(), lr = lr*(0.96**e))\n",
    "    user_grads = []\n",
    "    if (e%3 != 0):\n",
    "        for i in range(100):\n",
    "#             print(e,i)\n",
    "            hvp = lbfgs(buffer_models, buffer_clients[i], recovered_models[-1]-global_models[e])\n",
    "            hvp = torch.tensor(np.squeeze(hvp))\n",
    "            model_update = client_updates[i][e] + hvp.to(device)\n",
    "            user_grads=model_update[None, :] if len(user_grads)==0 else torch.cat((user_grads,model_update[None,:]), 0)\n",
    "        print(\"estimated update\")\n",
    "    else:\n",
    "        for i in range(100):\n",
    "            running_loss = 0\n",
    "\n",
    "            output = net_r(each_worker_data[i][:])\n",
    "            loss = criterion(output, each_worker_label[i][:])\n",
    "            net_r.zero_grad()\n",
    "\n",
    "            # backward\n",
    "            loss.backward(retain_graph = True)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in net_r.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "            if (len(buffer_clients[i])==2):\n",
    "                buffer_clients[i].pop(0)\n",
    "            buffer_clients[i].append(param_grad - client_updates[i][e])\n",
    "\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "#             print(\"Client: {} Epoch: {}, Loss:{:.4f}\".format(i, e, running_loss))\n",
    "        print(\"exact update\")\n",
    "        \n",
    "        \n",
    "#     agg_grads=torch.median(user_grads,dim=0)[0]\n",
    "    agg_grads=torch.mean(user_grads,dim=0)\n",
    "    \n",
    "    \n",
    "    tmp = []\n",
    "    for param in net_r.parameters():\n",
    "        tmp = param.data.view(-1) if not len(tmp) else torch.cat((tmp, param.data.view(-1)))\n",
    "    weight = tmp\n",
    "    \n",
    "    recovered_models.append(weight)\n",
    "    \n",
    "    if(e%3==0):\n",
    "        if(len(buffer_models)==2):\n",
    "            buffer_models.pop(0)\n",
    "            buffer_models.append(weight - global_models[e])\n",
    "    \n",
    "    del user_grads\n",
    "    \n",
    "    start_idx=0\n",
    "    \n",
    "    model_grads=[]\n",
    "\n",
    "    for i, param in enumerate(net_r.parameters()):\n",
    "        param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "        start_idx=start_idx+len(param.data.view(-1))\n",
    "        param_=param_.cuda()\n",
    "        model_grads.append(param_)\n",
    "\n",
    "    cnn_r_optimizer.step(model_grads)\n",
    "    \n",
    "    total, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_data):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net_r(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f6d8bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_data):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_r(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffc040af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((10,20))\n",
    "print(torch.mean(x,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c183d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
