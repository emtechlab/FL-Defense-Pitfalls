{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e300ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gypsum-gpu124/4305876/ipykernel_1080319/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbef18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from functools import reduce\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.insert(0,'./utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from SGD import *\n",
    "import copy\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77aa30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models import *\n",
    "from cifar10_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d17e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26708069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dirichlet_train_data(trainset, no_participants, alpha=0.9, force=False):\n",
    "        \"\"\"\n",
    "            Input: Number of participants and alpha (param for distribution)\n",
    "            Output: A list of indices denoting data in CIFAR training set.\n",
    "            Requires: cifar_classes, a preprocessed class-indice dictionary.\n",
    "            Sample Method: take a uniformly sampled 10-dimension vector as parameters for\n",
    "            dirichlet distribution to sample number of images in each class.\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants)) or force:\n",
    "            print('generating participant indices for alpha %.1f'%alpha)\n",
    "            np.random.seed(0)\n",
    "            cifar_classes = {}\n",
    "            for ind, x in enumerate(trainset):\n",
    "                _, label = x\n",
    "                if label in cifar_classes:\n",
    "                    cifar_classes[label].append(ind)\n",
    "                else:\n",
    "                    cifar_classes[label] = [ind]\n",
    "\n",
    "            per_participant_list = defaultdict(list)\n",
    "            no_classes = len(cifar_classes.keys())\n",
    "            for n in range(no_classes):\n",
    "                random.shuffle(cifar_classes[n])\n",
    "                sampled_probabilities = len(cifar_classes[n]) * np.random.dirichlet(\n",
    "                    np.array(no_participants * [alpha]))\n",
    "                for user in range(no_participants):\n",
    "                    no_imgs = int(round(sampled_probabilities[user]))\n",
    "                    sampled_list = cifar_classes[n][:min(len(cifar_classes[n]), no_imgs)]\n",
    "                    per_participant_list[user].extend(sampled_list)\n",
    "                    cifar_classes[n] = cifar_classes[n][min(len(cifar_classes[n]), no_imgs):]\n",
    "            with open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'wb') as f:\n",
    "                pickle.dump(per_participant_list, f)\n",
    "        else:\n",
    "            per_participant_list = pickle.load(open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'rb'))\n",
    "\n",
    "        return per_participant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c258374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fang_train_data(trainset, num_workers=100, bias=0.5):\n",
    "    bias_weight = bias\n",
    "    other_group_size = (1 - bias_weight) / 9.\n",
    "    worker_per_group = num_workers / 10\n",
    "\n",
    "    each_worker_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_label = [[] for _ in range(num_workers)]\n",
    "    per_participant_list = defaultdict(list)\n",
    "    for i, (x, y) in enumerate(trainset):\n",
    "        # assign a data point to a group\n",
    "        upper_bound = (y) * (1 - bias_weight) / 9. + bias_weight\n",
    "        lower_bound = (y) * (1 - bias_weight) / 9.\n",
    "        rd = np.random.random_sample()\n",
    "\n",
    "        if rd > upper_bound:\n",
    "            worker_group = int(np.floor((rd - upper_bound) / other_group_size) + y + 1)\n",
    "        elif rd < lower_bound:\n",
    "            worker_group = int(np.floor(rd / other_group_size))\n",
    "        else:\n",
    "            worker_group = y\n",
    "\n",
    "        rd = np.random.random_sample()\n",
    "        selected_worker = int(worker_group * worker_per_group + int(np.floor(rd * worker_per_group)))\n",
    "        \n",
    "        per_participant_list[selected_worker].extend([i])\n",
    "    \n",
    "    return per_participant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799ffb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_federated_data(trainset, num_workers, distribution='fang', param=1, force=False):\n",
    "    if distribution == 'fang':\n",
    "        per_participant_list = get_fang_train_data(trainset, num_workers, bias=param)\n",
    "    elif distribution == 'dirichlet':\n",
    "        per_participant_list = sample_dirichlet_train_data(trainset, num_workers, alpha=param, force=force)\n",
    "\n",
    "    each_worker_idx = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    each_worker_te_idx = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    for worker_idx in range(len(per_participant_list)):\n",
    "        w_indices = np.array(per_participant_list[worker_idx])\n",
    "        w_len = len(w_indices)\n",
    "        len_tr = int(6*w_len/7)\n",
    "        tr_idx = np.random.choice(w_len, len_tr, replace=False)\n",
    "        te_idx = np.delete(np.arange(w_len), tr_idx)\n",
    "        \n",
    "        each_worker_idx[worker_idx] = w_indices[tr_idx]\n",
    "        each_worker_te_idx[worker_idx] = w_indices[te_idx]\n",
    "    \n",
    "    global_test_idx = np.concatenate(each_worker_te_idx)\n",
    "    \n",
    "    return each_worker_idx, each_worker_te_idx, global_test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2590db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(dataset, indices, batch_size=32, shuffle=False):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=torch.utils.data.sampler.SubsetRandomSampler(indices))\n",
    "    \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbb06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/home/vshejwalkar_umass_edu/data/'\n",
    "# load the train dataset\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=transform_train)\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=transform_train)\n",
    "\n",
    "te_cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=transform_test)\n",
    "te_cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b05be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs(S_k_list, Y_k_list, v):\n",
    "    curr_S_k = torch.stack(S_k_list).T\n",
    "    curr_Y_k = torch.stack(Y_k_list).T\n",
    "    S_k_time_Y_k = np.dot(curr_S_k.T.cpu().numpy(), curr_Y_k.cpu().numpy())\n",
    "    S_k_time_S_k = np.dot(curr_S_k.T.cpu().numpy(), curr_S_k.cpu().numpy())\n",
    "    R_k = np.triu(S_k_time_Y_k)\n",
    "    L_k = S_k_time_Y_k - R_k\n",
    "    sigma_k = np.dot(Y_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()) / (np.dot(S_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()))\n",
    "    D_k_diag = np.diag(S_k_time_Y_k)\n",
    "    upper_mat = np.concatenate((sigma_k * S_k_time_S_k, L_k), axis=1)\n",
    "    lower_mat = np.concatenate((L_k.T, -np.diag(D_k_diag)), axis=1)\n",
    "    mat = np.concatenate((upper_mat, lower_mat), axis=0)\n",
    "    mat_inv = np.linalg.inv(mat)\n",
    "\n",
    "    approx_prod = sigma_k * v.cpu().numpy()\n",
    "    approx_prod = approx_prod.T\n",
    "    p_mat = np.concatenate((np.dot(curr_S_k.T.cpu().numpy(), sigma_k * v.unsqueeze(0).T.cpu().numpy()), np.dot(curr_Y_k.T.cpu().numpy(), v.unsqueeze(0).T.cpu().numpy())), axis=0)\n",
    "    approx_prod -= np.dot(np.dot(np.concatenate((sigma_k * curr_S_k.cpu().numpy(), curr_Y_k.cpu().numpy()), axis=1), mat_inv), p_mat)\n",
    "\n",
    "    return approx_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e35368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_trim(v, f):\n",
    "    '''\n",
    "    Full-knowledge Trim attack. w.l.o.g., we assume the first f worker devices are compromised.\n",
    "    v: the list of squeezed gradients\n",
    "    f: the number of compromised worker devices\n",
    "    '''\n",
    "    vi_shape = v[0].unsqueeze(0).T.shape\n",
    "    v_tran = v.T\n",
    "    \n",
    "    maximum_dim = torch.max(v_tran, dim=1)\n",
    "    maximum_dim = maximum_dim[0].reshape(vi_shape)\n",
    "    minimum_dim = torch.min(v_tran, dim=1)\n",
    "    minimum_dim = minimum_dim[0].reshape(vi_shape)\n",
    "    direction = torch.sign(torch.sum(v_tran, dim=-1, keepdims=True))\n",
    "    directed_dim = (direction > 0) * minimum_dim + (direction < 0) * maximum_dim\n",
    "\n",
    "    for i in range(f):\n",
    "        random_12 = 2\n",
    "        tmp = directed_dim * ((direction * directed_dim > 0) / random_12 + (direction * directed_dim < 0) * random_12)\n",
    "        tmp = tmp.squeeze()\n",
    "        v[i] = tmp\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2f5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_mean(all_updates, n_attackers):\n",
    "    sorted_updates = torch.sort(all_updates, 0)[0]\n",
    "    out = torch.mean(sorted_updates[n_attackers:-n_attackers], 0) if n_attackers else torch.mean(sorted_updates,0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5c00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mean(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = torch.mean(user_grads,dim=0)\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72fe92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = torch.median(user_grads, 0)[0]\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2626a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_mean(old_gradients, user_grads, b=0, hvp=None):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    agg_grads = tr_mean(user_grads, b)\n",
    "    \n",
    "    return agg_grads, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67adc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(score, nobyz):\n",
    "    estimator = KMeans(n_clusters=2)\n",
    "    estimator.fit(score.reshape(-1, 1))\n",
    "    label_pred = estimator.labels_\n",
    "    if np.mean(score[label_pred==0])<np.mean(score[label_pred==1]):\n",
    "        #0 is the label of malicious clients\n",
    "        label_pred = 1 - label_pred\n",
    "    real_label=np.ones(100)\n",
    "    real_label[:nobyz]=0\n",
    "    acc=len(label_pred[label_pred==real_label])/100\n",
    "    recall=1-np.sum(label_pred[:nobyz])/nobyz\n",
    "    fpr=1-np.sum(label_pred[nobyz:])/(100-nobyz)\n",
    "    fnr=np.sum(label_pred[:nobyz])/nobyz\n",
    "    print(\"acc %0.4f; recall %0.4f; fpr %0.4f; fnr %0.4f;\" % (acc, recall, fpr, fnr))\n",
    "    print(silhouette_score(score.reshape(-1, 1), label_pred))\n",
    "\n",
    "def detection1(score, nobyz):\n",
    "    nrefs = 10\n",
    "    ks = range(1, 8)\n",
    "    gaps = np.zeros(len(ks))\n",
    "    gapDiff = np.zeros(len(ks) - 1)\n",
    "    sdk = np.zeros(len(ks))\n",
    "    min = np.min(score)\n",
    "    max = np.max(score)\n",
    "    score = (score - min)/(max-min)\n",
    "    for i, k in enumerate(ks):\n",
    "        estimator = KMeans(n_clusters=k)\n",
    "        estimator.fit(score.reshape(-1, 1))\n",
    "        label_pred = estimator.labels_\n",
    "        center = estimator.cluster_centers_\n",
    "        Wk = np.sum([np.square(score[m]-center[label_pred[m]]) for m in range(len(score))])\n",
    "        WkRef = np.zeros(nrefs)\n",
    "        for j in range(nrefs):\n",
    "            rand = np.random.uniform(0, 1, len(score))\n",
    "            estimator = KMeans(n_clusters=k)\n",
    "            estimator.fit(rand.reshape(-1, 1))\n",
    "            label_pred = estimator.labels_\n",
    "            center = estimator.cluster_centers_\n",
    "            WkRef[j] = np.sum([np.square(rand[m]-center[label_pred[m]]) for m in range(len(rand))])\n",
    "        gaps[i] = np.log(np.mean(WkRef)) - np.log(Wk)\n",
    "        sdk[i] = np.sqrt((1.0 + nrefs) / nrefs) * np.std(np.log(WkRef))\n",
    "\n",
    "        if i > 0:\n",
    "            gapDiff[i - 1] = gaps[i - 1] - gaps[i] + sdk[i]\n",
    "    #print(gapDiff)\n",
    "    for i in range(len(gapDiff)):\n",
    "        if gapDiff[i] >= 0:\n",
    "            select_k = i+1\n",
    "            break\n",
    "    if select_k == 1:\n",
    "        print('No attack detected!')\n",
    "        return 0\n",
    "    else:\n",
    "        print('Attack Detected!')\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa727c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "def train(trainloader, model, model_received, criterion, optimizer, pgd=False, eps=2):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    for batch_ind, (inputs, targets) in enumerate(trainloader):\n",
    "\n",
    "        inputs = inputs.to(device, torch.float)\n",
    "        targets = targets.to(device, torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size()[0])\n",
    "        top1.update(prec1.item()/100.0, inputs.size()[0])\n",
    "        top5.update(prec5.item()/100.0, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if pgd:\n",
    "            curr_model = list(model.parameters())\n",
    "            curr_model_vec = parameters_to_vector(curr_model)\n",
    "\n",
    "            if torch.norm(curr_model_vec - model_received) > eps:\n",
    "                curr_model_vec = eps*(curr_model_vec - model_received)/torch.norm(curr_model_vec - model_received) + model_received\n",
    "                vector_to_parameters(curr_model_vec, curr_model)\n",
    "        \n",
    "    return (losses.avg, top1.avg)\n",
    "\n",
    "def test(testloader, model, criterion):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    for batch_ind, (inputs, targets) in enumerate(testloader):\n",
    "        inputs = inputs.to(device, torch.float)\n",
    "        targets = targets.to(device, torch.long)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1/100.0, inputs.size()[0])\n",
    "        top5.update(prec5/100.0, inputs.size()[0])\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116ed4e",
   "metadata": {},
   "source": [
    "# Fang + FLDetector - with state_dict + No attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4a25069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 9.039 val loss 46.354 val acc 0.100 best val_acc 0.100\n",
      "e 1 benign_norm 8.299 val loss 229.226 val acc 0.100 best val_acc 0.100\n",
      "e 2 benign_norm 10.367 val loss 304.616 val acc 0.100 best val_acc 0.100\n",
      "e 3 benign_norm 7.427 val loss 792.109 val acc 0.099 best val_acc 0.100\n",
      "e 4 benign_norm 6.935 val loss 1141.288 val acc 0.099 best val_acc 0.100\n",
      "e 5 benign_norm 6.612 val loss 847.240 val acc 0.105 best val_acc 0.105\n",
      "e 6 benign_norm 7.097 val loss 140.016 val acc 0.102 best val_acc 0.105\n",
      "e 7 benign_norm 5.271 val loss 227.043 val acc 0.098 best val_acc 0.105\n",
      "e 8 benign_norm 5.580 val loss 125.481 val acc 0.099 best val_acc 0.105\n",
      "e 9 benign_norm 5.264 val loss 51.188 val acc 0.105 best val_acc 0.105\n",
      "e 10 benign_norm 4.898 val loss 35.363 val acc 0.101 best val_acc 0.105\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 4.367 val loss 20.682 val acc 0.102 best val_acc 0.105\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 4.167 val loss 8.249 val acc 0.113 best val_acc 0.113\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 3.798 val loss 6.319 val acc 0.103 best val_acc 0.113\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 3.692 val loss 4.415 val acc 0.130 best val_acc 0.130\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 3.593 val loss 4.403 val acc 0.123 best val_acc 0.130\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 3.546 val loss 3.182 val acc 0.154 best val_acc 0.154\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 3.376 val loss 2.874 val acc 0.156 best val_acc 0.156\n",
      "==> 18 (8, 100)\n",
      "e 18 benign_norm 3.245 val loss 2.535 val acc 0.173 best val_acc 0.173\n",
      "==> 19 (9, 100)\n",
      "e 19 benign_norm 3.128 val loss 2.436 val acc 0.174 best val_acc 0.174\n",
      "==> 20 (10, 100)\n",
      "performing detection at epoch 20\n",
      "No attack detected!\n",
      "e 20 benign_norm 3.091 val loss 2.331 val acc 0.183 best val_acc 0.183\n",
      "==> 21 (11, 100)\n",
      "performing detection at epoch 21\n",
      "No attack detected!\n",
      "e 21 benign_norm 3.038 val loss 2.277 val acc 0.190 best val_acc 0.190\n",
      "==> 22 (12, 100)\n",
      "performing detection at epoch 22\n",
      "No attack detected!\n",
      "e 22 benign_norm 3.057 val loss 2.234 val acc 0.191 best val_acc 0.191\n",
      "==> 23 (13, 100)\n",
      "performing detection at epoch 23\n",
      "No attack detected!\n",
      "e 23 benign_norm 3.026 val loss 2.235 val acc 0.206 best val_acc 0.206\n",
      "==> 24 (14, 100)\n",
      "performing detection at epoch 24\n",
      "No attack detected!\n",
      "e 24 benign_norm 3.014 val loss 2.161 val acc 0.203 best val_acc 0.206\n",
      "==> 31 (21, 100)\n",
      "performing detection at epoch 31\n",
      "No attack detected!\n",
      "e 31 benign_norm 2.908 val loss 1.943 val acc 0.280 best val_acc 0.280\n",
      "==> 32 (22, 100)\n",
      "performing detection at epoch 32\n",
      "No attack detected!\n",
      "e 32 benign_norm 2.895 val loss 1.970 val acc 0.269 best val_acc 0.280\n",
      "==> 33 (23, 100)\n",
      "performing detection at epoch 33\n",
      "No attack detected!\n",
      "e 33 benign_norm 2.871 val loss 1.893 val acc 0.294 best val_acc 0.294\n",
      "==> 34 (24, 100)\n",
      "performing detection at epoch 34\n",
      "No attack detected!\n",
      "e 34 benign_norm 2.892 val loss 1.928 val acc 0.270 best val_acc 0.294\n",
      "==> 35 (25, 100)\n",
      "performing detection at epoch 35\n",
      "No attack detected!\n",
      "e 35 benign_norm 2.840 val loss 1.865 val acc 0.309 best val_acc 0.309\n",
      "==> 36 (26, 100)\n",
      "performing detection at epoch 36\n",
      "No attack detected!\n",
      "e 36 benign_norm 2.883 val loss 1.909 val acc 0.258 best val_acc 0.309\n",
      "==> 37 (27, 100)\n",
      "performing detection at epoch 37\n",
      "No attack detected!\n",
      "e 37 benign_norm 2.817 val loss 1.889 val acc 0.302 best val_acc 0.309\n",
      "==> 38 (28, 100)\n",
      "performing detection at epoch 38\n",
      "No attack detected!\n",
      "e 38 benign_norm 3.006 val loss 2.055 val acc 0.216 best val_acc 0.309\n",
      "==> 39 (29, 100)\n",
      "performing detection at epoch 39\n",
      "No attack detected!\n",
      "e 39 benign_norm 2.970 val loss 2.519 val acc 0.242 best val_acc 0.309\n",
      "==> 40 (30, 100)\n",
      "performing detection at epoch 40\n",
      "Attack Detected!\n",
      "Stop at iteration: 40\n",
      "acc 0.5800; recall 0.3571; fpr 0.3333; fnr 0.6429;\n",
      "0.6957845275158709\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "    all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "attack_type = 'none'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        user_grads = full_trim(user_grads, nbyz)\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                print(\"LIE\")\n",
    "                z = 0.01\n",
    "                noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_avg + z * noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "    agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "#     agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7649f7",
   "metadata": {},
   "source": [
    "# Fang + FLDetector + trim attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515c5c9",
   "metadata": {},
   "source": [
    "# mean agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08055da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 9.662 val loss 461.655 val acc 0.100 best val_acc 0.100\n",
      "e 1 benign_norm 12.622 val loss 6074.586 val acc 0.102 best val_acc 0.102\n",
      "e 2 benign_norm 13.465 val loss 11501.611 val acc 0.102 best val_acc 0.102\n",
      "e 3 benign_norm 16.115 val loss 33232.262 val acc 0.102 best val_acc 0.102\n",
      "e 4 benign_norm 16.025 val loss 7643.963 val acc 0.097 best val_acc 0.102\n",
      "e 5 benign_norm 12.231 val loss 9276.187 val acc 0.100 best val_acc 0.102\n",
      "e 6 benign_norm 14.740 val loss 3148.542 val acc 0.097 best val_acc 0.102\n",
      "e 7 benign_norm 12.070 val loss 1783.328 val acc 0.102 best val_acc 0.102\n",
      "e 8 benign_norm 12.074 val loss 766.637 val acc 0.102 best val_acc 0.102\n",
      "e 9 benign_norm 10.755 val loss 2902.072 val acc 0.100 best val_acc 0.102\n",
      "e 10 benign_norm 11.643 val loss 350.978 val acc 0.102 best val_acc 0.102\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 9.070 val loss 2309.509 val acc 0.104 best val_acc 0.104\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 12.885 val loss 649.998 val acc 0.107 best val_acc 0.107\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 10.678 val loss 171.106 val acc 0.090 best val_acc 0.107\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 9.914 val loss 122.724 val acc 0.096 best val_acc 0.107\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 9.442 val loss 11.594 val acc 0.101 best val_acc 0.107\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 8.538 val loss 126.372 val acc 0.098 best val_acc 0.107\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 9.002 val loss 11.019 val acc 0.121 best val_acc 0.121\n",
      "==> 18 (8, 100)\n",
      "e 18 benign_norm 7.723 val loss 9.592 val acc 0.132 best val_acc 0.132\n",
      "==> 19 (9, 100)\n",
      "e 19 benign_norm 7.330 val loss 7.084 val acc 0.130 best val_acc 0.132\n",
      "==> 20 (10, 100)\n",
      "performing detection at epoch 20\n",
      "Attack Detected!\n",
      "Stop at iteration: 20\n",
      "acc 0.8200; recall 0.7143; fpr 0.1389; fnr 0.2857;\n",
      "0.8619486172793551\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "    all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "attack_type = 'full_trim'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        user_grads = full_trim(user_grads, nbyz)\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                print(\"LIE\")\n",
    "                z = 0.01\n",
    "                noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_avg + z * noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "    agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "#     agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60c07bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 10.353 val loss 100.559 val acc 0.102 best val_acc 0.102\n",
      "e 1 benign_norm 9.587 val loss 305.944 val acc 0.100 best val_acc 0.102\n",
      "e 2 benign_norm 9.341 val loss 168.438 val acc 0.097 best val_acc 0.102\n",
      "e 3 benign_norm 7.324 val loss 1003.820 val acc 0.103 best val_acc 0.103\n",
      "e 4 benign_norm 8.057 val loss 833.734 val acc 0.100 best val_acc 0.103\n",
      "e 5 benign_norm 6.991 val loss 544.614 val acc 0.098 best val_acc 0.103\n",
      "e 6 benign_norm 6.419 val loss 153.872 val acc 0.097 best val_acc 0.103\n",
      "e 7 benign_norm 5.686 val loss 63.572 val acc 0.098 best val_acc 0.103\n",
      "e 8 benign_norm 5.212 val loss 35.630 val acc 0.098 best val_acc 0.103\n",
      "e 9 benign_norm 4.887 val loss 19.439 val acc 0.099 best val_acc 0.103\n",
      "e 10 benign_norm 4.586 val loss 12.241 val acc 0.119 best val_acc 0.119\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 4.233 val loss 12.693 val acc 0.101 best val_acc 0.119\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 4.215 val loss 24.238 val acc 0.097 best val_acc 0.119\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 4.692 val loss 66.686 val acc 0.097 best val_acc 0.119\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 5.694 val loss 394.832 val acc 0.097 best val_acc 0.119\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 8.205 val loss 3465.883 val acc 0.096 best val_acc 0.119\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 13.041 val loss 40463.867 val acc 0.097 best val_acc 0.119\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 19.511 val loss 172405.688 val acc 0.100 best val_acc 0.119\n",
      "val loss 172405.687500... exit\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "    all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "init_attack = 'LIE'\n",
    "attack_type = 'LIE'\n",
    "dev_type = 'std'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        if init_attack == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif init_attack == 'LIE':\n",
    "            z = 0.01\n",
    "            noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "            noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "            noise = noise_avg + z * noise_std\n",
    "            user_grads[:nbyz] = torch.stack(nbyz * [noise])\n",
    "\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                z = 0.01\n",
    "#                 noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "    agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "#     agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcabb5",
   "metadata": {},
   "source": [
    "# trimmed mean agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dea8bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 10.187 val loss 306.335 val acc 0.096 best val_acc 0.096\n",
      "e 1 benign_norm 11.349 val loss 316.114 val acc 0.100 best val_acc 0.100\n",
      "e 2 benign_norm 9.612 val loss 226.081 val acc 0.103 best val_acc 0.103\n",
      "e 3 benign_norm 8.937 val loss 403.680 val acc 0.100 best val_acc 0.103\n",
      "e 4 benign_norm 7.745 val loss 2553.563 val acc 0.093 best val_acc 0.103\n",
      "e 5 benign_norm 9.172 val loss 4347.745 val acc 0.103 best val_acc 0.103\n",
      "e 6 benign_norm 11.121 val loss 1229.835 val acc 0.103 best val_acc 0.103\n",
      "e 7 benign_norm 9.710 val loss 455.237 val acc 0.102 best val_acc 0.103\n",
      "e 8 benign_norm 9.996 val loss 101.610 val acc 0.102 best val_acc 0.103\n",
      "e 9 benign_norm 9.125 val loss 69.453 val acc 0.095 best val_acc 0.103\n",
      "e 10 benign_norm 8.534 val loss 48.394 val acc 0.101 best val_acc 0.103\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 7.675 val loss 26.177 val acc 0.106 best val_acc 0.106\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 7.186 val loss 14.765 val acc 0.084 best val_acc 0.106\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 6.976 val loss 12.792 val acc 0.095 best val_acc 0.106\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 6.847 val loss 10.776 val acc 0.105 best val_acc 0.106\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 6.859 val loss 16.180 val acc 0.106 best val_acc 0.106\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 7.340 val loss 19.778 val acc 0.099 best val_acc 0.106\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 7.111 val loss 13.724 val acc 0.105 best val_acc 0.106\n",
      "==> 18 (8, 100)\n",
      "e 18 benign_norm 6.736 val loss 30.576 val acc 0.103 best val_acc 0.106\n",
      "==> 19 (9, 100)\n",
      "e 19 benign_norm 7.220 val loss 24.756 val acc 0.105 best val_acc 0.106\n",
      "==> 20 (10, 100)\n",
      "performing detection at epoch 20\n",
      "Attack Detected!\n",
      "Stop at iteration: 20\n",
      "acc 0.0000; recall 0.0000; fpr 1.0000; fnr 1.0000;\n",
      "0.9262932894851958\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "    all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "train_loaders = []\n",
    "for pos, indices in enumerate(each_worker_idx):\n",
    "    train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "init_attack = 'LIE'\n",
    "attack_type = 'LIE'\n",
    "dev_type = 'std'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        if init_attack == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif init_attack == 'LIE':\n",
    "            z = 0.01\n",
    "            noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "            noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "            noise = noise_avg + z * noise_std\n",
    "            user_grads[:nbyz] = torch.stack(nbyz * [noise])\n",
    "\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                z = 0.01\n",
    "#                 noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "#     agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bcdc90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 benign_norm 9.795 val loss 128.449 val acc 0.097 best val_acc 0.097\n",
      "e 1 benign_norm 9.171 val loss 112.578 val acc 0.100 best val_acc 0.100\n",
      "e 2 benign_norm 8.954 val loss 113.510 val acc 0.100 best val_acc 0.100\n",
      "e 3 benign_norm 7.812 val loss 216.066 val acc 0.103 best val_acc 0.103\n",
      "e 4 benign_norm 8.888 val loss 746.109 val acc 0.103 best val_acc 0.103\n",
      "e 5 benign_norm 9.444 val loss 849.423 val acc 0.097 best val_acc 0.103\n",
      "e 6 benign_norm 8.700 val loss 448.563 val acc 0.097 best val_acc 0.103\n",
      "e 7 benign_norm 8.781 val loss 166.903 val acc 0.098 best val_acc 0.103\n",
      "e 8 benign_norm 7.308 val loss 72.789 val acc 0.104 best val_acc 0.104\n",
      "e 9 benign_norm 6.128 val loss 84.020 val acc 0.103 best val_acc 0.104\n",
      "e 10 benign_norm 6.712 val loss 19.809 val acc 0.098 best val_acc 0.104\n",
      "==> 11 (1, 100)\n",
      "e 11 benign_norm 4.651 val loss 59.494 val acc 0.108 best val_acc 0.108\n",
      "==> 12 (2, 100)\n",
      "e 12 benign_norm 7.048 val loss 48.081 val acc 0.104 best val_acc 0.108\n",
      "==> 13 (3, 100)\n",
      "e 13 benign_norm 6.297 val loss 156.357 val acc 0.103 best val_acc 0.108\n",
      "==> 14 (4, 100)\n",
      "e 14 benign_norm 6.672 val loss 177.883 val acc 0.108 best val_acc 0.108\n",
      "==> 15 (5, 100)\n",
      "e 15 benign_norm 8.118 val loss 192.812 val acc 0.097 best val_acc 0.108\n",
      "==> 16 (6, 100)\n",
      "e 16 benign_norm 8.296 val loss 542.471 val acc 0.097 best val_acc 0.108\n",
      "==> 17 (7, 100)\n",
      "e 17 benign_norm 8.670 val loss 720.500 val acc 0.103 best val_acc 0.108\n",
      "==> 18 (8, 100)\n",
      "e 18 benign_norm 10.742 val loss 1035.807 val acc 0.097 best val_acc 0.108\n",
      "==> 19 (9, 100)\n",
      "e 19 benign_norm 11.071 val loss 1600.890 val acc 0.097 best val_acc 0.108\n",
      "==> 20 (10, 100)\n",
      "performing detection at epoch 20\n",
      "No attack detected!\n",
      "e 20 benign_norm 16.338 val loss 1705.568 val acc 0.106 best val_acc 0.108\n",
      "==> 21 (11, 100)\n",
      "performing detection at epoch 21\n",
      "No attack detected!\n",
      "e 21 benign_norm 15.149 val loss 2588.228 val acc 0.100 best val_acc 0.108\n",
      "==> 22 (12, 100)\n",
      "performing detection at epoch 22\n",
      "No attack detected!\n",
      "e 22 benign_norm 13.398 val loss 2000.966 val acc 0.092 best val_acc 0.108\n",
      "==> 23 (13, 100)\n",
      "performing detection at epoch 23\n",
      "No attack detected!\n",
      "e 23 benign_norm 15.365 val loss 1298.277 val acc 0.100 best val_acc 0.108\n",
      "==> 24 (14, 100)\n",
      "performing detection at epoch 24\n",
      "No attack detected!\n",
      "e 24 benign_norm 16.855 val loss 2635.416 val acc 0.103 best val_acc 0.108\n",
      "==> 25 (15, 100)\n",
      "performing detection at epoch 25\n",
      "No attack detected!\n",
      "e 25 benign_norm 19.157 val loss 630.061 val acc 0.098 best val_acc 0.108\n",
      "==> 26 (16, 100)\n",
      "performing detection at epoch 26\n",
      "No attack detected!\n",
      "e 26 benign_norm 17.993 val loss 676.872 val acc 0.106 best val_acc 0.108\n",
      "==> 27 (17, 100)\n",
      "performing detection at epoch 27\n",
      "No attack detected!\n",
      "e 27 benign_norm 16.437 val loss 224.301 val acc 0.098 best val_acc 0.108\n",
      "==> 28 (18, 100)\n",
      "performing detection at epoch 28\n",
      "No attack detected!\n",
      "e 28 benign_norm 18.055 val loss 274.849 val acc 0.106 best val_acc 0.108\n",
      "==> 29 (19, 100)\n",
      "performing detection at epoch 29\n",
      "No attack detected!\n",
      "e 29 benign_norm 19.488 val loss 382.354 val acc 0.100 best val_acc 0.108\n",
      "==> 30 (20, 100)\n",
      "performing detection at epoch 30\n",
      "No attack detected!\n",
      "e 30 benign_norm 23.256 val loss 780.429 val acc 0.103 best val_acc 0.108\n",
      "==> 31 (21, 100)\n",
      "performing detection at epoch 31\n",
      "No attack detected!\n",
      "e 31 benign_norm 22.508 val loss 134.646 val acc 0.108 best val_acc 0.108\n",
      "==> 32 (22, 100)\n",
      "performing detection at epoch 32\n",
      "No attack detected!\n",
      "e 32 benign_norm 18.036 val loss 342.089 val acc 0.100 best val_acc 0.108\n",
      "==> 33 (23, 100)\n",
      "performing detection at epoch 33\n",
      "No attack detected!\n",
      "e 33 benign_norm 26.782 val loss 1929.550 val acc 0.106 best val_acc 0.108\n",
      "==> 34 (24, 100)\n",
      "performing detection at epoch 34\n",
      "No attack detected!\n",
      "e 34 benign_norm 26.954 val loss 4257.906 val acc 0.098 best val_acc 0.108\n",
      "==> 35 (25, 100)\n",
      "performing detection at epoch 35\n",
      "No attack detected!\n",
      "e 35 benign_norm 27.319 val loss 8541.779 val acc 0.097 best val_acc 0.108\n",
      "==> 36 (26, 100)\n",
      "performing detection at epoch 36\n",
      "No attack detected!\n",
      "e 36 benign_norm 28.973 val loss 2255.502 val acc 0.106 best val_acc 0.108\n",
      "==> 37 (27, 100)\n",
      "performing detection at epoch 37\n",
      "No attack detected!\n",
      "e 37 benign_norm 29.651 val loss 4116.198 val acc 0.103 best val_acc 0.108\n",
      "==> 38 (28, 100)\n",
      "performing detection at epoch 38\n",
      "No attack detected!\n",
      "e 38 benign_norm 40.162 val loss 2802.107 val acc 0.106 best val_acc 0.108\n",
      "==> 39 (29, 100)\n",
      "performing detection at epoch 39\n",
      "No attack detected!\n",
      "e 39 benign_norm 31.793 val loss 1829.462 val acc 0.103 best val_acc 0.108\n",
      "==> 40 (30, 100)\n",
      "performing detection at epoch 40\n",
      "No attack detected!\n",
      "e 40 benign_norm 39.523 val loss 1940.290 val acc 0.100 best val_acc 0.108\n",
      "==> 41 (31, 100)\n",
      "performing detection at epoch 41\n",
      "No attack detected!\n",
      "e 41 benign_norm 35.881 val loss 5961.595 val acc 0.103 best val_acc 0.108\n",
      "==> 42 (32, 100)\n",
      "performing detection at epoch 42\n",
      "No attack detected!\n",
      "e 42 benign_norm 52.003 val loss 8475.146 val acc 0.097 best val_acc 0.108\n",
      "==> 43 (33, 100)\n",
      "performing detection at epoch 43\n",
      "No attack detected!\n",
      "e 43 benign_norm 56.048 val loss 20578.654 val acc 0.100 best val_acc 0.108\n",
      "==> 44 (34, 100)\n",
      "performing detection at epoch 44\n",
      "No attack detected!\n",
      "e 44 benign_norm 51.583 val loss 48314.137 val acc 0.103 best val_acc 0.108\n",
      "==> 45 (35, 100)\n",
      "performing detection at epoch 45\n",
      "No attack detected!\n",
      "e 45 benign_norm 66.714 val loss 13794.539 val acc 0.097 best val_acc 0.108\n",
      "==> 46 (36, 100)\n",
      "performing detection at epoch 46\n",
      "No attack detected!\n",
      "e 46 benign_norm 50.806 val loss 11672.948 val acc 0.100 best val_acc 0.108\n",
      "==> 47 (37, 100)\n",
      "performing detection at epoch 47\n",
      "No attack detected!\n",
      "e 47 benign_norm 54.115 val loss 3441.315 val acc 0.097 best val_acc 0.108\n",
      "==> 48 (38, 100)\n",
      "performing detection at epoch 48\n",
      "No attack detected!\n",
      "e 48 benign_norm 46.458 val loss 1277.432 val acc 0.100 best val_acc 0.108\n",
      "==> 49 (39, 100)\n",
      "performing detection at epoch 49\n",
      "No attack detected!\n",
      "e 49 benign_norm 40.127 val loss 828.704 val acc 0.097 best val_acc 0.108\n",
      "==> 50 (40, 100)\n",
      "performing detection at epoch 50\n",
      "No attack detected!\n",
      "e 50 benign_norm 38.037 val loss 299.614 val acc 0.096 best val_acc 0.108\n",
      "==> 51 (41, 100)\n",
      "performing detection at epoch 51\n",
      "No attack detected!\n",
      "e 51 benign_norm 36.265 val loss 238.252 val acc 0.100 best val_acc 0.108\n",
      "==> 52 (42, 100)\n",
      "performing detection at epoch 52\n",
      "No attack detected!\n",
      "e 52 benign_norm 34.131 val loss 915.976 val acc 0.098 best val_acc 0.108\n",
      "==> 53 (43, 100)\n",
      "performing detection at epoch 53\n",
      "No attack detected!\n",
      "e 53 benign_norm 35.461 val loss 457.666 val acc 0.107 best val_acc 0.108\n",
      "==> 54 (44, 100)\n",
      "performing detection at epoch 54\n",
      "No attack detected!\n",
      "e 54 benign_norm 33.648 val loss 305.582 val acc 0.096 best val_acc 0.108\n",
      "==> 55 (45, 100)\n",
      "performing detection at epoch 55\n",
      "No attack detected!\n",
      "e 55 benign_norm 32.449 val loss 194.970 val acc 0.108 best val_acc 0.108\n",
      "==> 56 (46, 100)\n",
      "performing detection at epoch 56\n",
      "No attack detected!\n",
      "e 56 benign_norm 31.785 val loss 227.629 val acc 0.100 best val_acc 0.108\n",
      "==> 57 (47, 100)\n",
      "performing detection at epoch 57\n",
      "No attack detected!\n",
      "e 57 benign_norm 30.731 val loss 191.146 val acc 0.103 best val_acc 0.108\n",
      "==> 58 (48, 100)\n",
      "performing detection at epoch 58\n",
      "No attack detected!\n",
      "e 58 benign_norm 29.646 val loss 96.591 val acc 0.095 best val_acc 0.108\n",
      "==> 59 (49, 100)\n",
      "performing detection at epoch 59\n",
      "No attack detected!\n",
      "e 59 benign_norm 28.217 val loss 128.462 val acc 0.100 best val_acc 0.108\n",
      "==> 60 (50, 100)\n",
      "performing detection at epoch 60\n",
      "No attack detected!\n",
      "e 60 benign_norm 27.039 val loss 642.539 val acc 0.100 best val_acc 0.108\n",
      "==> 61 (51, 100)\n",
      "performing detection at epoch 61\n",
      "No attack detected!\n",
      "e 61 benign_norm 34.257 val loss 234.870 val acc 0.100 best val_acc 0.108\n",
      "==> 62 (52, 100)\n",
      "performing detection at epoch 62\n",
      "No attack detected!\n",
      "e 62 benign_norm 32.045 val loss 157.739 val acc 0.090 best val_acc 0.108\n",
      "==> 63 (53, 100)\n",
      "performing detection at epoch 63\n",
      "No attack detected!\n",
      "e 63 benign_norm 34.499 val loss 119.903 val acc 0.097 best val_acc 0.108\n",
      "==> 64 (54, 100)\n",
      "performing detection at epoch 64\n",
      "No attack detected!\n",
      "e 64 benign_norm 23.771 val loss 3877.889 val acc 0.103 best val_acc 0.108\n",
      "==> 65 (55, 100)\n",
      "performing detection at epoch 65\n",
      "No attack detected!\n",
      "e 65 benign_norm 68.014 val loss 33468.391 val acc 0.103 best val_acc 0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 66 (56, 100)\n",
      "performing detection at epoch 66\n",
      "No attack detected!\n",
      "e 66 benign_norm 111.198 val loss 50291.457 val acc 0.103 best val_acc 0.108\n",
      "==> 67 (57, 100)\n",
      "performing detection at epoch 67\n",
      "No attack detected!\n",
      "e 67 benign_norm 286.445 val loss 11791.866 val acc 0.108 best val_acc 0.108\n",
      "==> 68 (58, 100)\n",
      "performing detection at epoch 68\n",
      "No attack detected!\n",
      "e 68 benign_norm 262.943 val loss 2406.462 val acc 0.100 best val_acc 0.108\n",
      "==> 69 (59, 100)\n",
      "performing detection at epoch 69\n",
      "No attack detected!\n",
      "e 69 benign_norm 242.543 val loss 921.980 val acc 0.103 best val_acc 0.108\n",
      "==> 70 (60, 100)\n",
      "performing detection at epoch 70\n",
      "No attack detected!\n",
      "e 70 benign_norm 226.409 val loss 5708.082 val acc 0.103 best val_acc 0.108\n",
      "==> 71 (61, 100)\n",
      "performing detection at epoch 71\n",
      "No attack detected!\n",
      "e 71 benign_norm 230.121 val loss 755.251 val acc 0.081 best val_acc 0.108\n",
      "==> 72 (62, 100)\n",
      "performing detection at epoch 72\n",
      "No attack detected!\n",
      "e 72 benign_norm 201.377 val loss 793.694 val acc 0.106 best val_acc 0.108\n",
      "==> 73 (63, 100)\n",
      "performing detection at epoch 73\n",
      "No attack detected!\n",
      "e 73 benign_norm 195.905 val loss 522.824 val acc 0.100 best val_acc 0.108\n",
      "==> 74 (64, 100)\n",
      "performing detection at epoch 74\n",
      "No attack detected!\n",
      "e 74 benign_norm 188.749 val loss 529.239 val acc 0.105 best val_acc 0.108\n",
      "==> 75 (65, 100)\n",
      "performing detection at epoch 75\n",
      "No attack detected!\n",
      "e 75 benign_norm 179.635 val loss 492.091 val acc 0.096 best val_acc 0.108\n",
      "==> 76 (66, 100)\n",
      "performing detection at epoch 76\n",
      "No attack detected!\n",
      "e 76 benign_norm 170.574 val loss 298.110 val acc 0.098 best val_acc 0.108\n",
      "==> 77 (67, 100)\n",
      "performing detection at epoch 77\n",
      "No attack detected!\n",
      "e 77 benign_norm 160.234 val loss 84.026 val acc 0.091 best val_acc 0.108\n",
      "==> 78 (68, 100)\n",
      "performing detection at epoch 78\n",
      "No attack detected!\n",
      "e 78 benign_norm 146.010 val loss 113.536 val acc 0.100 best val_acc 0.108\n",
      "==> 79 (69, 100)\n",
      "performing detection at epoch 79\n",
      "No attack detected!\n",
      "e 79 benign_norm 132.818 val loss 73.706 val acc 0.129 best val_acc 0.129\n",
      "==> 80 (70, 100)\n",
      "performing detection at epoch 80\n",
      "No attack detected!\n",
      "e 80 benign_norm 136.729 val loss 58.572 val acc 0.124 best val_acc 0.129\n",
      "==> 81 (71, 100)\n",
      "performing detection at epoch 81\n",
      "No attack detected!\n",
      "e 81 benign_norm 127.717 val loss 59.685 val acc 0.131 best val_acc 0.131\n",
      "==> 82 (72, 100)\n",
      "performing detection at epoch 82\n",
      "No attack detected!\n",
      "e 82 benign_norm 120.644 val loss 52.484 val acc 0.110 best val_acc 0.131\n",
      "==> 83 (73, 100)\n",
      "performing detection at epoch 83\n",
      "No attack detected!\n",
      "e 83 benign_norm 116.631 val loss 87.877 val acc 0.103 best val_acc 0.131\n",
      "==> 84 (74, 100)\n",
      "performing detection at epoch 84\n",
      "No attack detected!\n",
      "e 84 benign_norm 119.190 val loss 30.252 val acc 0.098 best val_acc 0.131\n",
      "==> 85 (75, 100)\n",
      "performing detection at epoch 85\n",
      "No attack detected!\n",
      "e 85 benign_norm 103.620 val loss 24.803 val acc 0.099 best val_acc 0.131\n",
      "==> 86 (76, 100)\n",
      "performing detection at epoch 86\n",
      "No attack detected!\n",
      "e 86 benign_norm 98.637 val loss 34.662 val acc 0.109 best val_acc 0.131\n",
      "==> 87 (77, 100)\n",
      "performing detection at epoch 87\n",
      "No attack detected!\n",
      "e 87 benign_norm 93.632 val loss 47.546 val acc 0.095 best val_acc 0.131\n",
      "==> 88 (78, 100)\n",
      "performing detection at epoch 88\n",
      "No attack detected!\n",
      "e 88 benign_norm 92.979 val loss 9.569 val acc 0.098 best val_acc 0.131\n",
      "==> 89 (79, 100)\n",
      "performing detection at epoch 89\n",
      "No attack detected!\n",
      "e 89 benign_norm 78.648 val loss 16.064 val acc 0.117 best val_acc 0.131\n",
      "==> 90 (80, 100)\n",
      "performing detection at epoch 90\n",
      "No attack detected!\n",
      "e 90 benign_norm 72.731 val loss 601.688 val acc 0.122 best val_acc 0.131\n",
      "==> 91 (81, 100)\n",
      "performing detection at epoch 91\n",
      "No attack detected!\n",
      "e 91 benign_norm 127.133 val loss 568.914 val acc 0.103 best val_acc 0.131\n",
      "==> 92 (82, 100)\n",
      "performing detection at epoch 92\n",
      "No attack detected!\n",
      "e 92 benign_norm 123.254 val loss 231.125 val acc 0.103 best val_acc 0.131\n",
      "==> 93 (83, 100)\n",
      "performing detection at epoch 93\n",
      "No attack detected!\n",
      "e 93 benign_norm 91.307 val loss 323.281 val acc 0.100 best val_acc 0.131\n",
      "==> 94 (84, 100)\n",
      "performing detection at epoch 94\n",
      "No attack detected!\n",
      "e 94 benign_norm 94.280 val loss 101.706 val acc 0.102 best val_acc 0.131\n",
      "==> 95 (85, 100)\n",
      "performing detection at epoch 95\n",
      "No attack detected!\n",
      "e 95 benign_norm 72.918 val loss 57.358 val acc 0.102 best val_acc 0.131\n",
      "==> 96 (86, 100)\n",
      "performing detection at epoch 96\n",
      "No attack detected!\n",
      "e 96 benign_norm 58.322 val loss 35.714 val acc 0.095 best val_acc 0.131\n",
      "==> 97 (87, 100)\n",
      "performing detection at epoch 97\n",
      "No attack detected!\n",
      "e 97 benign_norm 53.265 val loss 11.908 val acc 0.098 best val_acc 0.131\n",
      "==> 98 (88, 100)\n",
      "performing detection at epoch 98\n",
      "No attack detected!\n",
      "e 98 benign_norm 43.425 val loss 32.757 val acc 0.085 best val_acc 0.131\n",
      "==> 99 (89, 100)\n",
      "performing detection at epoch 99\n",
      "No attack detected!\n",
      "e 99 benign_norm 48.730 val loss 20.332 val acc 0.103 best val_acc 0.131\n",
      "==> 100 (90, 100)\n",
      "performing detection at epoch 100\n",
      "No attack detected!\n",
      "e 100 benign_norm 42.778 val loss 22.241 val acc 0.102 best val_acc 0.131\n",
      "==> 101 (91, 100)\n",
      "performing detection at epoch 101\n",
      "No attack detected!\n",
      "e 101 benign_norm 42.049 val loss 20.457 val acc 0.103 best val_acc 0.131\n",
      "==> 102 (92, 100)\n",
      "performing detection at epoch 102\n",
      "No attack detected!\n",
      "e 102 benign_norm 38.637 val loss 50.648 val acc 0.107 best val_acc 0.131\n",
      "==> 103 (93, 100)\n",
      "performing detection at epoch 103\n",
      "No attack detected!\n",
      "e 103 benign_norm 48.799 val loss 43.072 val acc 0.089 best val_acc 0.131\n",
      "==> 104 (94, 100)\n",
      "performing detection at epoch 104\n",
      "No attack detected!\n",
      "e 104 benign_norm 50.486 val loss 20.098 val acc 0.098 best val_acc 0.131\n",
      "==> 105 (95, 100)\n",
      "performing detection at epoch 105\n",
      "No attack detected!\n",
      "e 105 benign_norm 38.826 val loss 11.249 val acc 0.100 best val_acc 0.131\n",
      "==> 106 (96, 100)\n",
      "performing detection at epoch 106\n",
      "No attack detected!\n",
      "e 106 benign_norm 35.392 val loss 22.108 val acc 0.100 best val_acc 0.131\n",
      "==> 107 (97, 100)\n",
      "performing detection at epoch 107\n",
      "No attack detected!\n",
      "e 107 benign_norm 32.720 val loss 22.089 val acc 0.093 best val_acc 0.131\n",
      "==> 108 (98, 100)\n",
      "performing detection at epoch 108\n",
      "No attack detected!\n",
      "e 108 benign_norm 30.760 val loss 27.720 val acc 0.101 best val_acc 0.131\n",
      "==> 109 (99, 100)\n",
      "performing detection at epoch 109\n",
      "No attack detected!\n",
      "e 109 benign_norm 31.330 val loss 26.685 val acc 0.089 best val_acc 0.131\n",
      "==> 110 (100, 100)\n",
      "performing detection at epoch 110\n",
      "No attack detected!\n",
      "e 110 benign_norm 36.154 val loss 12.868 val acc 0.101 best val_acc 0.131\n",
      "==> 111 (101, 100)\n",
      "performing detection at epoch 111\n",
      "No attack detected!\n",
      "e 111 benign_norm 29.264 val loss 34.653 val acc 0.098 best val_acc 0.131\n",
      "==> 112 (102, 100)\n",
      "performing detection at epoch 112\n",
      "No attack detected!\n",
      "e 112 benign_norm 39.517 val loss 29.768 val acc 0.100 best val_acc 0.131\n",
      "==> 113 (103, 100)\n",
      "performing detection at epoch 113\n",
      "No attack detected!\n",
      "e 113 benign_norm 38.536 val loss 10.319 val acc 0.105 best val_acc 0.131\n",
      "==> 114 (104, 100)\n",
      "performing detection at epoch 114\n",
      "No attack detected!\n",
      "e 114 benign_norm 31.428 val loss 18.850 val acc 0.100 best val_acc 0.131\n",
      "==> 115 (105, 100)\n",
      "performing detection at epoch 115\n",
      "No attack detected!\n",
      "e 115 benign_norm 37.168 val loss 17.509 val acc 0.088 best val_acc 0.131\n",
      "==> 116 (106, 100)\n",
      "performing detection at epoch 116\n",
      "No attack detected!\n",
      "e 116 benign_norm 34.650 val loss 16.354 val acc 0.097 best val_acc 0.131\n",
      "==> 117 (107, 100)\n",
      "performing detection at epoch 117\n",
      "No attack detected!\n",
      "e 117 benign_norm 34.972 val loss 16.865 val acc 0.103 best val_acc 0.131\n",
      "==> 118 (108, 100)\n",
      "performing detection at epoch 118\n",
      "No attack detected!\n",
      "e 118 benign_norm 32.036 val loss 27.519 val acc 0.117 best val_acc 0.131\n",
      "==> 119 (109, 100)\n",
      "performing detection at epoch 119\n",
      "No attack detected!\n",
      "e 119 benign_norm 35.223 val loss 27.134 val acc 0.077 best val_acc 0.131\n",
      "==> 120 (110, 100)\n",
      "performing detection at epoch 120\n",
      "No attack detected!\n",
      "e 120 benign_norm 29.802 val loss 42.891 val acc 0.103 best val_acc 0.131\n",
      "==> 121 (111, 100)\n",
      "performing detection at epoch 121\n",
      "No attack detected!\n",
      "e 121 benign_norm 44.069 val loss 28.075 val acc 0.134 best val_acc 0.134\n",
      "==> 122 (112, 100)\n",
      "performing detection at epoch 122\n",
      "No attack detected!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 122 benign_norm 31.634 val loss 141.625 val acc 0.094 best val_acc 0.134\n",
      "==> 123 (113, 100)\n",
      "performing detection at epoch 123\n",
      "No attack detected!\n",
      "e 123 benign_norm 73.371 val loss 38.811 val acc 0.096 best val_acc 0.134\n",
      "==> 124 (114, 100)\n",
      "performing detection at epoch 124\n",
      "No attack detected!\n",
      "e 124 benign_norm 30.179 val loss 21.186 val acc 0.105 best val_acc 0.134\n",
      "==> 125 (115, 100)\n",
      "performing detection at epoch 125\n",
      "No attack detected!\n",
      "e 125 benign_norm 32.556 val loss 17.079 val acc 0.100 best val_acc 0.134\n",
      "==> 126 (116, 100)\n",
      "performing detection at epoch 126\n",
      "No attack detected!\n",
      "e 126 benign_norm 44.062 val loss 28.884 val acc 0.104 best val_acc 0.134\n",
      "==> 127 (117, 100)\n",
      "performing detection at epoch 127\n",
      "No attack detected!\n",
      "e 127 benign_norm 38.001 val loss 44.256 val acc 0.106 best val_acc 0.134\n",
      "==> 128 (118, 100)\n",
      "performing detection at epoch 128\n",
      "No attack detected!\n",
      "e 128 benign_norm 54.775 val loss 39.036 val acc 0.103 best val_acc 0.134\n",
      "==> 129 (119, 100)\n",
      "performing detection at epoch 129\n",
      "No attack detected!\n",
      "e 129 benign_norm 31.565 val loss 28.344 val acc 0.092 best val_acc 0.134\n",
      "==> 130 (120, 100)\n",
      "performing detection at epoch 130\n",
      "No attack detected!\n",
      "e 130 benign_norm 41.611 val loss 20.805 val acc 0.103 best val_acc 0.134\n",
      "==> 131 (121, 100)\n",
      "performing detection at epoch 131\n",
      "No attack detected!\n",
      "e 131 benign_norm 27.917 val loss 55.170 val acc 0.103 best val_acc 0.134\n",
      "==> 132 (122, 100)\n",
      "performing detection at epoch 132\n",
      "No attack detected!\n",
      "e 132 benign_norm 35.741 val loss 45.509 val acc 0.085 best val_acc 0.134\n",
      "==> 133 (123, 100)\n",
      "performing detection at epoch 133\n",
      "No attack detected!\n",
      "e 133 benign_norm 29.610 val loss 138.040 val acc 0.088 best val_acc 0.134\n",
      "==> 134 (124, 100)\n",
      "performing detection at epoch 134\n",
      "No attack detected!\n",
      "e 134 benign_norm 40.526 val loss 99.841 val acc 0.094 best val_acc 0.134\n",
      "==> 135 (125, 100)\n",
      "performing detection at epoch 135\n",
      "No attack detected!\n",
      "e 135 benign_norm 43.878 val loss 69.355 val acc 0.100 best val_acc 0.134\n",
      "==> 136 (126, 100)\n",
      "performing detection at epoch 136\n",
      "No attack detected!\n",
      "e 136 benign_norm 38.582 val loss 292.722 val acc 0.102 best val_acc 0.134\n",
      "==> 137 (127, 100)\n",
      "performing detection at epoch 137\n",
      "No attack detected!\n",
      "e 137 benign_norm 140.726 val loss 275.849 val acc 0.097 best val_acc 0.134\n",
      "==> 138 (128, 100)\n",
      "performing detection at epoch 138\n",
      "No attack detected!\n",
      "e 138 benign_norm 132.133 val loss 99.109 val acc 0.106 best val_acc 0.134\n",
      "==> 139 (129, 100)\n",
      "performing detection at epoch 139\n",
      "No attack detected!\n",
      "e 139 benign_norm 104.727 val loss 49.181 val acc 0.097 best val_acc 0.134\n",
      "==> 140 (130, 100)\n",
      "performing detection at epoch 140\n",
      "No attack detected!\n",
      "e 140 benign_norm 94.709 val loss 27.216 val acc 0.111 best val_acc 0.134\n",
      "==> 141 (131, 100)\n",
      "performing detection at epoch 141\n",
      "No attack detected!\n",
      "e 141 benign_norm 97.257 val loss 20.872 val acc 0.100 best val_acc 0.134\n",
      "==> 142 (132, 100)\n",
      "performing detection at epoch 142\n",
      "No attack detected!\n",
      "e 142 benign_norm 80.967 val loss 15.193 val acc 0.103 best val_acc 0.134\n",
      "==> 143 (133, 100)\n",
      "performing detection at epoch 143\n",
      "No attack detected!\n",
      "e 143 benign_norm 60.848 val loss 12.288 val acc 0.107 best val_acc 0.134\n",
      "==> 144 (134, 100)\n",
      "performing detection at epoch 144\n",
      "No attack detected!\n",
      "e 144 benign_norm 57.822 val loss 9.627 val acc 0.092 best val_acc 0.134\n",
      "==> 145 (135, 100)\n",
      "performing detection at epoch 145\n",
      "No attack detected!\n",
      "e 145 benign_norm 59.926 val loss 5.333 val acc 0.099 best val_acc 0.134\n",
      "==> 146 (136, 100)\n",
      "performing detection at epoch 146\n",
      "No attack detected!\n",
      "e 146 benign_norm 58.199 val loss 5.716 val acc 0.122 best val_acc 0.134\n",
      "==> 147 (137, 100)\n",
      "performing detection at epoch 147\n",
      "No attack detected!\n",
      "e 147 benign_norm 50.250 val loss 6.783 val acc 0.103 best val_acc 0.134\n",
      "==> 148 (138, 100)\n",
      "performing detection at epoch 148\n",
      "No attack detected!\n",
      "e 148 benign_norm 49.593 val loss 4.259 val acc 0.119 best val_acc 0.134\n",
      "==> 149 (139, 100)\n",
      "performing detection at epoch 149\n",
      "No attack detected!\n",
      "e 149 benign_norm 39.533 val loss 4.925 val acc 0.100 best val_acc 0.134\n",
      "==> 150 (140, 100)\n",
      "performing detection at epoch 150\n",
      "No attack detected!\n",
      "e 150 benign_norm 36.280 val loss 3.587 val acc 0.115 best val_acc 0.134\n",
      "==> 151 (141, 100)\n",
      "performing detection at epoch 151\n",
      "No attack detected!\n",
      "e 151 benign_norm 48.366 val loss 3.966 val acc 0.103 best val_acc 0.134\n",
      "==> 152 (142, 100)\n",
      "performing detection at epoch 152\n",
      "No attack detected!\n",
      "e 152 benign_norm 54.317 val loss 3.884 val acc 0.102 best val_acc 0.134\n",
      "==> 153 (143, 100)\n",
      "performing detection at epoch 153\n",
      "No attack detected!\n",
      "e 153 benign_norm 43.198 val loss 4.911 val acc 0.099 best val_acc 0.134\n",
      "==> 154 (144, 100)\n",
      "performing detection at epoch 154\n",
      "No attack detected!\n",
      "e 154 benign_norm 43.156 val loss 4.440 val acc 0.100 best val_acc 0.134\n",
      "==> 155 (145, 100)\n",
      "performing detection at epoch 155\n",
      "No attack detected!\n",
      "e 155 benign_norm 33.653 val loss 7.637 val acc 0.103 best val_acc 0.134\n",
      "==> 156 (146, 100)\n",
      "performing detection at epoch 156\n",
      "No attack detected!\n",
      "e 156 benign_norm 57.609 val loss 9.553 val acc 0.107 best val_acc 0.134\n",
      "==> 157 (147, 100)\n",
      "performing detection at epoch 157\n",
      "No attack detected!\n",
      "e 157 benign_norm 63.645 val loss 6.581 val acc 0.099 best val_acc 0.134\n",
      "==> 158 (148, 100)\n",
      "performing detection at epoch 158\n",
      "No attack detected!\n",
      "e 158 benign_norm 61.628 val loss 4.761 val acc 0.105 best val_acc 0.134\n",
      "==> 159 (149, 100)\n",
      "performing detection at epoch 159\n",
      "No attack detected!\n",
      "e 159 benign_norm 47.509 val loss 4.744 val acc 0.100 best val_acc 0.134\n",
      "==> 160 (150, 100)\n",
      "performing detection at epoch 160\n",
      "No attack detected!\n",
      "e 160 benign_norm 92.465 val loss 4.853 val acc 0.100 best val_acc 0.134\n",
      "==> 161 (151, 100)\n",
      "performing detection at epoch 161\n",
      "No attack detected!\n",
      "e 161 benign_norm 48.806 val loss 5.019 val acc 0.100 best val_acc 0.134\n",
      "==> 162 (152, 100)\n",
      "performing detection at epoch 162\n",
      "No attack detected!\n",
      "e 162 benign_norm 37.306 val loss 4.298 val acc 0.101 best val_acc 0.134\n",
      "==> 163 (153, 100)\n",
      "performing detection at epoch 163\n",
      "No attack detected!\n",
      "e 163 benign_norm 39.663 val loss 5.230 val acc 0.100 best val_acc 0.134\n",
      "==> 164 (154, 100)\n",
      "performing detection at epoch 164\n",
      "No attack detected!\n",
      "e 164 benign_norm 35.322 val loss 4.303 val acc 0.103 best val_acc 0.134\n",
      "==> 165 (155, 100)\n",
      "performing detection at epoch 165\n",
      "No attack detected!\n",
      "e 165 benign_norm 48.139 val loss 6.264 val acc 0.101 best val_acc 0.134\n",
      "==> 166 (156, 100)\n",
      "performing detection at epoch 166\n",
      "No attack detected!\n",
      "e 166 benign_norm 29.306 val loss 10.964 val acc 0.097 best val_acc 0.134\n",
      "==> 167 (157, 100)\n",
      "performing detection at epoch 167\n",
      "No attack detected!\n",
      "e 167 benign_norm 78.213 val loss 7.181 val acc 0.102 best val_acc 0.134\n",
      "==> 168 (158, 100)\n",
      "performing detection at epoch 168\n",
      "No attack detected!\n",
      "e 168 benign_norm 36.930 val loss 6.273 val acc 0.116 best val_acc 0.134\n",
      "==> 169 (159, 100)\n",
      "performing detection at epoch 169\n",
      "No attack detected!\n",
      "e 169 benign_norm 58.397 val loss 9.035 val acc 0.100 best val_acc 0.134\n",
      "==> 170 (160, 100)\n",
      "performing detection at epoch 170\n",
      "No attack detected!\n",
      "e 170 benign_norm 29.529 val loss 9.311 val acc 0.103 best val_acc 0.134\n",
      "==> 171 (161, 100)\n",
      "performing detection at epoch 171\n",
      "No attack detected!\n",
      "e 171 benign_norm 32.388 val loss 15.972 val acc 0.100 best val_acc 0.134\n",
      "==> 172 (162, 100)\n",
      "performing detection at epoch 172\n",
      "No attack detected!\n",
      "e 172 benign_norm 39.814 val loss 10.453 val acc 0.120 best val_acc 0.134\n",
      "==> 173 (163, 100)\n",
      "performing detection at epoch 173\n",
      "No attack detected!\n",
      "e 173 benign_norm 39.292 val loss 39.508 val acc 0.089 best val_acc 0.134\n",
      "==> 174 (164, 100)\n",
      "performing detection at epoch 174\n",
      "No attack detected!\n",
      "e 174 benign_norm 97.684 val loss 258.166 val acc 0.100 best val_acc 0.134\n",
      "==> 175 (165, 100)\n",
      "performing detection at epoch 175\n",
      "No attack detected!\n",
      "e 175 benign_norm 112.040 val loss 59.210 val acc 0.098 best val_acc 0.134\n",
      "==> 176 (166, 100)\n",
      "performing detection at epoch 176\n",
      "No attack detected!\n",
      "e 176 benign_norm 62.560 val loss 35.648 val acc 0.097 best val_acc 0.134\n",
      "==> 177 (167, 100)\n",
      "performing detection at epoch 177\n",
      "No attack detected!\n",
      "e 177 benign_norm 54.176 val loss 27.728 val acc 0.106 best val_acc 0.134\n",
      "==> 178 (168, 100)\n",
      "performing detection at epoch 178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 178 benign_norm 50.624 val loss 11.145 val acc 0.103 best val_acc 0.134\n",
      "==> 179 (169, 100)\n",
      "performing detection at epoch 179\n",
      "No attack detected!\n",
      "e 179 benign_norm 59.080 val loss 8.095 val acc 0.103 best val_acc 0.134\n",
      "==> 180 (170, 100)\n",
      "performing detection at epoch 180\n",
      "No attack detected!\n",
      "e 180 benign_norm 53.063 val loss 5.620 val acc 0.100 best val_acc 0.134\n",
      "==> 181 (171, 100)\n",
      "performing detection at epoch 181\n",
      "No attack detected!\n",
      "e 181 benign_norm 55.113 val loss 3.900 val acc 0.104 best val_acc 0.134\n",
      "==> 182 (172, 100)\n",
      "performing detection at epoch 182\n",
      "No attack detected!\n",
      "e 182 benign_norm 95.704 val loss 794.983 val acc 0.097 best val_acc 0.134\n",
      "==> 183 (173, 100)\n",
      "performing detection at epoch 183\n",
      "No attack detected!\n",
      "e 183 benign_norm 195.908 val loss 584.969 val acc 0.103 best val_acc 0.134\n",
      "==> 184 (174, 100)\n",
      "performing detection at epoch 184\n",
      "No attack detected!\n",
      "e 184 benign_norm 189.935 val loss 101.094 val acc 0.103 best val_acc 0.134\n",
      "==> 185 (175, 100)\n",
      "performing detection at epoch 185\n",
      "No attack detected!\n",
      "e 185 benign_norm 88.231 val loss 66.638 val acc 0.099 best val_acc 0.134\n",
      "==> 186 (176, 100)\n",
      "performing detection at epoch 186\n",
      "No attack detected!\n",
      "e 186 benign_norm 72.675 val loss 51.443 val acc 0.110 best val_acc 0.134\n",
      "==> 187 (177, 100)\n",
      "performing detection at epoch 187\n",
      "No attack detected!\n",
      "e 187 benign_norm 85.932 val loss 20.793 val acc 0.100 best val_acc 0.134\n",
      "==> 188 (178, 100)\n",
      "performing detection at epoch 188\n",
      "No attack detected!\n",
      "e 188 benign_norm 62.848 val loss 25.596 val acc 0.103 best val_acc 0.134\n",
      "==> 189 (179, 100)\n",
      "performing detection at epoch 189\n",
      "No attack detected!\n",
      "e 189 benign_norm 66.665 val loss 21.391 val acc 0.090 best val_acc 0.134\n",
      "==> 190 (180, 100)\n",
      "performing detection at epoch 190\n",
      "No attack detected!\n",
      "e 190 benign_norm 72.133 val loss 15.333 val acc 0.105 best val_acc 0.134\n",
      "==> 191 (181, 100)\n",
      "performing detection at epoch 191\n",
      "No attack detected!\n",
      "e 191 benign_norm 63.406 val loss 11.490 val acc 0.098 best val_acc 0.134\n",
      "==> 192 (182, 100)\n",
      "performing detection at epoch 192\n",
      "No attack detected!\n",
      "e 192 benign_norm 53.347 val loss 33.811 val acc 0.097 best val_acc 0.134\n",
      "==> 193 (183, 100)\n",
      "performing detection at epoch 193\n",
      "No attack detected!\n",
      "e 193 benign_norm 86.914 val loss 58.718 val acc 0.103 best val_acc 0.134\n",
      "==> 194 (184, 100)\n",
      "performing detection at epoch 194\n",
      "No attack detected!\n",
      "e 194 benign_norm 112.056 val loss 45.323 val acc 0.091 best val_acc 0.134\n",
      "==> 195 (185, 100)\n",
      "performing detection at epoch 195\n",
      "No attack detected!\n",
      "e 195 benign_norm 88.322 val loss 71.248 val acc 0.097 best val_acc 0.134\n",
      "==> 196 (186, 100)\n",
      "performing detection at epoch 196\n",
      "No attack detected!\n",
      "e 196 benign_norm 98.820 val loss 26.023 val acc 0.113 best val_acc 0.134\n",
      "==> 197 (187, 100)\n",
      "performing detection at epoch 197\n",
      "No attack detected!\n",
      "e 197 benign_norm 50.262 val loss 48.779 val acc 0.082 best val_acc 0.134\n",
      "==> 198 (188, 100)\n",
      "performing detection at epoch 198\n",
      "No attack detected!\n",
      "e 198 benign_norm 66.095 val loss 82.807 val acc 0.090 best val_acc 0.134\n",
      "==> 199 (189, 100)\n",
      "performing detection at epoch 199\n",
      "No attack detected!\n",
      "e 199 benign_norm 101.272 val loss 162.124 val acc 0.103 best val_acc 0.134\n",
      "==> 200 (190, 100)\n",
      "performing detection at epoch 200\n",
      "No attack detected!\n",
      "e 200 benign_norm 76.229 val loss 154.973 val acc 0.102 best val_acc 0.134\n",
      "==> 201 (191, 100)\n",
      "performing detection at epoch 201\n",
      "No attack detected!\n",
      "e 201 benign_norm 102.457 val loss 152.556 val acc 0.103 best val_acc 0.134\n",
      "==> 202 (192, 100)\n",
      "performing detection at epoch 202\n",
      "No attack detected!\n",
      "e 202 benign_norm 52.160 val loss 72.626 val acc 0.100 best val_acc 0.134\n",
      "==> 203 (193, 100)\n",
      "performing detection at epoch 203\n",
      "No attack detected!\n",
      "e 203 benign_norm 61.703 val loss 37.974 val acc 0.064 best val_acc 0.134\n",
      "==> 204 (194, 100)\n",
      "performing detection at epoch 204\n",
      "No attack detected!\n",
      "e 204 benign_norm 76.136 val loss 4179.494 val acc 0.098 best val_acc 0.134\n",
      "e 210 benign_norm 73.516 val loss 172.585 val acc 0.096 best val_acc 0.134\n",
      "==> 211 (201, 100)\n",
      "performing detection at epoch 211\n",
      "No attack detected!\n",
      "e 211 benign_norm 68.449 val loss 154.552 val acc 0.095 best val_acc 0.134\n",
      "==> 212 (202, 100)\n",
      "performing detection at epoch 212\n",
      "No attack detected!\n",
      "e 212 benign_norm 64.181 val loss 112.655 val acc 0.103 best val_acc 0.134\n",
      "==> 213 (203, 100)\n",
      "performing detection at epoch 213\n",
      "No attack detected!\n",
      "e 213 benign_norm 72.197 val loss 96.893 val acc 0.100 best val_acc 0.134\n",
      "==> 214 (204, 100)\n",
      "performing detection at epoch 214\n",
      "No attack detected!\n",
      "e 214 benign_norm 69.645 val loss 67.588 val acc 0.102 best val_acc 0.134\n",
      "==> 215 (205, 100)\n",
      "performing detection at epoch 215\n",
      "No attack detected!\n",
      "e 215 benign_norm 67.316 val loss 103.458 val acc 0.087 best val_acc 0.134\n",
      "==> 216 (206, 100)\n",
      "performing detection at epoch 216\n",
      "No attack detected!\n",
      "e 216 benign_norm 65.462 val loss 172.486 val acc 0.103 best val_acc 0.134\n",
      "==> 217 (207, 100)\n",
      "performing detection at epoch 217\n",
      "No attack detected!\n",
      "e 217 benign_norm 74.837 val loss 191.614 val acc 0.097 best val_acc 0.134\n",
      "==> 218 (208, 100)\n",
      "performing detection at epoch 218\n",
      "No attack detected!\n",
      "e 218 benign_norm 71.455 val loss 135.698 val acc 0.106 best val_acc 0.134\n",
      "==> 219 (209, 100)\n",
      "performing detection at epoch 219\n",
      "No attack detected!\n",
      "e 219 benign_norm 65.375 val loss 51.534 val acc 0.102 best val_acc 0.134\n",
      "==> 220 (210, 100)\n",
      "performing detection at epoch 220\n",
      "No attack detected!\n",
      "e 220 benign_norm 106.723 val loss 82.440 val acc 0.103 best val_acc 0.134\n",
      "==> 221 (211, 100)\n",
      "performing detection at epoch 221\n",
      "No attack detected!\n",
      "e 221 benign_norm 799.288 val loss 93.045 val acc 0.093 best val_acc 0.134\n",
      "==> 222 (212, 100)\n",
      "performing detection at epoch 222\n",
      "No attack detected!\n",
      "e 222 benign_norm 764.550 val loss 144.772 val acc 0.097 best val_acc 0.134\n",
      "==> 223 (213, 100)\n",
      "performing detection at epoch 223\n",
      "No attack detected!\n",
      "e 223 benign_norm 704.489 val loss 95.200 val acc 0.103 best val_acc 0.134\n",
      "==> 224 (214, 100)\n",
      "performing detection at epoch 224\n",
      "No attack detected!\n",
      "e 224 benign_norm 686.443 val loss 45.746 val acc 0.085 best val_acc 0.134\n",
      "==> 225 (215, 100)\n",
      "performing detection at epoch 225\n",
      "No attack detected!\n",
      "e 225 benign_norm 658.296 val loss 58.055 val acc 0.095 best val_acc 0.134\n",
      "==> 226 (216, 100)\n",
      "performing detection at epoch 226\n",
      "No attack detected!\n",
      "e 226 benign_norm 634.456 val loss 43.544 val acc 0.065 best val_acc 0.134\n",
      "==> 227 (217, 100)\n",
      "performing detection at epoch 227\n",
      "No attack detected!\n",
      "e 227 benign_norm 634.248 val loss 54.342 val acc 0.103 best val_acc 0.134\n",
      "==> 228 (218, 100)\n",
      "performing detection at epoch 228\n",
      "No attack detected!\n",
      "e 228 benign_norm 612.791 val loss 49.042 val acc 0.108 best val_acc 0.134\n",
      "==> 229 (219, 100)\n",
      "performing detection at epoch 229\n",
      "No attack detected!\n",
      "e 229 benign_norm 592.336 val loss 17.002 val acc 0.115 best val_acc 0.134\n",
      "==> 230 (220, 100)\n",
      "performing detection at epoch 230\n",
      "No attack detected!\n",
      "e 230 benign_norm 569.204 val loss 18.534 val acc 0.099 best val_acc 0.134\n",
      "==> 231 (221, 100)\n",
      "performing detection at epoch 231\n",
      "No attack detected!\n",
      "e 231 benign_norm 537.361 val loss 16.804 val acc 0.100 best val_acc 0.134\n",
      "==> 232 (222, 100)\n",
      "performing detection at epoch 232\n",
      "No attack detected!\n",
      "e 232 benign_norm 499.535 val loss 13.872 val acc 0.084 best val_acc 0.134\n",
      "==> 233 (223, 100)\n",
      "performing detection at epoch 233\n",
      "No attack detected!\n",
      "e 233 benign_norm 484.357 val loss 32.335 val acc 0.100 best val_acc 0.134\n",
      "==> 234 (224, 100)\n",
      "performing detection at epoch 234\n",
      "No attack detected!\n",
      "e 234 benign_norm 449.828 val loss 48.542 val acc 0.100 best val_acc 0.134\n",
      "==> 235 (225, 100)\n",
      "performing detection at epoch 235\n",
      "No attack detected!\n",
      "e 235 benign_norm 473.242 val loss 23.778 val acc 0.103 best val_acc 0.134\n",
      "==> 236 (226, 100)\n",
      "performing detection at epoch 236\n",
      "No attack detected!\n",
      "e 236 benign_norm 461.915 val loss 121.288 val acc 0.089 best val_acc 0.134\n",
      "==> 237 (227, 100)\n",
      "performing detection at epoch 237\n",
      "No attack detected!\n",
      "e 237 benign_norm 462.911 val loss 62.339 val acc 0.121 best val_acc 0.134\n",
      "==> 238 (228, 100)\n",
      "performing detection at epoch 238\n",
      "No attack detected!\n",
      "e 238 benign_norm 433.449 val loss 42.686 val acc 0.100 best val_acc 0.134\n",
      "==> 239 (229, 100)\n",
      "performing detection at epoch 239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 239 benign_norm 417.774 val loss 21.620 val acc 0.103 best val_acc 0.134\n",
      "==> 240 (230, 100)\n",
      "performing detection at epoch 240\n",
      "No attack detected!\n",
      "e 240 benign_norm 412.920 val loss 17.440 val acc 0.103 best val_acc 0.134\n",
      "==> 241 (231, 100)\n",
      "performing detection at epoch 241\n",
      "No attack detected!\n",
      "e 241 benign_norm 399.495 val loss 16.937 val acc 0.134 best val_acc 0.134\n",
      "==> 242 (232, 100)\n",
      "performing detection at epoch 242\n",
      "No attack detected!\n",
      "e 242 benign_norm 416.271 val loss 123.739 val acc 0.099 best val_acc 0.134\n",
      "==> 243 (233, 100)\n",
      "performing detection at epoch 243\n",
      "No attack detected!\n",
      "e 243 benign_norm 403.733 val loss 56.341 val acc 0.100 best val_acc 0.134\n",
      "==> 244 (234, 100)\n",
      "performing detection at epoch 244\n",
      "No attack detected!\n",
      "e 244 benign_norm 329.984 val loss 47.508 val acc 0.103 best val_acc 0.134\n",
      "==> 245 (235, 100)\n",
      "performing detection at epoch 245\n",
      "No attack detected!\n",
      "e 245 benign_norm 307.597 val loss 42.570 val acc 0.103 best val_acc 0.134\n",
      "==> 246 (236, 100)\n",
      "performing detection at epoch 246\n",
      "No attack detected!\n",
      "e 246 benign_norm 306.706 val loss 24.521 val acc 0.097 best val_acc 0.134\n",
      "==> 247 (237, 100)\n",
      "performing detection at epoch 247\n",
      "No attack detected!\n",
      "e 247 benign_norm 304.453 val loss 180.759 val acc 0.098 best val_acc 0.134\n",
      "==> 248 (238, 100)\n",
      "performing detection at epoch 248\n",
      "No attack detected!\n",
      "e 248 benign_norm 303.725 val loss 4119.767 val acc 0.097 best val_acc 0.134\n",
      "==> 249 (239, 100)\n",
      "performing detection at epoch 249\n",
      "No attack detected!\n",
      "e 249 benign_norm 783.849 val loss 2122.439 val acc 0.103 best val_acc 0.134\n",
      "==> 250 (240, 100)\n",
      "performing detection at epoch 250\n",
      "No attack detected!\n",
      "e 250 benign_norm 780.759 val loss 918.564 val acc 0.097 best val_acc 0.134\n",
      "==> 251 (241, 100)\n",
      "performing detection at epoch 251\n",
      "No attack detected!\n",
      "e 251 benign_norm 621.587 val loss 400.093 val acc 0.103 best val_acc 0.134\n",
      "==> 252 (242, 100)\n",
      "performing detection at epoch 252\n",
      "No attack detected!\n",
      "e 252 benign_norm 595.593 val loss 521.896 val acc 0.097 best val_acc 0.134\n",
      "==> 253 (243, 100)\n",
      "performing detection at epoch 253\n",
      "No attack detected!\n",
      "e 253 benign_norm 564.494 val loss 567.589 val acc 0.098 best val_acc 0.134\n",
      "==> 254 (244, 100)\n",
      "performing detection at epoch 254\n",
      "No attack detected!\n",
      "e 254 benign_norm 486.038 val loss 448.296 val acc 0.103 best val_acc 0.134\n",
      "==> 255 (245, 100)\n",
      "performing detection at epoch 255\n",
      "No attack detected!\n",
      "e 255 benign_norm 414.827 val loss 365.467 val acc 0.100 best val_acc 0.134\n",
      "==> 256 (246, 100)\n",
      "performing detection at epoch 256\n",
      "No attack detected!\n",
      "e 256 benign_norm 315.150 val loss 5716.729 val acc 0.097 best val_acc 0.134\n",
      "==> 257 (247, 100)\n",
      "performing detection at epoch 257\n",
      "No attack detected!\n",
      "e 257 benign_norm 863.501 val loss 2318.732 val acc 0.097 best val_acc 0.134\n",
      "==> 258 (248, 100)\n",
      "performing detection at epoch 258\n",
      "No attack detected!\n",
      "e 258 benign_norm 718.467 val loss 1093.753 val acc 0.103 best val_acc 0.134\n",
      "==> 259 (249, 100)\n",
      "performing detection at epoch 259\n",
      "No attack detected!\n",
      "e 259 benign_norm 633.626 val loss 472.951 val acc 0.097 best val_acc 0.134\n",
      "==> 260 (250, 100)\n",
      "performing detection at epoch 260\n",
      "No attack detected!\n",
      "e 260 benign_norm 636.920 val loss 477.437 val acc 0.103 best val_acc 0.134\n",
      "==> 261 (251, 100)\n",
      "performing detection at epoch 261\n",
      "No attack detected!\n",
      "e 261 benign_norm 923.598 val loss 873.682 val acc 0.103 best val_acc 0.134\n",
      "==> 262 (252, 100)\n",
      "performing detection at epoch 262\n",
      "No attack detected!\n",
      "e 262 benign_norm 998.382 val loss 346.371 val acc 0.097 best val_acc 0.134\n",
      "==> 263 (253, 100)\n",
      "performing detection at epoch 263\n",
      "No attack detected!\n",
      "e 263 benign_norm 419.513 val loss 325.989 val acc 0.100 best val_acc 0.134\n",
      "==> 264 (254, 100)\n",
      "performing detection at epoch 264\n",
      "No attack detected!\n",
      "e 264 benign_norm 356.678 val loss 258.593 val acc 0.118 best val_acc 0.134\n",
      "==> 265 (255, 100)\n",
      "performing detection at epoch 265\n",
      "No attack detected!\n",
      "e 265 benign_norm 313.749 val loss 302.651 val acc 0.100 best val_acc 0.134\n",
      "==> 266 (256, 100)\n",
      "performing detection at epoch 266\n",
      "No attack detected!\n",
      "e 266 benign_norm 310.450 val loss 178.206 val acc 0.097 best val_acc 0.134\n",
      "==> 267 (257, 100)\n",
      "performing detection at epoch 267\n",
      "No attack detected!\n",
      "e 267 benign_norm 281.226 val loss 197.964 val acc 0.100 best val_acc 0.134\n",
      "==> 268 (258, 100)\n",
      "performing detection at epoch 268\n",
      "No attack detected!\n",
      "e 268 benign_norm 272.227 val loss 134.136 val acc 0.106 best val_acc 0.134\n",
      "==> 269 (259, 100)\n",
      "performing detection at epoch 269\n",
      "No attack detected!\n",
      "e 269 benign_norm 243.464 val loss 119.157 val acc 0.103 best val_acc 0.134\n",
      "==> 270 (260, 100)\n",
      "performing detection at epoch 270\n",
      "No attack detected!\n",
      "e 270 benign_norm 195.956 val loss 81.119 val acc 0.110 best val_acc 0.134\n",
      "==> 271 (261, 100)\n",
      "performing detection at epoch 271\n",
      "No attack detected!\n",
      "e 271 benign_norm 191.315 val loss 110.499 val acc 0.100 best val_acc 0.134\n",
      "==> 272 (262, 100)\n",
      "performing detection at epoch 272\n",
      "No attack detected!\n",
      "e 272 benign_norm 214.291 val loss 115.836 val acc 0.097 best val_acc 0.134\n",
      "==> 273 (263, 100)\n",
      "performing detection at epoch 273\n",
      "No attack detected!\n",
      "e 273 benign_norm 217.612 val loss 95.227 val acc 0.103 best val_acc 0.134\n",
      "==> 274 (264, 100)\n",
      "performing detection at epoch 274\n",
      "No attack detected!\n",
      "e 274 benign_norm 206.059 val loss 165.902 val acc 0.100 best val_acc 0.134\n",
      "==> 275 (265, 100)\n",
      "performing detection at epoch 275\n",
      "No attack detected!\n",
      "e 275 benign_norm 226.302 val loss 269.019 val acc 0.103 best val_acc 0.134\n",
      "==> 276 (266, 100)\n",
      "performing detection at epoch 276\n",
      "No attack detected!\n",
      "e 276 benign_norm 219.980 val loss 206.121 val acc 0.101 best val_acc 0.134\n",
      "==> 277 (267, 100)\n",
      "performing detection at epoch 277\n",
      "No attack detected!\n",
      "e 277 benign_norm 218.750 val loss 212.113 val acc 0.103 best val_acc 0.134\n",
      "==> 278 (268, 100)\n",
      "performing detection at epoch 278\n",
      "No attack detected!\n",
      "e 278 benign_norm 213.995 val loss 174.339 val acc 0.094 best val_acc 0.134\n",
      "==> 279 (269, 100)\n",
      "performing detection at epoch 279\n",
      "No attack detected!\n",
      "e 279 benign_norm 181.301 val loss 156.917 val acc 0.098 best val_acc 0.134\n",
      "==> 280 (270, 100)\n",
      "performing detection at epoch 280\n",
      "No attack detected!\n",
      "e 280 benign_norm 235.146 val loss 128.723 val acc 0.094 best val_acc 0.134\n",
      "==> 281 (271, 100)\n",
      "performing detection at epoch 281\n",
      "No attack detected!\n",
      "e 281 benign_norm 223.319 val loss 319.090 val acc 0.103 best val_acc 0.134\n",
      "==> 282 (272, 100)\n",
      "performing detection at epoch 282\n",
      "No attack detected!\n",
      "e 282 benign_norm 384.606 val loss 7667.135 val acc 0.100 best val_acc 0.134\n",
      "==> 283 (273, 100)\n",
      "performing detection at epoch 283\n",
      "No attack detected!\n",
      "e 283 benign_norm 696.148 val loss 18198.031 val acc 0.103 best val_acc 0.134\n",
      "==> 284 (274, 100)\n",
      "performing detection at epoch 284\n",
      "No attack detected!\n",
      "e 284 benign_norm 1714.328 val loss 9916.272 val acc 0.103 best val_acc 0.134\n",
      "==> 285 (275, 100)\n",
      "performing detection at epoch 285\n",
      "No attack detected!\n",
      "e 285 benign_norm 1672.743 val loss 4489.533 val acc 0.100 best val_acc 0.134\n",
      "==> 286 (276, 100)\n",
      "performing detection at epoch 286\n",
      "No attack detected!\n",
      "e 286 benign_norm 794.790 val loss 22610.271 val acc 0.097 best val_acc 0.134\n",
      "==> 287 (277, 100)\n",
      "performing detection at epoch 287\n",
      "No attack detected!\n",
      "e 287 benign_norm 1406.553 val loss 3616.022 val acc 0.100 best val_acc 0.134\n",
      "==> 288 (278, 100)\n",
      "performing detection at epoch 288\n",
      "No attack detected!\n",
      "e 288 benign_norm 863.289 val loss 2337.341 val acc 0.100 best val_acc 0.134\n",
      "==> 289 (279, 100)\n",
      "performing detection at epoch 289\n",
      "No attack detected!\n",
      "e 289 benign_norm 747.169 val loss 1397.037 val acc 0.103 best val_acc 0.134\n",
      "==> 290 (280, 100)\n",
      "performing detection at epoch 290\n",
      "No attack detected!\n",
      "e 290 benign_norm 565.140 val loss 1748.968 val acc 0.103 best val_acc 0.134\n",
      "==> 291 (281, 100)\n",
      "performing detection at epoch 291\n",
      "No attack detected!\n",
      "e 291 benign_norm 739.217 val loss 1631.891 val acc 0.103 best val_acc 0.134\n",
      "==> 292 (282, 100)\n",
      "performing detection at epoch 292\n",
      "No attack detected!\n",
      "e 292 benign_norm 761.071 val loss 1192.197 val acc 0.096 best val_acc 0.134\n",
      "==> 293 (283, 100)\n",
      "performing detection at epoch 293\n",
      "No attack detected!\n",
      "e 293 benign_norm 787.944 val loss 1448.382 val acc 0.103 best val_acc 0.134\n",
      "==> 294 (284, 100)\n",
      "performing detection at epoch 294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No attack detected!\n",
      "e 294 benign_norm 829.469 val loss 945.743 val acc 0.098 best val_acc 0.134\n",
      "==> 295 (285, 100)\n",
      "performing detection at epoch 295\n",
      "No attack detected!\n",
      "e 295 benign_norm 649.063 val loss 1415.260 val acc 0.100 best val_acc 0.134\n",
      "==> 296 (286, 100)\n",
      "performing detection at epoch 296\n",
      "No attack detected!\n",
      "e 296 benign_norm 696.790 val loss 1228.139 val acc 0.095 best val_acc 0.134\n",
      "==> 297 (287, 100)\n",
      "performing detection at epoch 297\n",
      "No attack detected!\n",
      "e 297 benign_norm 614.678 val loss 1410.003 val acc 0.103 best val_acc 0.134\n",
      "==> 298 (288, 100)\n",
      "performing detection at epoch 298\n",
      "No attack detected!\n",
      "e 298 benign_norm 644.848 val loss 1219.252 val acc 0.088 best val_acc 0.134\n",
      "==> 299 (289, 100)\n",
      "performing detection at epoch 299\n",
      "No attack detected!\n",
      "e 299 benign_norm 653.679 val loss 1361.169 val acc 0.094 best val_acc 0.134\n",
      "==> 300 (290, 100)\n",
      "performing detection at epoch 300\n",
      "No attack detected!\n",
      "e 300 benign_norm 477.870 val loss 5569.326 val acc 0.103 best val_acc 0.134\n",
      "==> 301 (291, 100)\n",
      "performing detection at epoch 301\n",
      "No attack detected!\n",
      "e 301 benign_norm 1031.770 val loss 3934.124 val acc 0.091 best val_acc 0.134\n",
      "==> 302 (292, 100)\n",
      "performing detection at epoch 302\n",
      "No attack detected!\n",
      "e 302 benign_norm 960.390 val loss 3281.167 val acc 0.100 best val_acc 0.134\n",
      "==> 303 (293, 100)\n",
      "performing detection at epoch 303\n",
      "No attack detected!\n",
      "e 303 benign_norm 1021.259 val loss 1411.954 val acc 0.100 best val_acc 0.134\n",
      "==> 304 (294, 100)\n",
      "performing detection at epoch 304\n",
      "No attack detected!\n",
      "e 304 benign_norm 717.593 val loss 1639.813 val acc 0.100 best val_acc 0.134\n",
      "==> 305 (295, 100)\n",
      "performing detection at epoch 305\n",
      "No attack detected!\n",
      "e 305 benign_norm 686.055 val loss 2430.744 val acc 0.103 best val_acc 0.134\n",
      "==> 306 (296, 100)\n",
      "performing detection at epoch 306\n",
      "No attack detected!\n",
      "e 306 benign_norm 771.969 val loss 2404.195 val acc 0.097 best val_acc 0.134\n",
      "==> 307 (297, 100)\n",
      "performing detection at epoch 307\n",
      "No attack detected!\n",
      "e 307 benign_norm 702.495 val loss 4002.897 val acc 0.103 best val_acc 0.134\n",
      "==> 308 (298, 100)\n",
      "performing detection at epoch 308\n",
      "No attack detected!\n",
      "e 308 benign_norm 811.850 val loss 1774.813 val acc 0.097 best val_acc 0.134\n",
      "==> 309 (299, 100)\n",
      "performing detection at epoch 309\n",
      "No attack detected!\n",
      "e 309 benign_norm 566.360 val loss 1052.314 val acc 0.095 best val_acc 0.134\n",
      "==> 310 (300, 100)\n",
      "performing detection at epoch 310\n",
      "No attack detected!\n",
      "e 310 benign_norm 461.320 val loss 914.788 val acc 0.100 best val_acc 0.134\n",
      "==> 311 (301, 100)\n",
      "performing detection at epoch 311\n",
      "No attack detected!\n",
      "e 311 benign_norm 466.558 val loss 1932.388 val acc 0.097 best val_acc 0.134\n",
      "==> 312 (302, 100)\n",
      "performing detection at epoch 312\n",
      "No attack detected!\n",
      "e 312 benign_norm 577.273 val loss 762.598 val acc 0.103 best val_acc 0.134\n",
      "==> 313 (303, 100)\n",
      "performing detection at epoch 313\n",
      "No attack detected!\n",
      "e 313 benign_norm 466.100 val loss 567.171 val acc 0.106 best val_acc 0.134\n",
      "==> 314 (304, 100)\n",
      "performing detection at epoch 314\n",
      "No attack detected!\n",
      "e 314 benign_norm 474.136 val loss 483.724 val acc 0.098 best val_acc 0.134\n",
      "==> 315 (305, 100)\n",
      "performing detection at epoch 315\n",
      "No attack detected!\n",
      "e 315 benign_norm 621.240 val loss 793.283 val acc 0.100 best val_acc 0.134\n",
      "==> 316 (306, 100)\n",
      "performing detection at epoch 316\n",
      "No attack detected!\n",
      "e 316 benign_norm 554.117 val loss 1367.670 val acc 0.097 best val_acc 0.134\n",
      "==> 317 (307, 100)\n",
      "performing detection at epoch 317\n",
      "No attack detected!\n",
      "e 317 benign_norm 798.638 val loss 5933.573 val acc 0.103 best val_acc 0.134\n",
      "==> 318 (308, 100)\n",
      "performing detection at epoch 318\n",
      "No attack detected!\n",
      "e 318 benign_norm 479.229 val loss 1735336.500 val acc 0.097 best val_acc 0.134\n",
      "val loss 1735336.500000... exit\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "local_epochs = 1\n",
    "batch_size = 32\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 1\n",
    "global_lr = .5\n",
    "nepochs = 1000\n",
    "\n",
    "aggregation = 'trim'\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "# each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "#     all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "# train_loaders = []\n",
    "# for pos, indices in enumerate(each_worker_idx):\n",
    "#     train_loaders.append((pos, get_train(all_data, indices, len(indices))))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "start_detection_epoch = 10\n",
    "window_size = 10\n",
    "assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "nbyz = int(num_workers * 0.28)\n",
    "good_distance_rage = np.zeros((1, nbyz))\n",
    "malicious_scores = np.zeros((1, num_workers))\n",
    "init_attack = 'full_trim'\n",
    "attack_type = 'NDSS21'\n",
    "dev_type = 'std'\n",
    "weight_record = []\n",
    "grad_record = []\n",
    "test_grads = []\n",
    "old_grad_list = []\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "#         optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.99**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        if init_attack == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif init_attack == 'LIE':\n",
    "            z = 0.01\n",
    "            noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "            noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "            noise = noise_avg + z * noise_std\n",
    "            user_grads[:nbyz] = torch.stack(nbyz * [noise])\n",
    "\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                z = 0.01\n",
    "#                 noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "#     agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "    model_received = model_received + global_lr * (0.999 ** epoch_num) * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "\n",
    "    if epoch_num%1==0 or epoch_num==nepochs-1:\n",
    "        val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "        is_best = best_global_acc < val_acc\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f' % (\n",
    "            epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504ec30",
   "metadata": {},
   "source": [
    "# Fast baseline + Fang + FLDetector + attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "nepochs=200\n",
    "local_epochs = 2\n",
    "batch_size = 8\n",
    "num_workers = 100\n",
    "\n",
    "local_lr = 0.1\n",
    "global_lr = 1\n",
    "\n",
    "nbyz = 28\n",
    "byz_type = 'full_trim'\n",
    "aggregation = 'trim'\n",
    "\n",
    "\n",
    "all_data = torch.utils.data.ConcatDataset((cifar10_train, cifar10_test))\n",
    "all_test_data = torch.utils.data.ConcatDataset((te_cifar10_train, te_cifar10_test))\n",
    "\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "# each_worker_idx, each_worker_te_idx, global_test_idx = get_federated_data(\n",
    "#     all_data, num_workers=100, distribution=distribution, param=param, force=force)\n",
    "# train_loaders = []\n",
    "# for pos, indices in enumerate(each_worker_idx):\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_data, indices, batch_size)))\n",
    "# test_loaders = []\n",
    "# for pos, indices in each_worker_te_idx.items():\n",
    "#     batch_size = batch_size\n",
    "#     train_loaders.append((pos, get_train(all_test_data, indices, len(indices))))\n",
    "cifar10_test_loader = get_train(all_test_data, global_test_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "resume=False\n",
    "round_nclients = num_workers\n",
    "best_global_acc=0\n",
    "epoch_num = 0\n",
    "\n",
    "fed_model = resnet20().cuda()\n",
    "\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "while epoch_num <= nepochs:\n",
    "    torch.cuda.empty_cache()\n",
    "    round_clients = np.arange(nbyz, num_workers)\n",
    "    round_benign = round_clients\n",
    "    user_grads=[]\n",
    "    benign_norm = 0\n",
    "    for i in round_benign:\n",
    "        model = copy.deepcopy(fed_model)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = local_lr*(0.999**epoch_num), momentum=0.9, weight_decay=1e-4)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            train_loss, train_acc = train(train_loaders[i][1], model, model_received, criterion, optimizer)\n",
    "\n",
    "        params = []\n",
    "        for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "            params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat((params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        update =  (params - model_received)\n",
    "        benign_norm += torch.norm(update)/len(round_benign)\n",
    "        user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "    weight = copy.deepcopy(model_received)\n",
    "\n",
    "    if (epoch_num > start_detection_epoch):\n",
    "        hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "        hvp = np.squeeze(hvp)\n",
    "    else:\n",
    "        hvp = None\n",
    "\n",
    "    good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "    if hvp is not None:\n",
    "        pred_grad = copy.deepcopy(good_old_grads)\n",
    "        distance = []\n",
    "        for i in range(len(good_old_grads)):\n",
    "            pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "        good_distance_rage = np.concatenate(\n",
    "            (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "        \n",
    "    if attack_type != 'none' and (epoch_num < start_detection_epoch):\n",
    "        if init_attack == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif init_attack == 'LIE':\n",
    "            z = 0.01\n",
    "            noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "            noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "            noise = noise_avg + z * noise_std\n",
    "            user_grads[:nbyz] = torch.stack(nbyz * [noise])\n",
    "\n",
    "    elif epoch_num > start_detection_epoch:\n",
    "        if attack_type == 'full_trim':\n",
    "            user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif attack_type == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            if attack_type == 'LIE':\n",
    "                z = 0.01\n",
    "#                 noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                noise = noise_std\n",
    "            elif attack_type == 'NDSS21':\n",
    "                distance_bound = np.mean(np.mean(good_distance_rage[-1:], 0))\n",
    "                model_re = torch.mean(good_current_grads, dim=0)\n",
    "                if dev_type == 'unit_vec':\n",
    "                    deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                elif dev_type == 'sign':\n",
    "                    deviation = torch.sign(model_re)\n",
    "                elif dev_type == 'std':\n",
    "                    deviation = torch.std(good_current_grads, 0)\n",
    "                noise = deviation * (distance_bound / torch.norm(deviation))\n",
    "            elif attack_type == 'mod_trim':\n",
    "                mal_grads= full_trim(user_grads[:nbyz], nbyz)\n",
    "                pass\n",
    "            else:\n",
    "                noise = torch.zeros(hvp.shape).to(device)\n",
    "            for m in range(nbyz):\n",
    "                user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "#     agg_grads, distance = simple_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    agg_grads, distance = trimmed_mean(old_grad_list, user_grads, nbyz, hvp)\n",
    "    \n",
    "    if distance is not None and epoch_num > (start_detection_epoch - window_size):\n",
    "        print('==>', epoch_num, malicious_scores.shape)\n",
    "        malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "    if malicious_scores.shape[0] >= (window_size+1):\n",
    "        print('performing detection at epoch %d' % epoch_num)\n",
    "        if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "            print('Stop at iteration:', epoch_num)\n",
    "            detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz)\n",
    "            break\n",
    "\n",
    "    if epoch_num > (start_detection_epoch - window_size):\n",
    "        weight_record.append(weight - last_weight)\n",
    "        grad_record.append(agg_grads - last_grad)\n",
    "    \n",
    "    if (len(weight_record) > 10):\n",
    "        del weight_record[0]\n",
    "        del grad_record[0]\n",
    "    \n",
    "    last_weight = weight\n",
    "    last_grad = agg_grads\n",
    "    old_grad_list = user_grads\n",
    "    good_old_grads = good_current_grads\n",
    "\n",
    "    del user_grads\n",
    "\n",
    "    model_received = model_received + global_lr * agg_grads\n",
    "    fed_model = resnet20().cuda()\n",
    "    start_idx=0\n",
    "    state_dict = {}\n",
    "    previous_name = 'none'\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "        start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "        params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "        state_dict[name] = params\n",
    "        previous_name = name\n",
    "\n",
    "    fed_model.load_state_dict(state_dict)\n",
    "    val_loss, val_acc = test(cifar10_test_loader, fed_model, criterion)\n",
    "    is_best = best_global_acc < val_acc\n",
    "    best_global_acc = max(best_global_acc, val_acc)\n",
    "    \n",
    "    if epoch_num%10==0 or epoch_num==nepochs-1:\n",
    "        print('e %d benign_norm %.3f val loss %.3f val acc %.3f best val_acc %.3f'% (epoch_num, benign_norm, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "    if math.isnan(val_loss) or val_loss > 100000:\n",
    "        print('val loss %f... exit'%val_loss)\n",
    "        break\n",
    "\n",
    "    epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d5a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd2533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
