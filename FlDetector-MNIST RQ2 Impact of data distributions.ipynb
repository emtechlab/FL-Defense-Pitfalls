{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900c792f",
   "metadata": {},
   "source": [
    "# FLDetector for MNIST with Fang/Dirichlet distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821b1014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gypsum-gpu067/6138700/ipykernel_1680552/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbef18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.insert(0,'./utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from SGD import *\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a52c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26708069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dirichlet_train_data(trainset, no_participants, alpha=0.9, force=False):\n",
    "        \"\"\"\n",
    "            Input: Number of participants and alpha (param for distribution)\n",
    "            Output: A list of indices denoting data in CIFAR training set.\n",
    "            Requires: cifar_classes, a preprocessed class-indice dictionary.\n",
    "            Sample Method: take a uniformly sampled 10-dimension vector as parameters for\n",
    "            dirichlet distribution to sample number of images in each class.\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants)) or force:\n",
    "            print('generating participant indices for alpha %.1f'%alpha)\n",
    "            np.random.seed(0)\n",
    "            cifar_classes = {}\n",
    "            for ind, x in enumerate(trainset):\n",
    "                _, label = x\n",
    "                if label in cifar_classes:\n",
    "                    cifar_classes[label].append(ind)\n",
    "                else:\n",
    "                    cifar_classes[label] = [ind]\n",
    "\n",
    "            per_participant_list = defaultdict(list)\n",
    "            no_classes = len(cifar_classes.keys())\n",
    "            for n in range(no_classes):\n",
    "                random.shuffle(cifar_classes[n])\n",
    "                sampled_probabilities = len(cifar_classes[n]) * np.random.dirichlet(\n",
    "                    np.array(no_participants * [alpha]))\n",
    "                for user in range(no_participants):\n",
    "                    no_imgs = int(round(sampled_probabilities[user]))\n",
    "                    sampled_list = cifar_classes[n][:min(len(cifar_classes[n]), no_imgs)]\n",
    "                    per_participant_list[user].extend(sampled_list)\n",
    "                    cifar_classes[n] = cifar_classes[n][min(len(cifar_classes[n]), no_imgs):]\n",
    "            with open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'wb') as f:\n",
    "                pickle.dump(per_participant_list, f)\n",
    "        else:\n",
    "            per_participant_list = pickle.load(open('./dirichlet_a_%.1f_nusers_%d.pkl'%(alpha, no_participants), 'rb'))\n",
    "            \n",
    "        return per_participant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c258374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_train_data(trainset, num_workers=100, bias=0.5):\n",
    "    np.random.seed(0)\n",
    "    bias_weight = bias\n",
    "    other_group_size = (1 - bias_weight) / 9.\n",
    "    worker_per_group = num_workers / 10\n",
    "\n",
    "    each_worker_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_label = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    for i, (x, y) in enumerate(trainset):\n",
    "        # assign a data point to a group\n",
    "        upper_bound = (y) * (1 - bias_weight) / 9. + bias_weight\n",
    "        lower_bound = (y) * (1 - bias_weight) / 9.\n",
    "        rd = np.random.random_sample()\n",
    "\n",
    "        if rd > upper_bound:\n",
    "            worker_group = int(np.floor((rd - upper_bound) / other_group_size) + y + 1)\n",
    "        elif rd < lower_bound:\n",
    "            worker_group = int(np.floor(rd / other_group_size))\n",
    "        else:\n",
    "            worker_group = y\n",
    "\n",
    "        rd = np.random.random_sample()\n",
    "        selected_worker = int(worker_group * worker_per_group + int(np.floor(rd * worker_per_group)))\n",
    "        \n",
    "        if not len(each_worker_data[selected_worker]):\n",
    "            each_worker_data[selected_worker] = x[None, :]\n",
    "        else:\n",
    "            each_worker_data[selected_worker]= torch.concat((each_worker_data[selected_worker], x[None, :]))\n",
    "        \n",
    "        each_worker_label[selected_worker].append(y)\n",
    "    \n",
    "    each_worker_tr_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_tr_label = [[] for _ in range(num_workers)]\n",
    "    each_worker_te_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_te_label = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    for i in range(num_workers):\n",
    "        w_len = len(each_worker_data[i])\n",
    "        len_tr = int(6 * w_len / 7)\n",
    "        len_te = w_len - len_tr\n",
    "        tr_idx = np.random.choice(w_len, len_tr, replace=False)\n",
    "        te_idx = np.delete(np.arange(w_len), tr_idx)\n",
    "        each_worker_tr_data[i] = each_worker_data[i][tr_idx]\n",
    "        each_worker_tr_label[i] = torch.Tensor(each_worker_label[i])[tr_idx]\n",
    "        \n",
    "        each_worker_te_data[i] = each_worker_data[i][te_idx]\n",
    "        each_worker_te_label[i] = torch.Tensor(each_worker_label[i])[te_idx]\n",
    "        \n",
    "    global_test_data = torch.concat(each_worker_te_data)\n",
    "    global_test_label = torch.concat(each_worker_te_label)\n",
    "    del each_worker_data, each_worker_label\n",
    "    return each_worker_tr_data, each_worker_tr_label, each_worker_te_data, each_worker_te_label, global_test_data, global_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f36f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_data_dirichlet(trainset, num_workers, alpha=1, force=False):\n",
    "    per_participant_list = sample_dirichlet_train_data(trainset, num_workers, alpha=alpha, force=force)\n",
    "    \n",
    "    each_worker_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_label = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    each_worker_te_data = [[] for _ in range(num_workers)]\n",
    "    each_worker_te_label = [[] for _ in range(num_workers)]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    for worker_idx in range(len(per_participant_list)):\n",
    "        w_indices = np.array(per_participant_list[worker_idx])\n",
    "        w_len = len(w_indices)\n",
    "        len_tr = int(6*w_len/7)\n",
    "        len_te = w_len - len_tr\n",
    "        tr_idx = np.random.choice(w_len, len_tr, replace=False)\n",
    "        te_idx = np.delete(np.arange(w_len), tr_idx)\n",
    "        \n",
    "        for idx in tr_idx:\n",
    "            each_worker_data[worker_idx].append(trainset[idx][0])\n",
    "            each_worker_label[worker_idx].append(trainset[idx][1])\n",
    "        each_worker_data[worker_idx] = torch.stack(each_worker_data[worker_idx])\n",
    "        each_worker_label[worker_idx] = torch.Tensor(each_worker_label[worker_idx]).long()\n",
    "        \n",
    "        for idx in te_idx:\n",
    "            each_worker_te_data[worker_idx].append(trainset[idx][0])\n",
    "            each_worker_te_label[worker_idx].append(trainset[idx][1])\n",
    "        each_worker_te_data[worker_idx] = torch.stack(each_worker_te_data[worker_idx])\n",
    "        each_worker_te_label[worker_idx] = torch.Tensor(each_worker_te_label[worker_idx]).long()\n",
    "    \n",
    "    global_test_data = torch.concat(each_worker_te_data)\n",
    "    global_test_label = torch.concat(each_worker_te_label)\n",
    "    \n",
    "    return each_worker_data, each_worker_label, each_worker_te_data, each_worker_te_label, global_test_data, global_test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e35368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_trim(v, f):\n",
    "    '''\n",
    "    Full-knowledge Trim attack. w.l.o.g., we assume the first f worker devices are compromised.\n",
    "    v: the list of squeezed gradients\n",
    "    f: the number of compromised worker devices\n",
    "    '''\n",
    "    vi_shape = v[0].unsqueeze(0).T.shape\n",
    "    v_tran = v.T\n",
    "    \n",
    "    maximum_dim = torch.max(v_tran, dim=1)\n",
    "    maximum_dim = maximum_dim[0].reshape(vi_shape)\n",
    "    minimum_dim = torch.min(v_tran, dim=1)\n",
    "    minimum_dim = minimum_dim[0].reshape(vi_shape)\n",
    "    direction = torch.sign(torch.sum(v_tran, dim=-1, keepdims=True))\n",
    "    directed_dim = (direction > 0) * minimum_dim + (direction < 0) * maximum_dim\n",
    "\n",
    "    for i in range(f):\n",
    "        random_12 = 2\n",
    "        tmp = directed_dim * ((direction * directed_dim > 0) / random_12 + (direction * directed_dim < 0) * random_12)\n",
    "        tmp = tmp.squeeze()\n",
    "        v[i] = tmp\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2f5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_mean(all_updates, n_attackers):\n",
    "    sorted_updates = torch.sort(all_updates, 0)[0]\n",
    "    out = torch.mean(sorted_updates[n_attackers:-n_attackers], 0) if n_attackers else torch.mean(sorted_updates,0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6b5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(30, 50, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(800, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc271f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model params is 453572\n"
     ]
    }
   ],
   "source": [
    "fed_model = cnn().cuda()\n",
    "model_received = []\n",
    "for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "    model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(\n",
    "        model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "print(f'Number of model params is {len(model_received)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17acb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def fldetector(old_gradients, user_grads, b=0, hvp=None, agr='tr_mean'):\n",
    "    if hvp is not None:\n",
    "        hvp = torch.from_numpy(hvp).to(device)\n",
    "        pred_grad = copy.deepcopy(old_gradients)\n",
    "        distance = []\n",
    "        for i in range(len(old_gradients)):\n",
    "            pred_grad[i] += hvp\n",
    "        pred = np.zeros(100)\n",
    "        pred[:b] = 1\n",
    "        distance = torch.norm(pred_grad - user_grads, dim = 1).cpu().numpy()\n",
    "        distance = distance / np.sum(distance)\n",
    "    else:\n",
    "        distance = None\n",
    "    \n",
    "    if agr == 'average':\n",
    "        agg_grads = torch.mean(user_grads, 0)\n",
    "    elif agr == 'median':\n",
    "        agg_grads = torch.median(user_grads, 0)[0]\n",
    "    elif agr == 'tr_mean':\n",
    "        agg_grads = tr_mean(user_grads, b)\n",
    "    return agg_grads, distance\n",
    "\n",
    "def lbfgs(S_k_list, Y_k_list, v):\n",
    "    curr_S_k = torch.stack(S_k_list).T\n",
    "    curr_Y_k = torch.stack(Y_k_list).T\n",
    "    S_k_time_Y_k = np.dot(curr_S_k.T.cpu().numpy(), curr_Y_k.cpu().numpy())\n",
    "    S_k_time_S_k = np.dot(curr_S_k.T.cpu().numpy(), curr_S_k.cpu().numpy())\n",
    "    R_k = np.triu(S_k_time_Y_k)\n",
    "    L_k = S_k_time_Y_k - R_k\n",
    "    sigma_k = np.dot(Y_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()) / (np.dot(S_k_list[-1].unsqueeze(0).cpu().numpy(), S_k_list[-1].unsqueeze(0).T.cpu().numpy()))\n",
    "    D_k_diag = np.diag(S_k_time_Y_k)\n",
    "    upper_mat = np.concatenate((sigma_k * S_k_time_S_k, L_k), axis=1)\n",
    "    lower_mat = np.concatenate((L_k.T, -np.diag(D_k_diag)), axis=1)\n",
    "    mat = np.concatenate((upper_mat, lower_mat), axis=0)\n",
    "    mat_inv = np.linalg.inv(mat)\n",
    "\n",
    "    approx_prod = sigma_k * v.cpu().numpy()\n",
    "    approx_prod = approx_prod.T\n",
    "    p_mat = np.concatenate((np.dot(curr_S_k.T.cpu().numpy(), sigma_k * v.unsqueeze(0).T.cpu().numpy()), np.dot(curr_Y_k.T.cpu().numpy(), v.unsqueeze(0).T.cpu().numpy())), axis=0)\n",
    "    approx_prod -= np.dot(np.dot(np.concatenate((sigma_k * curr_S_k.cpu().numpy(), curr_Y_k.cpu().numpy()), axis=1), mat_inv), p_mat)\n",
    "\n",
    "    return approx_prod\n",
    "\n",
    "def detection(score, nobyz, nworkers):\n",
    "    estimator = KMeans(n_clusters=2)\n",
    "    estimator.fit(score.reshape(-1, 1))\n",
    "    label_pred = estimator.labels_\n",
    "    if np.mean(score[label_pred==0])<np.mean(score[label_pred==1]):\n",
    "        #0 is the label of malicious clients\n",
    "        label_pred = 1 - label_pred\n",
    "    real_label=np.ones(nworkers)\n",
    "    real_label[:nobyz]=0\n",
    "    acc=len(label_pred[label_pred==real_label])/nworkers\n",
    "    recall=1-np.sum(label_pred[:nobyz])/nobyz\n",
    "    fpr=1-np.sum(label_pred[nobyz:])/(nworkers-nobyz)\n",
    "    fnr=np.sum(label_pred[:nobyz])/nobyz\n",
    "    try:\n",
    "        auc = roc_auc_score(real_label, label_pred)\n",
    "    except:\n",
    "        auc = -1\n",
    "    print(\"acc %0.4f; recall %0.4f; fpr %0.4f; fnr %0.4f; auc %.4f\" % (acc, recall, fpr, fnr, auc))\n",
    "    return acc, fpr, fnr, auc\n",
    "    # print(silhouette_score(score.reshape(-1, 1), label_pred))\n",
    "\n",
    "def detection1(score, nobyz):\n",
    "    nrefs = 10\n",
    "    ks = range(1, 8)\n",
    "    gaps = np.zeros(len(ks))\n",
    "    gapDiff = np.zeros(len(ks) - 1)\n",
    "    sdk = np.zeros(len(ks))\n",
    "    min = np.min(score)\n",
    "    max = np.max(score)\n",
    "    score = (score - min)/(max-min)\n",
    "    for i, k in enumerate(ks):\n",
    "        estimator = KMeans(n_clusters=k)\n",
    "        estimator.fit(score.reshape(-1, 1))\n",
    "        label_pred = estimator.labels_\n",
    "        center = estimator.cluster_centers_\n",
    "        Wk = np.sum([np.square(score[m]-center[label_pred[m]]) for m in range(len(score))])\n",
    "        WkRef = np.zeros(nrefs)\n",
    "        for j in range(nrefs):\n",
    "            rand = np.random.uniform(0, 1, len(score))\n",
    "            estimator = KMeans(n_clusters=k)\n",
    "            estimator.fit(rand.reshape(-1, 1))\n",
    "            label_pred = estimator.labels_\n",
    "            center = estimator.cluster_centers_\n",
    "            WkRef[j] = np.sum([np.square(rand[m]-center[label_pred[m]]) for m in range(len(rand))])\n",
    "        gaps[i] = np.log(np.mean(WkRef)) - np.log(Wk)\n",
    "        sdk[i] = np.sqrt((1.0 + nrefs) / nrefs) * np.std(np.log(WkRef))\n",
    "\n",
    "        if i > 0:\n",
    "            gapDiff[i - 1] = gaps[i - 1] - gaps[i] + sdk[i]\n",
    "    #print(gapDiff)\n",
    "    for i in range(len(gapDiff)):\n",
    "        if gapDiff[i] >= 0:\n",
    "            select_k = i+1\n",
    "            break\n",
    "    if select_k == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        # print('Attack Detected!')\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b14be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "def train(train_data, labels, model, optimizer, batch_size=20):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    len_t = (len(train_data) // batch_size)\n",
    "    if len(train_data)%batch_size:\n",
    "        len_t += 1\n",
    "    r=np.arange(len(train_data))\n",
    "    np.random.shuffle(r)\n",
    "    train_data = train_data[r]\n",
    "    labels = labels[r]\n",
    "    for ind in range(len_t):\n",
    "        inputs = train_data[ind * batch_size:(ind + 1) * batch_size].cuda()\n",
    "        targets = labels[ind * batch_size:(ind + 1) * batch_size].cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return (losses.avg, top1.avg)\n",
    "\n",
    "\n",
    "def test(test_data, labels, model, criterion, use_cuda, debug_='MEDIUM', batch_size=64):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    model.eval()\n",
    "    len_t = (len(test_data) // batch_size)\n",
    "    if len(test_data)%batch_size:\n",
    "        len_t += 1\n",
    "    with torch.no_grad():\n",
    "        for ind in range(len_t):\n",
    "            inputs = test_data[ind * batch_size:(ind + 1) * batch_size].cuda()\n",
    "            targets = labels[ind * batch_size:(ind + 1) * batch_size].cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(prec1.item(), inputs.size(0))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace04bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = torch.utils.data.ConcatDataset((trainset, testset))\n",
    "num_workers = 100\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "\n",
    "if distribution=='fang':\n",
    "    each_worker_data, each_worker_label, each_worker_te_data, each_worker_te_label, global_test_data, global_test_label = get_client_train_data(all_data, num_workers=100, bias=param)\n",
    "elif distribution == 'dirichlet':\n",
    "    each_worker_data, each_worker_label, each_worker_te_data, each_worker_te_label, global_test_data, global_test_label = get_client_data_dirichlet(all_data, num_workers, alpha=param, force=force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6bb7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb9dd7",
   "metadata": {},
   "source": [
    "# Histogram of number of samples / client for Fang and Dirichlet distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f49b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([30., 21., 15., 13.,  7.,  3.,  4.,  1.,  3.,  3.]),\n",
       " array([   3. ,  227.2,  451.4,  675.6,  899.8, 1124. , 1348.2, 1572.4,\n",
       "        1796.6, 2020.8, 2245. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_lens_dirichlet = [len(d) for d in each_worker_data]\n",
    "plt.hist(d_lens)\n",
    "plt.hist(d_lens_dirichlet, alpha=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d70d30",
   "metadata": {},
   "source": [
    "# Fast baseline results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050a1d3",
   "metadata": {},
   "source": [
    "# MNIST + some client with noisy Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a779827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 | val_loss 1.537 val acc 74.061 | best val_acc 74.061\n",
      "e 5 | val_loss 0.168 val acc 95.229 | best val_acc 95.229\n",
      "Stop at iteration: 10\n",
      "acc 1.0000; recall 1.0000; fpr 0.0000; fnr 0.0000; auc 1.0000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FAST BASELINE\n",
    "'''\n",
    "n_malicious = [10]\n",
    "\n",
    "for n_mal in n_malicious:\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        # delete all variables\n",
    "        del weight_record, grad_record, old_grad_list, num_workers, malicious_scores, start_detection_epoch, window_size\n",
    "        del good_distance_rage\n",
    "        del nepochs, num_workers, local_lr, local_epochs, global_lr, agr\n",
    "        del attack_type, dev_type, fed_model\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # FL training initializations\n",
    "    num_workers = 100\n",
    "    use_cuda = True\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    local_lr=0.01\n",
    "    local_batch_size=32\n",
    "    local_epochs=2\n",
    "    global_lr=1\n",
    "    agr='tr_mean' # ['average', 'median', 'tr_mean']\n",
    "\n",
    "    # Attack initializations\n",
    "    attack_type = 'none'\n",
    "    dev_type = 'sign'\n",
    "    nbyz = n_mal\n",
    "\n",
    "    # FLD initializations\n",
    "    weight_record = []\n",
    "    grad_record = []\n",
    "    old_grad_list = []\n",
    "    malicious_scores = np.zeros((1, num_workers))\n",
    "    start_detection_epoch = 5\n",
    "    window_size = 5\n",
    "    assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "    good_distance_rage = np.zeros((1, nbyz))\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "\n",
    "    # FL model initializations\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    fed_model = cnn().to(device)\n",
    "    fed_model.apply(init_weights)\n",
    "    model_received = []\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "    for e in range(50):\n",
    "        user_grads=[]\n",
    "        round_clients = np.arange(num_workers)\n",
    "        round_benign = round_clients\n",
    "        user_grads=[]\n",
    "\n",
    "        for i in round_benign:\n",
    "            model = copy.deepcopy(fed_model)\n",
    "            optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "            if i < n_mal:\n",
    "                for epoch in range(local_epochs):\n",
    "                    train_loss, train_acc = train(\n",
    "                        each_worker_data[i].reshape(-1, 1, 28, 28),\n",
    "                        torch.Tensor((np.random.choice(10)+each_worker_label[i])%10).long(), model, optimizer, local_batch_size)\n",
    "            else:\n",
    "                for epoch in range(local_epochs):\n",
    "                    train_loss, train_acc = train(\n",
    "                        each_worker_data[i].reshape(-1, 1, 28, 28),\n",
    "                        torch.Tensor(each_worker_label[i]).long(), model, optimizer, local_batch_size)\n",
    "\n",
    "            params = []\n",
    "            for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                    (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "            update =  (params - model_received)\n",
    "            user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "        weight = model_received\n",
    "\n",
    "        if (e > start_detection_epoch):\n",
    "            hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "            hvp = np.squeeze(hvp)\n",
    "        else:\n",
    "            hvp = None\n",
    "\n",
    "        good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "        if hvp is not None:\n",
    "            pred_grad = copy.deepcopy(good_old_grads)\n",
    "            distance = []\n",
    "            for i in range(len(good_old_grads)):\n",
    "                pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "            good_distance_rage = np.concatenate(\n",
    "                (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "\n",
    "        if attack_type != 'none' and (e < start_detection_epoch):\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "            # user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "        elif e > start_detection_epoch:\n",
    "            if attack_type == 'full_trim':\n",
    "                user_grads = full_trim(user_grads, nbyz)\n",
    "            elif attack_type == 'none':\n",
    "                pass\n",
    "            else:\n",
    "                if attack_type == 'LIE':\n",
    "                    z = 0.1\n",
    "                    noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                    noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                    noise = noise_avg + z * noise_std\n",
    "                elif attack_type == 'NDSS21':\n",
    "                    distance_bound = np.random.choice(np.mean(good_distance_rage[-1:], 0))\n",
    "                    model_re = torch.mean(good_current_grads, dim=0)\n",
    "                    if dev_type == 'unit_vec':\n",
    "                        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                    elif dev_type == 'sign':\n",
    "                        deviation = torch.sign(model_re)\n",
    "                    elif dev_type == 'std':\n",
    "                        deviation = torch.std(good_current_grads, 0)\n",
    "                    # noise = deviation * ((distance_bound + np.random.uniform(0, np.std(good_distance_rage[-1]))) / torch.norm(deviation))\n",
    "                    noise = deviation * ((distance_bound)) / torch.norm(deviation)\n",
    "                else:\n",
    "                    noise = torch.zeros(hvp.shape).to(device)\n",
    "                for m in range(nbyz):\n",
    "                    user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "        agg_grads, distance = fldetector(old_grad_list, user_grads, nbyz, hvp, agr=agr)\n",
    "\n",
    "        if distance is not None and e > (start_detection_epoch - window_size):\n",
    "            malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "        if malicious_scores.shape[0] >= window_size+1:\n",
    "            if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "                print('Stop at iteration:', e)\n",
    "                detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz, num_workers)\n",
    "                break\n",
    "\n",
    "        if e > (start_detection_epoch - window_size):\n",
    "            weight_record.append(weight - last_weight)\n",
    "            grad_record.append(agg_grads - last_grad)\n",
    "\n",
    "        if (len(weight_record) > window_size):\n",
    "            del weight_record[0]\n",
    "            del grad_record[0]\n",
    "\n",
    "        last_weight = weight\n",
    "        last_grad = agg_grads\n",
    "        old_grad_list = user_grads\n",
    "        good_old_grads = good_current_grads\n",
    "\n",
    "        del user_grads\n",
    "        model_received = model_received + global_lr * agg_grads\n",
    "        fed_model = cnn().to(device)\n",
    "        fed_model.apply(init_weights)\n",
    "        start_idx=0\n",
    "        state_dict = {}\n",
    "        previous_name = 'none'\n",
    "        for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "            start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "            start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "            params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "            state_dict[name] = params\n",
    "            previous_name = name\n",
    "\n",
    "        fed_model.load_state_dict(state_dict)\n",
    "        val_loss, val_acc = test(global_test_data.reshape(-1,1,28,28), global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "        is_best = best_val_acc < val_acc\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "        if e%5==0 or e==99:\n",
    "            print('e %d | val_loss %.3f val acc %.3f | best val_acc %.3f' % (e, val_loss, val_acc, best_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0096d9",
   "metadata": {},
   "source": [
    "# MNIST + some clients with feature noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ddd194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy_mnist_data len:  10\n",
      "user grads shape:  torch.Size([110, 453572])\n",
      "e 0 | val_loss 1.758 val acc 67.786 | best val_acc 67.786\n",
      "e 5 | val_loss 0.185 val acc 94.452 | best val_acc 94.452\n",
      "e 10 | val_loss 0.124 val acc 96.225 | best val_acc 96.225\n",
      "e 20 | val_loss 0.085 val acc 97.450 | best val_acc 97.450\n",
      "e 25 | val_loss 0.076 val acc 97.619 | best val_acc 97.619\n",
      "e 30 | val_loss 0.070 val acc 97.828 | best val_acc 97.838\n",
      "e 35 | val_loss 0.064 val acc 97.998 | best val_acc 97.998\n",
      "Stop at iteration: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gypsum-gpu122/4403169/ipykernel_3998100/2337786522.py:54: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  acc=len(label_pred[label_pred==real_label])/nworkers\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [100, 110]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detection1(np\u001b[38;5;241m.\u001b[39msum(malicious_scores[\u001b[38;5;241m-\u001b[39mwindow_size:], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), nbyz):\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStop at iteration:\u001b[39m\u001b[38;5;124m'\u001b[39m, e)\n\u001b[0;32m--> 152\u001b[0m         \u001b[43mdetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmalicious_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m>\u001b[39m (start_detection_epoch \u001b[38;5;241m-\u001b[39m window_size):\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mdetection\u001b[0;34m(score, nobyz, nworkers)\u001b[0m\n\u001b[1;32m     56\u001b[0m fpr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(label_pred[nobyz:])\u001b[38;5;241m/\u001b[39m(nworkers\u001b[38;5;241m-\u001b[39mnobyz)\n\u001b[1;32m     57\u001b[0m fnr\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(label_pred[:nobyz])\u001b[38;5;241m/\u001b[39mnobyz\n\u001b[0;32m---> 58\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m; recall \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m; fpr \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m; fnr \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m; auc \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (acc, recall, fpr, fnr, auc))\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc, fpr, fnr, auc\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:571\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    569\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    570\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    580\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    581\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    585\u001b[0m     )\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:981\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    893\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    894\u001b[0m ):\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m \n\u001b[1;32m    980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:742\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 742\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    744\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m/work/vshejwalkar_umass_edu/anaconda/envs/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [100, 110]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FAST BASELINE\n",
    "'''\n",
    "n_malicious = [10]\n",
    "\n",
    "for n_mal in n_malicious:\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        # delete all variables\n",
    "        del weight_record, grad_record, old_grad_list, num_workers, malicious_scores, start_detection_epoch, window_size\n",
    "        del good_distance_rage\n",
    "        del nepochs, num_workers, local_lr, local_epochs, global_lr, agr\n",
    "        del attack_type, dev_type, fed_model\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # FL training initializations\n",
    "    num_workers = 100\n",
    "    use_cuda = True\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    local_lr=0.01\n",
    "    local_batch_size=32\n",
    "    local_epochs=2\n",
    "    global_lr=1\n",
    "    nepochs=50\n",
    "    agr='tr_mean' # ['average', 'median', 'tr_mean']\n",
    "\n",
    "    # Attack initializations\n",
    "    attack_type = 'none'\n",
    "    dev_type = 'sign'\n",
    "    nbyz = n_mal\n",
    "\n",
    "    # Noisy MNIST initializations\n",
    "    noisy_mnist = 10\n",
    "    beta = 1.0\n",
    "    nbyz = noisy_mnist\n",
    "    noisy_mnist_data = []\n",
    "    for i in range(noisy_mnist):\n",
    "        d = copy.deepcopy(each_worker_data[i])\n",
    "        d = (1 - beta) * d + beta * torch.normal(mean = torch.zeros(d.shape), std=1e-1*torch.ones(d.shape))\n",
    "        noisy_mnist_data.append(d)\n",
    "    print('noisy_mnist_data len: ', len(noisy_mnist_data))\n",
    "    \n",
    "    # FLD initializations\n",
    "    weight_record = []\n",
    "    grad_record = []\n",
    "    old_grad_list = []\n",
    "    malicious_scores = np.zeros((1, noisy_mnist + num_workers))\n",
    "    start_detection_epoch = 5\n",
    "    window_size = 5\n",
    "    assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "    good_distance_rage = np.zeros((1, nbyz))\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    # FL model initializations\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    fed_model = cnn().to(device)\n",
    "    fed_model.apply(init_weights)\n",
    "    model_received = []\n",
    "    for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "        model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        user_grads=[]\n",
    "        round_clients = np.arange(noisy_mnist + num_workers)\n",
    "        round_benign = round_clients\n",
    "        user_grads=[]\n",
    "\n",
    "        for i in round_benign:\n",
    "            model = copy.deepcopy(fed_model)\n",
    "            optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "            if i < noisy_mnist:\n",
    "                for epoch in range(local_epochs):\n",
    "                    train_loss, train_acc = train(\n",
    "                        noisy_mnist_data[i].reshape(-1, 1, 28, 28),\n",
    "                        torch.Tensor(each_worker_label[i]).long(), model, optimizer, local_batch_size)\n",
    "            else:\n",
    "                for epoch in range(local_epochs):\n",
    "                    train_loss, train_acc = train(\n",
    "                        each_worker_data[i - noisy_mnist].reshape(-1, 1, 28, 28),\n",
    "                        torch.Tensor(each_worker_label[i - noisy_mnist]).long(),\n",
    "                        model, optimizer, local_batch_size)\n",
    "\n",
    "            params = []\n",
    "            for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                    (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "            update =  (params - model_received)\n",
    "            user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "        if e == 0:\n",
    "            print('user grads shape: ', user_grads.shape)\n",
    "\n",
    "        weight = model_received\n",
    "\n",
    "        if (e > start_detection_epoch):\n",
    "            hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "            hvp = np.squeeze(hvp)\n",
    "        else:\n",
    "            hvp = None\n",
    "\n",
    "        good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "        if hvp is not None:\n",
    "            pred_grad = copy.deepcopy(good_old_grads)\n",
    "            distance = []\n",
    "            for i in range(len(good_old_grads)):\n",
    "                pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "            good_distance_rage = np.concatenate(\n",
    "                (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "\n",
    "        if attack_type != 'none' and (e < start_detection_epoch):\n",
    "            user_grads = full_trim(user_grads, nbyz)\n",
    "        elif e > start_detection_epoch:\n",
    "            if attack_type == 'full_trim':\n",
    "                user_grads = full_trim(user_grads, nbyz)\n",
    "            elif attack_type == 'none':\n",
    "                pass\n",
    "            else:\n",
    "                if attack_type == 'LIE':\n",
    "                    z = 0.1\n",
    "                    noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                    noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                    noise = noise_avg + z * noise_std\n",
    "                elif attack_type == 'NDSS21':\n",
    "                    distance_bound = np.random.choice(np.mean(good_distance_rage[-1:], 0))\n",
    "                    model_re = torch.mean(good_current_grads, dim=0)\n",
    "                    if dev_type == 'unit_vec':\n",
    "                        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                    elif dev_type == 'sign':\n",
    "                        deviation = torch.sign(model_re)\n",
    "                    elif dev_type == 'std':\n",
    "                        deviation = torch.std(good_current_grads, 0)\n",
    "                    # noise = deviation * ((distance_bound + np.random.uniform(0, np.std(good_distance_rage[-1]))) / torch.norm(deviation))\n",
    "                    noise = deviation * ((distance_bound)) / torch.norm(deviation)\n",
    "                else:\n",
    "                    noise = torch.zeros(hvp.shape).to(device)\n",
    "                for m in range(nbyz):\n",
    "                    user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "        agg_grads, distance = fldetector(old_grad_list, user_grads, nbyz, hvp, agr=agr)\n",
    "\n",
    "        if distance is not None and e > (start_detection_epoch - window_size):\n",
    "            malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "        if malicious_scores.shape[0] >= window_size+1:\n",
    "            if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "                print('Stop at iteration:', e)\n",
    "                detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz, num_workers)\n",
    "                break\n",
    "\n",
    "        if e > (start_detection_epoch - window_size):\n",
    "            weight_record.append(weight - last_weight)\n",
    "            grad_record.append(agg_grads - last_grad)\n",
    "\n",
    "        if (len(weight_record) > window_size):\n",
    "            del weight_record[0]\n",
    "            del grad_record[0]\n",
    "\n",
    "        last_weight = weight\n",
    "        last_grad = agg_grads\n",
    "        old_grad_list = user_grads\n",
    "        good_old_grads = good_current_grads\n",
    "\n",
    "        del user_grads\n",
    "        model_received = model_received + global_lr * agg_grads\n",
    "        fed_model = cnn().to(device)\n",
    "        fed_model.apply(init_weights)\n",
    "        start_idx=0\n",
    "        state_dict = {}\n",
    "        previous_name = 'none'\n",
    "        for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "            start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "            start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "            params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "            state_dict[name] = params\n",
    "            previous_name = name\n",
    "\n",
    "        fed_model.load_state_dict(state_dict)\n",
    "        val_loss, val_acc = test(global_test_data.reshape(-1,1,28,28), global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "        is_best = best_val_acc < val_acc\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "        if e%5==0 or e==nepochs-1:\n",
    "            print('e %d | val_loss %.3f val acc %.3f | best val_acc %.3f' % (e, val_loss, val_acc, best_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb45f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9000; recall 0.0000; fpr 0.0100; fnr 1.0000; auc 0.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9, 0.010000000000000009, 1.0, 0.495)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz, 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb2eb0",
   "metadata": {},
   "source": [
    "# Load ARDIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9be1cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('/home/vshejwalkar_umass_edu/ardis/ARDIS_train_2828.csv', header=None)\n",
    "l = pd.read_csv('/home/vshejwalkar_umass_edu/ardis/ARDIS_train_labels.csv', header=None)\n",
    "ardis_data = 1-np.array([np.array(s.split(' ')).reshape(28, 28).astype(np.float32) for s in d[0]])/255\n",
    "ardis_label = np.array([np.array(s.split('          ')).astype(np.int32).argmax() for s in l[0]])\n",
    "\n",
    "d_ = pd.read_csv('/home/vshejwalkar_umass_edu/ardis/ARDIS_test_2828.csv', header=None)\n",
    "l_ = pd.read_csv('/home/vshejwalkar_umass_edu/ardis/ARDIS_test_labels.csv', header=None)\n",
    "\n",
    "te_ardis_data = 1-np.array([np.array(s.split(' ')).reshape(28, 28).astype(np.float32) for s in d_[0]])/255\n",
    "te_ardis_label = np.array([np.array(s.split('          ')).astype(np.int32).argmax() for s in l_[0]])\n",
    "\n",
    "ardis_data = np.concatenate((ardis_data, te_ardis_data))\n",
    "ardis_label = np.concatenate((te_ardis_label, ardis_label))\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Ardis(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, ardis_data, ardis_label, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = ardis_data\n",
    "        self.labels = ardis_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = torch.Tensor((self.data[idx] - np.mean(self.data[idx]))/np.std(self.data[idx]))\n",
    "        label = self.labels[idx]\n",
    "        sample = (image, label)\n",
    "        return sample\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "ardis = Ardis(ardis_data, ardis_label, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f66d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_workers_ardis = 30\n",
    "num_workers_ardis = 30\n",
    "num_ardis_backdoor_clients=0\n",
    "distribution='fang'\n",
    "param = .5\n",
    "force = True\n",
    "if distribution=='fang':\n",
    "    ardis_each_worker_data, ardis_each_worker_label, ardis_each_worker_te_data, ardis_each_worker_te_label, ardis_global_test_data, ardis_global_test_label = get_client_train_data(\n",
    "        ardis, num_workers=total_num_workers_ardis, bias=param)\n",
    "elif distribution == 'dirichlet':\n",
    "    ardis_each_worker_data, ardis_each_worker_label, ardis_each_worker_te_data, ardis_each_worker_te_label, ardis_global_test_data, ardis_global_test_label = get_client_data_dirichlet(\n",
    "        ardis, total_num_workers_ardis, alpha=param, force=force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5483ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_data = []\n",
    "source_class = 7\n",
    "for i in range(len(ardis)):\n",
    "    if ardis[i][1] == source_class:\n",
    "        backdoor_data.append(ardis[i])\n",
    "\n",
    "backdoor_tr_data = []\n",
    "backdoor_tr_labels = []\n",
    "backdoor_te_data = []\n",
    "backdoor_te_labels = []\n",
    "for i in range(len(backdoor_data)):\n",
    "    if i < 700:\n",
    "        backdoor_tr_data.append(backdoor_data[i][0])\n",
    "        backdoor_tr_labels.append(backdoor_data[i][1])\n",
    "    else:\n",
    "        backdoor_te_data.append(backdoor_data[i][0])\n",
    "        backdoor_te_labels.append(backdoor_data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a454b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(backdoor_te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ededf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> run 0\n",
      "user grads shape:  torch.Size([130, 453572])\n",
      "e 0 | val_loss 1.685 val acc 72.119 | best val_acc 72.119 | ardis loss 2.287 acc 11.749\n",
      "e 5 | val_loss 0.198 val acc 94.820 | best val_acc 94.820 | ardis loss 2.168 acc 20.583\n",
      "e 10 | val_loss 0.131 val acc 96.065 | best val_acc 96.065 | ardis loss 1.921 acc 28.780\n",
      "e 15 | val_loss 0.105 val acc 96.693 | best val_acc 96.693 | ardis loss 1.753 acc 33.151\n",
      "e 20 | val_loss 0.090 val acc 97.181 | best val_acc 97.181 | ardis loss 1.648 acc 36.885\n",
      "e 25 | val_loss 0.081 val acc 97.500 | best val_acc 97.500 | ardis loss 1.577 acc 39.982\n",
      "e 30 | val_loss 0.074 val acc 97.639 | best val_acc 97.639 | ardis loss 1.524 acc 40.984\n",
      "e 35 | val_loss 0.069 val acc 97.838 | best val_acc 97.838 | ardis loss 1.485 acc 42.077\n",
      "e 40 | val_loss 0.064 val acc 97.958 | best val_acc 97.968 | ardis loss 1.452 acc 42.623\n",
      "e 45 | val_loss 0.061 val acc 98.028 | best val_acc 98.048 | ardis loss 1.427 acc 43.352\n",
      "e 49 | val_loss 0.058 val acc 98.157 | best val_acc 98.177 | ardis loss 1.408 acc 44.171\n",
      "\n",
      "====> run 1\n",
      "user grads shape:  torch.Size([130, 453572])\n",
      "e 0 | val_loss 1.884 val acc 68.075 | best val_acc 68.075 | ardis loss 2.262 acc 14.754\n",
      "e 5 | val_loss 0.212 val acc 93.814 | best val_acc 93.814 | ardis loss 2.203 acc 19.763\n",
      "e 10 | val_loss 0.138 val acc 96.045 | best val_acc 96.045 | ardis loss 1.920 acc 29.599\n",
      "e 15 | val_loss 0.109 val acc 96.773 | best val_acc 96.773 | ardis loss 1.749 acc 35.701\n",
      "e 20 | val_loss 0.093 val acc 97.171 | best val_acc 97.171 | ardis loss 1.643 acc 39.071\n",
      "e 25 | val_loss 0.081 val acc 97.490 | best val_acc 97.490 | ardis loss 1.575 acc 39.435\n",
      "e 30 | val_loss 0.074 val acc 97.649 | best val_acc 97.649 | ardis loss 1.524 acc 40.619\n",
      "e 35 | val_loss 0.069 val acc 97.789 | best val_acc 97.789 | ardis loss 1.485 acc 42.623\n",
      "e 40 | val_loss 0.064 val acc 97.908 | best val_acc 97.908 | ardis loss 1.457 acc 42.896\n",
      "e 45 | val_loss 0.061 val acc 97.998 | best val_acc 97.998 | ardis loss 1.430 acc 43.716\n",
      "e 49 | val_loss 0.058 val acc 98.117 | best val_acc 98.117 | ardis loss 1.415 acc 43.989\n",
      "\n",
      "====> run 2\n",
      "user grads shape:  torch.Size([130, 453572])\n",
      "e 0 | val_loss 1.818 val acc 72.477 | best val_acc 72.477 | ardis loss 2.277 acc 13.297\n",
      "e 5 | val_loss 0.196 val acc 94.501 | best val_acc 94.501 | ardis loss 2.222 acc 21.767\n",
      "e 10 | val_loss 0.130 val acc 96.006 | best val_acc 96.006 | ardis loss 1.895 acc 30.055\n",
      "e 15 | val_loss 0.103 val acc 96.882 | best val_acc 96.882 | ardis loss 1.717 acc 36.612\n",
      "e 20 | val_loss 0.087 val acc 97.360 | best val_acc 97.360 | ardis loss 1.616 acc 39.526\n",
      "e 25 | val_loss 0.077 val acc 97.669 | best val_acc 97.669 | ardis loss 1.552 acc 40.801\n",
      "e 30 | val_loss 0.070 val acc 97.928 | best val_acc 97.928 | ardis loss 1.512 acc 41.439\n",
      "e 35 | val_loss 0.064 val acc 98.077 | best val_acc 98.077 | ardis loss 1.475 acc 42.259\n",
      "e 40 | val_loss 0.060 val acc 98.277 | best val_acc 98.277 | ardis loss 1.448 acc 43.534\n",
      "e 45 | val_loss 0.057 val acc 98.247 | best val_acc 98.317 | ardis loss 1.422 acc 44.900\n",
      "e 49 | val_loss 0.054 val acc 98.386 | best val_acc 98.386 | ardis loss 1.409 acc 43.898\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FAST --AVERAGE-- BASELINE\n",
    "'''\n",
    "n_malicious = [0]\n",
    "for run in range(3):\n",
    "    print('\\n====> run %d' % run)\n",
    "    for n_mal in n_malicious:\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            # delete all variables\n",
    "            del weight_record, grad_record, old_grad_list, num_workers, malicious_scores, start_detection_epoch, window_size\n",
    "            del good_distance_rage\n",
    "            del nepochs, num_workers, local_lr, local_epochs, global_lr, agr\n",
    "            del attack_type, dev_type, fed_model\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # FL training initializations\n",
    "        num_workers = 100\n",
    "        use_cuda = True\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        local_lr=0.01\n",
    "        local_batch_size=32\n",
    "        local_epochs=2\n",
    "        global_lr=1\n",
    "        nepochs=50\n",
    "        agr='average' # ['average', 'median', 'tr_mean']\n",
    "\n",
    "        # Attack initializations\n",
    "        num_ardis_backdoor_clients = 0\n",
    "\n",
    "        attack_type = 'none'\n",
    "        dev_type = 'sign'\n",
    "        nbyz = num_workers_ardis\n",
    "\n",
    "        # FLD initializations\n",
    "        weight_record = []\n",
    "        grad_record = []\n",
    "        old_grad_list = []\n",
    "        malicious_scores = np.zeros((1, num_workers_ardis + num_workers))\n",
    "        start_detection_epoch = 5\n",
    "        window_size = 5\n",
    "        assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "        good_distance_rage = np.zeros((1, nbyz))\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        # FL model initializations\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "        fed_model = cnn().to(device)\n",
    "        fed_model.apply(init_weights)\n",
    "        model_received = []\n",
    "        for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "            model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        for e in range(nepochs):\n",
    "            user_grads=[]\n",
    "            round_clients = np.arange(num_workers_ardis + num_workers)\n",
    "            round_benign = round_clients\n",
    "            user_grads=[]\n",
    "\n",
    "            for i in round_benign:\n",
    "                model = copy.deepcopy(fed_model)\n",
    "                optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "                if i < num_workers_ardis:\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            ardis_each_worker_data[i].reshape(-1, 1, 28, 28),\n",
    "                            torch.Tensor(ardis_each_worker_label[i]).long(), model, optimizer, local_batch_size)\n",
    "                else:\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            each_worker_data[i - num_workers_ardis].reshape(-1, 1, 28, 28),\n",
    "                            torch.Tensor(each_worker_label[i - num_workers_ardis]).long(),\n",
    "                            model, optimizer, local_batch_size)\n",
    "\n",
    "                params = []\n",
    "                for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                    params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                        (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "                update =  (params - model_received)\n",
    "                user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "            if num_ardis_backdoor_clients:\n",
    "                backdoor_norm = 0\n",
    "                for _ in range(num_ardis_backdoor_clients):\n",
    "                    r = np.arange(len(backdoor_tr_data))\n",
    "                    np.random.shuffle(r)\n",
    "                    backdoor_tr_len = 200\n",
    "                    model = copy.deepcopy(fed_model)\n",
    "                    optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            torch.stack(backdoor_tr_data)[r][:backdoor_tr_len].reshape(-1, 1, 28, 28),\n",
    "                            torch.from_numpy(np.ones(backdoor_tr_len)).long(),\n",
    "                            model, optimizer, local_batch_size)\n",
    "                    params = []\n",
    "                    for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                        params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                            (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "                    update =  (params - model_received)\n",
    "                    backdoor_norm += torch.norm(update)/num_ardis_backdoor_clients\n",
    "                    user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "            if e == 0:\n",
    "                print('user grads shape: ', user_grads.shape)\n",
    "\n",
    "            weight = model_received\n",
    "            if (e > start_detection_epoch):\n",
    "                hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "                hvp = np.squeeze(hvp)\n",
    "            else:\n",
    "                hvp = None\n",
    "\n",
    "            if attack_type != 'none':\n",
    "                good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "                if hvp is not None:\n",
    "                    pred_grad = copy.deepcopy(good_old_grads)\n",
    "                    distance = []\n",
    "                    for i in range(len(good_old_grads)):\n",
    "                        pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "                    good_distance_rage = np.concatenate(\n",
    "                        (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "\n",
    "            if attack_type != 'none' and (e < start_detection_epoch):\n",
    "                user_grads = full_trim(user_grads, nbyz)\n",
    "            elif e > start_detection_epoch:\n",
    "                if attack_type == 'full_trim':\n",
    "                    user_grads = full_trim(user_grads, nbyz)\n",
    "                elif attack_type == 'none':\n",
    "                    pass\n",
    "                else:\n",
    "                    if attack_type == 'LIE':\n",
    "                        z = 0.1\n",
    "                        noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                        noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                        noise = noise_avg + z * noise_std\n",
    "                    elif attack_type == 'NDSS21':\n",
    "                        distance_bound = np.random.choice(np.mean(good_distance_rage[-1:], 0))\n",
    "                        model_re = torch.mean(good_current_grads, dim=0)\n",
    "                        if dev_type == 'unit_vec':\n",
    "                            deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                        elif dev_type == 'sign':\n",
    "                            deviation = torch.sign(model_re)\n",
    "                        elif dev_type == 'std':\n",
    "                            deviation = torch.std(good_current_grads, 0)\n",
    "                        # noise = deviation * ((distance_bound + np.random.uniform(0, np.std(good_distance_rage[-1]))) / torch.norm(deviation))\n",
    "                        noise = deviation * ((distance_bound)) / torch.norm(deviation)\n",
    "                    else:\n",
    "                        noise = torch.zeros(hvp.shape).to(device)\n",
    "                    for m in range(nbyz):\n",
    "                        user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "            agg_grads, distance = fldetector(old_grad_list, user_grads, nbyz, hvp, agr=agr)\n",
    "\n",
    "            if distance is not None and e > (start_detection_epoch - window_size):\n",
    "                malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "            if malicious_scores.shape[0] >= window_size+1:\n",
    "                if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "                    print('Stop at iteration:', e)\n",
    "                    detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz, len(user_grads))\n",
    "                    break\n",
    "\n",
    "            if e > (start_detection_epoch - window_size):\n",
    "                weight_record.append(weight - last_weight)\n",
    "                grad_record.append(agg_grads - last_grad)\n",
    "\n",
    "            if (len(weight_record) > window_size):\n",
    "                del weight_record[0]\n",
    "                del grad_record[0]\n",
    "\n",
    "            last_weight = weight\n",
    "            last_grad = agg_grads\n",
    "            old_grad_list = user_grads\n",
    "            if attack_type != 'none':\n",
    "                good_old_grads = good_current_grads\n",
    "\n",
    "            del user_grads\n",
    "            model_received = model_received + global_lr * agg_grads\n",
    "            fed_model = cnn().to(device)\n",
    "            fed_model.apply(init_weights)\n",
    "            start_idx=0\n",
    "            state_dict = {}\n",
    "            previous_name = 'none'\n",
    "            for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "                start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "                start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "                params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "                state_dict[name] = params\n",
    "                previous_name = name\n",
    "\n",
    "            fed_model.load_state_dict(state_dict)\n",
    "            val_loss, val_acc = test(global_test_data.reshape(-1,1,28,28), global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "            ardis_loss, ardis_acc = test(ardis_global_test_data.reshape(-1,1,28,28), ardis_global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "            is_best = best_val_acc < val_acc\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "            if e%5==0 or e==nepochs-1:\n",
    "                print('e %d | val_loss %.3f val acc %.3f | best val_acc %.3f | ardis loss %.3f acc %.3f' % (\n",
    "                    e, val_loss, val_acc, best_val_acc, ardis_loss, ardis_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "216f3ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> run 0\n",
      "user grads shape:  torch.Size([135, 453572])\n",
      "e 0 | val_loss 1.835 val acc 73.005 | best val_acc 73.005 | ardis loss 2.317 acc 13.479 | ardis backdoor loss 1.647 acc 93.333\n",
      "e 5 | val_loss 0.199 val acc 94.591 | best val_acc 94.591 | ardis loss 2.258 acc 19.672 | ardis backdoor loss 1.630 acc 53.333\n",
      "Stop at iteration: 10\n",
      "acc 0.7259; recall 0.0000; fpr 0.2462; fnr 1.0000; auc 0.3769\n",
      "\n",
      "====> run 1\n",
      "user grads shape:  torch.Size([135, 453572])\n",
      "e 0 | val_loss 1.688 val acc 67.387 | best val_acc 67.387 | ardis loss 2.312 acc 15.118 | ardis backdoor loss 2.002 acc 38.333\n",
      "e 5 | val_loss 0.229 val acc 93.495 | best val_acc 93.495 | ardis loss 2.308 acc 19.672 | ardis backdoor loss 1.774 acc 43.333\n",
      "e 10 | val_loss 0.145 val acc 95.707 | best val_acc 95.707 | ardis loss 2.054 acc 26.321 | ardis backdoor loss 1.581 acc 38.333\n",
      "e 15 | val_loss 0.114 val acc 96.524 | best val_acc 96.524 | ardis loss 1.909 acc 30.783 | ardis backdoor loss 1.612 acc 25.000\n",
      "e 20 | val_loss 0.096 val acc 97.081 | best val_acc 97.081 | ardis loss 1.806 acc 35.246 | ardis backdoor loss 1.630 acc 16.667\n",
      "e 25 | val_loss 0.085 val acc 97.450 | best val_acc 97.450 | ardis loss 1.732 acc 36.430 | ardis backdoor loss 1.648 acc 11.667\n",
      "e 30 | val_loss 0.077 val acc 97.729 | best val_acc 97.729 | ardis loss 1.673 acc 36.794 | ardis backdoor loss 1.674 acc 11.667\n",
      "e 35 | val_loss 0.071 val acc 97.809 | best val_acc 97.809 | ardis loss 1.638 acc 37.796 | ardis backdoor loss 1.634 acc 11.667\n",
      "e 40 | val_loss 0.066 val acc 97.938 | best val_acc 97.968 | ardis loss 1.594 acc 37.978 | ardis backdoor loss 1.629 acc 11.667\n",
      "e 45 | val_loss 0.062 val acc 98.028 | best val_acc 98.028 | ardis loss 1.560 acc 38.251 | ardis backdoor loss 1.652 acc 13.333\n",
      "e 49 | val_loss 0.060 val acc 98.117 | best val_acc 98.117 | ardis loss 1.544 acc 39.891 | ardis backdoor loss 1.635 acc 18.333\n",
      "\n",
      "====> run 2\n",
      "user grads shape:  torch.Size([135, 453572])\n",
      "e 0 | val_loss 1.675 val acc 77.129 | best val_acc 77.129 | ardis loss 2.270 acc 12.568 | ardis backdoor loss 1.997 acc 45.000\n",
      "e 5 | val_loss 0.200 val acc 94.242 | best val_acc 94.242 | ardis loss 2.218 acc 23.953 | ardis backdoor loss 1.961 acc 28.333\n",
      "e 10 | val_loss 0.133 val acc 95.996 | best val_acc 95.996 | ardis loss 1.979 acc 28.324 | ardis backdoor loss 1.786 acc 31.667\n",
      "e 15 | val_loss 0.104 val acc 96.713 | best val_acc 96.713 | ardis loss 1.833 acc 33.607 | ardis backdoor loss 1.748 acc 25.000\n",
      "e 20 | val_loss 0.088 val acc 97.251 | best val_acc 97.251 | ardis loss 1.749 acc 35.701 | ardis backdoor loss 1.658 acc 25.000\n",
      "e 25 | val_loss 0.077 val acc 97.530 | best val_acc 97.530 | ardis loss 1.669 acc 37.341 | ardis backdoor loss 1.703 acc 15.000\n",
      "e 30 | val_loss 0.070 val acc 97.729 | best val_acc 97.729 | ardis loss 1.634 acc 38.069 | ardis backdoor loss 1.606 acc 18.333\n",
      "e 35 | val_loss 0.065 val acc 97.878 | best val_acc 97.878 | ardis loss 1.590 acc 38.980 | ardis backdoor loss 1.652 acc 16.667\n",
      "e 40 | val_loss 0.061 val acc 98.038 | best val_acc 98.038 | ardis loss 1.561 acc 39.344 | ardis backdoor loss 1.685 acc 15.000\n",
      "e 45 | val_loss 0.057 val acc 98.177 | best val_acc 98.177 | ardis loss 1.538 acc 40.255 | ardis backdoor loss 1.635 acc 15.000\n",
      "e 49 | val_loss 0.055 val acc 98.227 | best val_acc 98.227 | ardis loss 1.526 acc 40.528 | ardis backdoor loss 1.614 acc 16.667\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FAST --AVERAGE-- BASELINE\n",
    "'''\n",
    "n_malicious = [0]\n",
    "for run in range(3):\n",
    "    print('\\n====> run %d' % run)\n",
    "    for n_mal in n_malicious:\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            # delete all variables\n",
    "            del weight_record, grad_record, old_grad_list, num_workers, malicious_scores, start_detection_epoch, window_size\n",
    "            del good_distance_rage\n",
    "            del nepochs, num_workers, local_lr, local_epochs, global_lr, agr\n",
    "            del attack_type, dev_type, fed_model\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # FL training initializations\n",
    "        num_workers = 100\n",
    "        use_cuda = True\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        local_lr=0.01\n",
    "        local_batch_size=32\n",
    "        local_epochs=2\n",
    "        global_lr=1\n",
    "        nepochs=50\n",
    "        agr='average' # ['average', 'median', 'tr_mean']\n",
    "\n",
    "        # Attack initializations\n",
    "        num_ardis_backdoor_clients = 5\n",
    "\n",
    "        attack_type = 'none'\n",
    "        dev_type = 'sign'\n",
    "        nbyz = num_ardis_backdoor_clients\n",
    "\n",
    "        # FLD initializations\n",
    "        weight_record = []\n",
    "        grad_record = []\n",
    "        old_grad_list = []\n",
    "        malicious_scores = np.zeros((1, (num_ardis_backdoor_clients + num_workers_ardis + num_workers)))\n",
    "        start_detection_epoch = 5\n",
    "        window_size = 5\n",
    "        assert (start_detection_epoch - window_size >= 0), 'start_detection_epoch %d should be more than window_size %d' % (start_detection_epoch, window_size)\n",
    "        good_distance_rage = np.zeros((1, nbyz))\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        # FL model initializations\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "        fed_model = cnn().to(device)\n",
    "        fed_model.apply(init_weights)\n",
    "        model_received = []\n",
    "        for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "            model_received = param.view(-1).data.type(torch.cuda.FloatTensor) if len(model_received) == 0 else torch.cat((model_received, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "        for e in range(nepochs):\n",
    "            user_grads=[]\n",
    "            round_clients = np.arange(num_workers_ardis + num_workers)\n",
    "            round_benign = round_clients\n",
    "            user_grads=[]\n",
    "\n",
    "            if num_ardis_backdoor_clients:\n",
    "                backdoor_norm = 0\n",
    "                for _ in range(num_ardis_backdoor_clients):\n",
    "                    r = np.arange(len(backdoor_tr_data))\n",
    "                    np.random.shuffle(r)\n",
    "                    backdoor_tr_len = 200\n",
    "                    model = copy.deepcopy(fed_model)\n",
    "                    optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            torch.stack(backdoor_tr_data)[r][:backdoor_tr_len].reshape(-1, 1, 28, 28),\n",
    "                            torch.from_numpy(np.ones(backdoor_tr_len)).long(),\n",
    "                            model, optimizer, local_batch_size)\n",
    "                    params = []\n",
    "                    for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                        params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                            (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "                    update =  (params - model_received)\n",
    "                    backdoor_norm += torch.norm(update)/num_ardis_backdoor_clients\n",
    "                    user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "            for i in round_benign:\n",
    "                model = copy.deepcopy(fed_model)\n",
    "                optimizer = optim.SGD(model.parameters(), lr = local_lr, momentum=0.9, weight_decay=1e-4)\n",
    "                if i < num_workers_ardis:\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            ardis_each_worker_data[i].reshape(-1, 1, 28, 28),\n",
    "                            torch.Tensor(ardis_each_worker_label[i]).long(), model, optimizer, local_batch_size)\n",
    "                else:\n",
    "                    for epoch in range(local_epochs):\n",
    "                        train_loss, train_acc = train(\n",
    "                            each_worker_data[i - num_workers_ardis].reshape(-1, 1, 28, 28),\n",
    "                            torch.Tensor(each_worker_label[i - num_workers_ardis]).long(),\n",
    "                            model, optimizer, local_batch_size)\n",
    "\n",
    "                params = []\n",
    "                for i, (name, param) in enumerate(model.state_dict().items()):\n",
    "                    params = param.view(-1).data.type(torch.cuda.FloatTensor) if len(params) == 0 else torch.cat(\n",
    "                        (params, param.view(-1).data.type(torch.cuda.FloatTensor)))\n",
    "\n",
    "                update =  (params - model_received)\n",
    "                user_grads = update[None,:] if len(user_grads) == 0 else torch.cat((user_grads, update[None,:]), 0)\n",
    "\n",
    "            if e == 0:\n",
    "                print('user grads shape: ', user_grads.shape)\n",
    "\n",
    "            weight = model_received\n",
    "            if (e > start_detection_epoch):\n",
    "                hvp = lbfgs(weight_record, grad_record, weight - last_weight)\n",
    "                hvp = np.squeeze(hvp)\n",
    "            else:\n",
    "                hvp = None\n",
    "\n",
    "            good_current_grads = copy.deepcopy(user_grads[:nbyz])\n",
    "            if hvp is not None:\n",
    "                pred_grad = copy.deepcopy(good_old_grads)\n",
    "                distance = []\n",
    "                for i in range(len(good_old_grads)):\n",
    "                    pred_grad[i] += torch.from_numpy(hvp).to(device)\n",
    "                good_distance_rage = np.concatenate(\n",
    "                    (good_distance_rage, torch.norm(pred_grad - good_current_grads, dim = 1).cpu().numpy()[None,:]), 0)\n",
    "\n",
    "            if attack_type != 'none' and (e < start_detection_epoch):\n",
    "                user_grads = full_trim(user_grads, nbyz)\n",
    "                # user_grads[:nbyz] = full_trim(user_grads[:nbyz], nbyz)\n",
    "            elif e > start_detection_epoch:\n",
    "                if attack_type == 'full_trim':\n",
    "                    user_grads = full_trim(user_grads, nbyz)\n",
    "                elif attack_type == 'none':\n",
    "                    pass\n",
    "                else:\n",
    "                    if attack_type == 'LIE':\n",
    "                        z = 0.1\n",
    "                        noise_avg = torch.mean(user_grads[:nbyz], dim=0)\n",
    "                        noise_std = torch.std(user_grads[:nbyz], dim=0)\n",
    "                        noise = noise_avg + z * noise_std\n",
    "                    elif attack_type == 'NDSS21':\n",
    "                        distance_bound = np.random.choice(np.mean(good_distance_rage[-1:], 0))\n",
    "                        model_re = torch.mean(good_current_grads, dim=0)\n",
    "                        if dev_type == 'unit_vec':\n",
    "                            deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "                        elif dev_type == 'sign':\n",
    "                            deviation = torch.sign(model_re)\n",
    "                        elif dev_type == 'std':\n",
    "                            deviation = torch.std(good_current_grads, 0)\n",
    "                        # noise = deviation * ((distance_bound + np.random.uniform(0, np.std(good_distance_rage[-1]))) / torch.norm(deviation))\n",
    "                        noise = deviation * ((distance_bound)) / torch.norm(deviation)\n",
    "                    else:\n",
    "                        noise = torch.zeros(hvp.shape).to(device)\n",
    "                    for m in range(nbyz):\n",
    "                        user_grads[m] = old_grad_list[m] + torch.from_numpy(hvp).to(device) + noise\n",
    "\n",
    "            agg_grads, distance = fldetector(old_grad_list, user_grads, nbyz, hvp, agr=agr)\n",
    "\n",
    "            if distance is not None and e > (start_detection_epoch - window_size):\n",
    "                malicious_scores = np.concatenate((malicious_scores, distance[None, :]), 0)\n",
    "\n",
    "            if malicious_scores.shape[0] >= window_size+1:\n",
    "                if detection1(np.sum(malicious_scores[-window_size:], axis=0), nbyz):\n",
    "                    print('Stop at iteration:', e)\n",
    "                    detection(np.sum(malicious_scores[-window_size:], axis=0), nbyz, len(user_grads))\n",
    "                    break\n",
    "\n",
    "            if e > (start_detection_epoch - window_size):\n",
    "                weight_record.append(weight - last_weight)\n",
    "                grad_record.append(agg_grads - last_grad)\n",
    "\n",
    "            if (len(weight_record) > window_size):\n",
    "                del weight_record[0]\n",
    "                del grad_record[0]\n",
    "\n",
    "            last_weight = weight\n",
    "            last_grad = agg_grads\n",
    "            old_grad_list = user_grads\n",
    "            good_old_grads = good_current_grads\n",
    "\n",
    "            del user_grads\n",
    "            model_received = model_received + global_lr * agg_grads\n",
    "            fed_model = cnn().to(device)\n",
    "            fed_model.apply(init_weights)\n",
    "            start_idx=0\n",
    "            state_dict = {}\n",
    "            previous_name = 'none'\n",
    "            for i, (name, param) in enumerate(fed_model.state_dict().items()):\n",
    "                start_idx = 0 if i == 0 else start_idx + len(fed_model.state_dict()[previous_name].data.view(-1))\n",
    "                start_end = start_idx + len(fed_model.state_dict()[name].data.view(-1))\n",
    "                params = model_received[start_idx:start_end].reshape(fed_model.state_dict()[name].data.shape)\n",
    "                state_dict[name] = params\n",
    "                previous_name = name\n",
    "\n",
    "            fed_model.load_state_dict(state_dict)\n",
    "            val_loss, val_acc = test(global_test_data.reshape(-1,1,28,28), global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "            ardis_loss, ardis_acc = test(ardis_global_test_data.reshape(-1,1,28,28), ardis_global_test_label.long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "            ardis_bd_loss, ardis_bd_acc = test(torch.stack(backdoor_te_data).reshape(-1,1,28,28), torch.from_numpy(np.ones(len(backdoor_te_data))).long(), fed_model, criterion, use_cuda, batch_size=50)\n",
    "            is_best = best_val_acc < val_acc\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "            if e%5==0 or e==nepochs-1:\n",
    "                print('e %d | val_loss %.3f val acc %.3f | best val_acc %.3f | ardis loss %.3f acc %.3f | ardis backdoor loss %.3f acc %.3f' % (\n",
    "                    e, val_loss, val_acc, best_val_acc, ardis_loss, ardis_acc, ardis_bd_loss, ardis_bd_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78762c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
